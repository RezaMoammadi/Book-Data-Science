\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{apalike}
\HyPL@Entry{0<</S/D>>}
\newlabel{preface}{{}{7}{Preface}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{Preface}{7}{chapter*.2}\protected@file@percent }
\newlabel{why-this-book}{{}{7}{Why This Book?}{section*.3}{}}
\@writefile{toc}{\contentsline {section}{Why This Book?}{7}{section*.3}\protected@file@percent }
\newlabel{who-should-read-this-book}{{}{8}{Who Should Read This Book?}{section*.4}{}}
\@writefile{toc}{\contentsline {section}{Who Should Read This Book?}{8}{section*.4}\protected@file@percent }
\newlabel{what-you-will-learn}{{}{8}{What You Will Learn}{section*.5}{}}
\@writefile{toc}{\contentsline {section}{What You Will Learn}{8}{section*.5}\protected@file@percent }
\newlabel{the-data-science-process}{{}{8}{The Data Science Process}{section*.6}{}}
\@writefile{toc}{\contentsline {section}{The Data Science Process}{8}{section*.6}\protected@file@percent }
\newlabel{how-this-book-is-structured}{{}{9}{How This Book Is Structured}{section*.7}{}}
\@writefile{toc}{\contentsline {section}{How This Book Is Structured}{9}{section*.7}\protected@file@percent }
\newlabel{how-to-use-this-book}{{}{10}{How to Use This Book}{section*.8}{}}
\@writefile{toc}{\contentsline {section}{How to Use This Book}{10}{section*.8}\protected@file@percent }
\newlabel{datasets-used-in-this-book}{{}{10}{Datasets Used in This Book}{section*.9}{}}
\@writefile{toc}{\contentsline {section}{Datasets Used in This Book}{10}{section*.9}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces List of datasets used for case studies in different chapters. Available in the R package liver.}}{11}{table.0.1}\protected@file@percent }
\newlabel{tab:data-table}{{1}{11}{List of datasets used for case studies in different chapters. Available in the R package liver}{table.0.1}{}}
\newlabel{prerequisites}{{}{11}{Prerequisites}{section*.10}{}}
\@writefile{toc}{\contentsline {section}{Prerequisites}{11}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}The Basics for R}{13}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-into-R}{{1}{13}{The Basics for R}{chapter.1}{}}
\newlabel{why-choose-r-for-data-science}{{1}{13}{Why Choose R for Data Science?}{section*.11}{}}
\@writefile{toc}{\contentsline {subsection}{Why Choose R for Data Science?}{13}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.1}How to Install R}{14}{section.1.1}\protected@file@percent }
\newlabel{how-to-install-r}{{1.1}{14}{How to Install R}{section.1.1}{}}
\newlabel{keeping-r-up-to-date}{{1.1}{14}{Keeping R Up to Date}{section*.12}{}}
\@writefile{toc}{\contentsline {subsection}{Keeping R Up to Date}{14}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}How to Install RStudio}{14}{section.1.2}\protected@file@percent }
\newlabel{how-to-install-rstudio}{{1.2}{14}{How to Install RStudio}{section.1.2}{}}
\newlabel{installing-rstudio}{{1.2}{15}{Installing RStudio}{section*.13}{}}
\@writefile{toc}{\contentsline {subsection}{Installing RStudio}{15}{section*.13}\protected@file@percent }
\newlabel{exploring-the-rstudio-interface}{{1.2}{15}{Exploring the RStudio Interface}{section*.14}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring the RStudio Interface}{15}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The RStudio window when you first launch the program.}}{15}{figure.1.1}\protected@file@percent }
\newlabel{fig:RStudio-window-1}{{1.1}{15}{The RStudio window when you first launch the program}{figure.1.1}{}}
\citation{grolemund2014hands}
\newlabel{customizing-rstudio}{{1.2}{16}{Customizing RStudio}{section*.15}{}}
\@writefile{toc}{\contentsline {subsection}{Customizing RStudio}{16}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}How to Learn R}{16}{section.1.3}\protected@file@percent }
\newlabel{how-to-learn-r}{{1.3}{16}{How to Learn R}{section.1.3}{}}
\newlabel{video-tutorials}{{1.3}{16}{1. Video Tutorials}{section*.16}{}}
\@writefile{toc}{\contentsline {subsection}{1. Video Tutorials}{16}{section*.16}\protected@file@percent }
\newlabel{books}{{1.3}{16}{2. Books}{section*.17}{}}
\@writefile{toc}{\contentsline {subsection}{2. Books}{16}{section*.17}\protected@file@percent }
\citation{wickham2017r}
\citation{lantz2013machine}
\newlabel{online-courses}{{1.3}{17}{3. Online Courses}{section*.18}{}}
\@writefile{toc}{\contentsline {subsection}{3. Online Courses}{17}{section*.18}\protected@file@percent }
\newlabel{r-communities-forums}{{1.3}{17}{4. R Communities \& Forums}{section*.19}{}}
\@writefile{toc}{\contentsline {subsection}{4. R Communities \& Forums}{17}{section*.19}\protected@file@percent }
\newlabel{practice-regularly}{{1.3}{17}{5. Practice Regularly}{section*.20}{}}
\@writefile{toc}{\contentsline {subsection}{5. Practice Regularly}{17}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Getting Help and Learning More}{17}{section.1.4}\protected@file@percent }
\newlabel{getting-help-and-learning-more}{{1.4}{17}{Getting Help and Learning More}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Data Science with R}{18}{section.1.5}\protected@file@percent }
\newlabel{data-science-with-r}{{1.5}{18}{Data Science with R}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}How to Install R Packages}{19}{section.1.6}\protected@file@percent }
\newlabel{install-packages}{{1.6}{19}{How to Install R Packages}{section.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A visual guide to installing R packages using the 'Tools' tab in RStudio.}}{19}{figure.1.2}\protected@file@percent }
\newlabel{fig:install-packages}{{1.2}{19}{A visual guide to installing R packages using the 'Tools' tab in RStudio}{figure.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}How to Load R Packages}{20}{section.1.7}\protected@file@percent }
\newlabel{how-to-load-r-packages}{{1.7}{20}{How to Load R Packages}{section.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Running R Code}{21}{section.1.8}\protected@file@percent }
\newlabel{running-r-code}{{1.8}{21}{Running R Code}{section.1.8}{}}
\newlabel{using-comments-in-r}{{1.8}{21}{Using Comments in R}{section*.21}{}}
\@writefile{toc}{\contentsline {subsection}{Using Comments in R}{21}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Functions in R}{21}{subsection.1.8.1}\protected@file@percent }
\newlabel{functions-in-r}{{1.8.1}{21}{Functions in R}{subsection.1.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}How to Import Data into R}{22}{section.1.9}\protected@file@percent }
\newlabel{how-to-import-data-into-r}{{1.9}{22}{How to Import Data into R}{section.1.9}{}}
\newlabel{using-rstudios-graphical-interface}{{1.9}{22}{Using RStudio's Graphical Interface}{section*.22}{}}
\@writefile{toc}{\contentsline {subsection}{Using RStudio's Graphical Interface}{22}{section*.22}\protected@file@percent }
\newlabel{using-read.csv}{{1.9}{22}{\texorpdfstring {Using \texttt {read.csv()}}{Using read.csv()}}{section*.23}{}}
\@writefile{toc}{\contentsline {subsection}{Using \texttt  {read.csv()}}{22}{section*.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A visual guide to loading a dataset into R using the 'Import Dataset' tab in RStudio.}}{23}{figure.1.3}\protected@file@percent }
\newlabel{fig:load-data}{{1.3}{23}{A visual guide to loading a dataset into R using the 'Import Dataset' tab in RStudio}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A visual guide to customizing the import settings when loading a dataset into R using the 'Import Dataset' tab in RStudio.}}{23}{figure.1.4}\protected@file@percent }
\newlabel{fig:load-data-2}{{1.4}{23}{A visual guide to customizing the import settings when loading a dataset into R using the 'Import Dataset' tab in RStudio}{figure.1.4}{}}
\newlabel{setting-the-working-directory}{{1.9}{24}{Setting the Working Directory}{section*.24}{}}
\@writefile{toc}{\contentsline {subsection}{Setting the Working Directory}{24}{section*.24}\protected@file@percent }
\newlabel{using-file.choose-with-read.csv}{{1.9}{24}{\texorpdfstring {Using \texttt {file.choose()} with \texttt {read.csv()}}{Using file.choose() with read.csv()}}{section*.25}{}}
\@writefile{toc}{\contentsline {subsection}{Using \texttt  {file.choose()} with \texttt  {read.csv()}}{24}{section*.25}\protected@file@percent }
\newlabel{loading-data-from-online-sources}{{1.9}{24}{Loading Data from Online Sources}{section*.26}{}}
\@writefile{toc}{\contentsline {subsection}{Loading Data from Online Sources}{24}{section*.26}\protected@file@percent }
\newlabel{using-read_excel-for-excel-files}{{1.9}{25}{\texorpdfstring {Using \texttt {read\_excel()} for Excel Files}{Using read\_excel() for Excel Files}}{section*.27}{}}
\@writefile{toc}{\contentsline {subsection}{Using \texttt  {read\_excel()} for Excel Files}{25}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.10}Data Types in R}{25}{section.1.10}\protected@file@percent }
\newlabel{data-types-in-r}{{1.10}{25}{Data Types in R}{section.1.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.11}Data Structures in R}{26}{section.1.11}\protected@file@percent }
\newlabel{data-structures-in-r}{{1.11}{26}{Data Structures in R}{section.1.11}{}}
\newlabel{vectors-in-r}{{1.11}{26}{Vectors in R}{section*.28}{}}
\@writefile{toc}{\contentsline {subsection}{Vectors in R}{26}{section*.28}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces A visual guide to different types of data structures in R.}}{27}{figure.1.5}\protected@file@percent }
\newlabel{fig:R-objects}{{1.5}{27}{A visual guide to different types of data structures in R}{figure.1.5}{}}
\newlabel{matrices-in-r}{{1.11}{27}{Matrices in R}{section*.29}{}}
\@writefile{toc}{\contentsline {subsection}{Matrices in R}{27}{section*.29}\protected@file@percent }
\newlabel{data-frames-in-r}{{1.11}{28}{Data Frames in R}{section*.30}{}}
\@writefile{toc}{\contentsline {subsection}{Data Frames in R}{28}{section*.30}\protected@file@percent }
\newlabel{lists-in-r}{{1.11}{30}{Lists in R}{section*.31}{}}
\@writefile{toc}{\contentsline {subsection}{Lists in R}{30}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.12}Accessing Records or Variables in R}{31}{section.1.12}\protected@file@percent }
\newlabel{accessing-records-or-variables-in-r}{{1.12}{31}{Accessing Records or Variables in R}{section.1.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.13}Visualizing Data in R}{33}{section.1.13}\protected@file@percent }
\newlabel{visualizing-data-in-r}{{1.13}{33}{Visualizing Data in R}{section.1.13}{}}
\newlabel{geom-functions-in-ggplot2}{{1.13}{34}{Geom Functions in ggplot2}{section*.32}{}}
\@writefile{toc}{\contentsline {subsection}{Geom Functions in ggplot2}{34}{section*.32}\protected@file@percent }
\newlabel{aesthetics-in-ggplot2}{{1.13}{36}{Aesthetics in ggplot2}{section*.33}{}}
\@writefile{toc}{\contentsline {subsection}{Aesthetics in ggplot2}{36}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.14}Formula in R}{37}{section.1.14}\protected@file@percent }
\newlabel{sec-formula-in-R}{{1.14}{37}{Formula in R}{section.1.14}{}}
\newlabel{exm:ex-formula}{{1.1}{38}{}{example.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.15}Reporting with R Markdown}{38}{section.1.15}\protected@file@percent }
\newlabel{reporting-with-r-markdown}{{1.15}{38}{Reporting with R Markdown}{section.1.15}{}}
\newlabel{r-markdown-basics}{{1.15}{39}{R Markdown Basics}{section*.34}{}}
\@writefile{toc}{\contentsline {subsection}{R Markdown Basics}{39}{section*.34}\protected@file@percent }
\newlabel{the-header}{{1.15}{39}{The Header}{section*.35}{}}
\@writefile{toc}{\contentsline {subsection}{The Header}{39}{section*.35}\protected@file@percent }
\newlabel{code-chunks-and-inline-code}{{1.15}{40}{Code Chunks and Inline Code}{section*.36}{}}
\@writefile{toc}{\contentsline {subsection}{Code Chunks and Inline Code}{40}{section*.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Executing a code chunk in R Markdown using the 'Run' button in RStudio.}}{40}{figure.1.6}\protected@file@percent }
\newlabel{fig:run-chunk}{{1.6}{40}{Executing a code chunk in R Markdown using the 'Run' button in RStudio}{figure.1.6}{}}
\newlabel{styling-text}{{1.15}{41}{Styling Text}{section*.37}{}}
\@writefile{toc}{\contentsline {subsection}{Styling Text}{41}{section*.37}\protected@file@percent }
\newlabel{mastering-r-markdown}{{1.15}{41}{Mastering R Markdown}{section*.38}{}}
\@writefile{toc}{\contentsline {subsection}{Mastering R Markdown}{41}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.16}Exercises}{42}{section.1.16}\protected@file@percent }
\newlabel{exercises}{{1.16}{42}{Exercises}{section.1.16}{}}
\newlabel{basic-exercises}{{1.16}{42}{Basic Exercises}{section*.39}{}}
\@writefile{toc}{\contentsline {subsection}{Basic Exercises}{42}{section*.39}\protected@file@percent }
\newlabel{more-challenges-exercise}{{1.16}{43}{More Challenges Exercise}{section*.40}{}}
\@writefile{toc}{\contentsline {subsection}{More Challenges Exercise}{43}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Introduction to Data Science}{47}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-intro-DS}{{2}{47}{Introduction to Data Science}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}What is Data Science?}{47}{section.2.1}\protected@file@percent }
\newlabel{what-is-data-science}{{2.1}{47}{What is Data Science?}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Data science is a multidisciplinary field that applies computational and statistical methods to extract insights from data.}}{48}{figure.2.1}\protected@file@percent }
\newlabel{fig:Data-Science}{{2.1}{48}{Data science is a multidisciplinary field that applies computational and statistical methods to extract insights from data}{figure.2.1}{}}
\newlabel{key-components-of-data-science}{{2.1}{48}{Key Components of Data Science}{section*.41}{}}
\@writefile{toc}{\contentsline {subsection}{Key Components of Data Science}{48}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Why Data Science Matters}{49}{section.2.2}\protected@file@percent }
\newlabel{why-data-science-matters}{{2.2}{49}{Why Data Science Matters}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}The Data Science Workflow}{50}{section.2.3}\protected@file@percent }
\newlabel{the-data-science-workflow}{{2.3}{50}{The Data Science Workflow}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The DIKW Pyramid illustrates the transformation of raw data into actionable insights, progressing from data to information, knowledge, and ultimately wisdom.}}{50}{figure.2.2}\protected@file@percent }
\newlabel{fig:DIKW-Pyramid}{{2.2}{50}{The DIKW Pyramid illustrates the transformation of raw data into actionable insights, progressing from data to information, knowledge, and ultimately wisdom}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model, it ensures systematic problem-solving and continuous refinement.}}{51}{figure.2.3}\protected@file@percent }
\newlabel{fig:CRISP-DM}{{2.3}{51}{The Data Science Workflow is an iterative framework for structuring data science and machine learning projects. Inspired by the CRISP-DM model, it ensures systematic problem-solving and continuous refinement}{figure.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem Understanding}{52}{section.2.4}\protected@file@percent }
\newlabel{problem-understanding}{{2.4}{52}{Problem Understanding}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Data Preparation}{53}{section.2.5}\protected@file@percent }
\newlabel{data-preparation}{{2.5}{53}{Data Preparation}{section.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Exploratory Data Analysis (EDA)}{53}{section.2.6}\protected@file@percent }
\newlabel{exploratory-data-analysis-eda}{{2.6}{53}{Exploratory Data Analysis (EDA)}{section.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Preparing Data for Modeling}{54}{section.2.7}\protected@file@percent }
\newlabel{preparing-data-for-modeling}{{2.7}{54}{Preparing Data for Modeling}{section.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Modeling}{55}{section.2.8}\protected@file@percent }
\newlabel{modeling}{{2.8}{55}{Modeling}{section.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Evaluation}{55}{section.2.9}\protected@file@percent }
\newlabel{evaluation}{{2.9}{55}{Evaluation}{section.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Deployment}{56}{section.2.10}\protected@file@percent }
\newlabel{deployment}{{2.10}{56}{Deployment}{section.2.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Machine Learning}{56}{section.2.11}\protected@file@percent }
\newlabel{machine-learning}{{2.11}{56}{Machine Learning}{section.2.11}{}}
\newlabel{machine-learning-tasks-supervised-vs.-unsupervised-learning}{{2.11}{57}{Machine Learning Tasks: Supervised vs.~Unsupervised Learning}{section*.42}{}}
\@writefile{toc}{\contentsline {subsection}{Machine Learning Tasks: Supervised vs.\nobreakspace  {}Unsupervised Learning}{57}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.12}Exercises}{58}{section.2.12}\protected@file@percent }
\newlabel{exercises-1}{{2.12}{58}{Exercises}{section.2.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Data Preparation}{61}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-data-prep}{{3}{61}{Data Preparation}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem Understanding}{61}{section.3.1}\protected@file@percent }
\newlabel{problem-understanding}{{3.1}{61}{Problem Understanding}{section.3.1}{}}
\newlabel{objectives-and-key-questions}{{3.1}{61}{Objectives and Key Questions}{section*.43}{}}
\@writefile{toc}{\contentsline {subsection}{Objectives and Key Questions}{61}{section*.43}\protected@file@percent }
\newlabel{framing-the-problem-as-a-data-science-task}{{3.1}{62}{Framing the Problem as a Data Science Task}{section*.44}{}}
\@writefile{toc}{\contentsline {subsection}{Framing the Problem as a Data Science Task}{62}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}diamonds Dataset Overview}{62}{section.3.2}\protected@file@percent }
\newlabel{diamonds-dataset-overview}{{3.2}{62}{diamonds Dataset Overview}{section.3.2}{}}
\newlabel{types-of-features-in-the-diamonds-dataset}{{3.2}{64}{\texorpdfstring {Types of Features in the \texttt {diamonds} Dataset}{Types of Features in the diamonds Dataset}}{section*.45}{}}
\@writefile{toc}{\contentsline {subsection}{Types of Features in the \texttt  {diamonds} Dataset}{64}{section*.45}\protected@file@percent }
\newlabel{key-considerations-for-data-preparation}{{3.2}{64}{Key Considerations for Data Preparation}{section*.46}{}}
\@writefile{toc}{\contentsline {subsection}{Key Considerations for Data Preparation}{64}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Outliers}{65}{section.3.3}\protected@file@percent }
\newlabel{Data-pre-outliers}{{3.3}{65}{Outliers}{section.3.3}{}}
\newlabel{identifying-outliers-using-visualization-techniques}{{3.3}{65}{Identifying Outliers Using Visualization Techniques}{section*.47}{}}
\@writefile{toc}{\contentsline {subsection}{Identifying Outliers Using Visualization Techniques}{65}{section*.47}\protected@file@percent }
\newlabel{boxplots-detecting-extreme-values}{{3.3}{65}{Boxplots: Detecting Extreme Values}{section*.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{Boxplots: Detecting Extreme Values}{65}{section*.48}\protected@file@percent }
\newlabel{histograms-understanding-outlier-distribution}{{3.3}{66}{Histograms: Understanding Outlier Distribution}{section*.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{Histograms: Understanding Outlier Distribution}{66}{section*.49}\protected@file@percent }
\newlabel{handling-outliers-best-practices}{{3.3}{67}{Handling Outliers: Best Practices}{section*.50}{}}
\@writefile{toc}{\contentsline {subsection}{Handling Outliers: Best Practices}{67}{section*.50}\protected@file@percent }
\newlabel{expanded-code-example-handling-outliers-in-r}{{3.3}{68}{Expanded Code Example: Handling Outliers in R}{section*.51}{}}
\@writefile{toc}{\contentsline {subsection}{Expanded Code Example: Handling Outliers in R}{68}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Missing Values}{68}{section.3.4}\protected@file@percent }
\newlabel{missing-values}{{3.4}{68}{Missing Values}{section.3.4}{}}
\newlabel{imputation-techniques}{{3.4}{68}{Imputation Techniques}{section*.52}{}}
\@writefile{toc}{\contentsline {subsection}{Imputation Techniques}{68}{section*.52}\protected@file@percent }
\newlabel{best-practices}{{3.4}{69}{Best Practices}{section*.53}{}}
\@writefile{toc}{\contentsline {subsection}{Best Practices}{69}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Feature Scaling}{69}{section.3.5}\protected@file@percent }
\newlabel{feature-scaling}{{3.5}{69}{Feature Scaling}{section.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Min-Max Scaling}{70}{section.3.6}\protected@file@percent }
\newlabel{min-max-scaling}{{3.6}{70}{Min-Max Scaling}{section.3.6}{}}
\newlabel{exm:ex-min-max}{{3.1}{71}{}{example.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Z-score Scaling}{71}{section.3.7}\protected@file@percent }
\newlabel{z-score-scaling}{{3.7}{71}{Z-score Scaling}{section.3.7}{}}
\newlabel{exm:ex-zscore}{{3.2}{72}{}{example.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}How to Reexpress Categorical Field Values}{73}{section.3.8}\protected@file@percent }
\newlabel{how-to-reexpress-categorical-field-values}{{3.8}{73}{How to Reexpress Categorical Field Values}{section.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Why Reexpress Categorical Fields?}{73}{subsection.3.8.1}\protected@file@percent }
\newlabel{why-reexpress-categorical-fields}{{3.8.1}{73}{Why Reexpress Categorical Fields?}{subsection.3.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.2}Techniques for Reexpressing Categorical Variables}{74}{subsection.3.8.2}\protected@file@percent }
\newlabel{techniques-for-reexpressing-categorical-variables}{{3.8.2}{74}{Techniques for Reexpressing Categorical Variables}{subsection.3.8.2}{}}
\newlabel{ordinal-encoding}{{3.8.2}{74}{Ordinal Encoding}{section*.54}{}}
\@writefile{toc}{\contentsline {subsubsection}{Ordinal Encoding}{74}{section*.54}\protected@file@percent }
\newlabel{one-hot-encoding}{{3.8.2}{74}{One-Hot Encoding}{section*.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{One-Hot Encoding}{74}{section*.55}\protected@file@percent }
\newlabel{frequency-encoding}{{3.8.2}{75}{Frequency Encoding}{section*.56}{}}
\@writefile{toc}{\contentsline {subsubsection}{Frequency Encoding}{75}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.3}Choosing the Right Encoding Technique}{75}{subsection.3.8.3}\protected@file@percent }
\newlabel{choosing-the-right-encoding-technique}{{3.8.3}{75}{Choosing the Right Encoding Technique}{subsection.3.8.3}{}}
\newlabel{exm:ex-encoding}{{3.3}{75}{}{example.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Case Study: Who Can Earn More Than \$50K Per Year?}{76}{section.3.9}\protected@file@percent }
\newlabel{Data-pre-adult}{{3.9}{76}{Case Study: Who Can Earn More Than \$50K Per Year?}{section.3.9}{}}
\newlabel{overview-of-the-dataset}{{3.9}{76}{Overview of the Dataset}{section*.57}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{76}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Missing Values}{80}{subsection.3.9.1}\protected@file@percent }
\newlabel{missing-values-1}{{3.9.1}{80}{Missing Values}{subsection.3.9.1}{}}
\newlabel{imputing-missing-values}{{3.9.1}{81}{Imputing Missing Values}{section*.58}{}}
\@writefile{toc}{\contentsline {subsubsection}{Imputing Missing Values}{81}{section*.58}\protected@file@percent }
\newlabel{alternative-approaches}{{3.9.1}{82}{Alternative Approaches}{section*.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{Alternative Approaches}{82}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.2}Encoding Categorical Variables}{82}{subsection.3.9.2}\protected@file@percent }
\newlabel{encoding-categorical-variables}{{3.9.2}{82}{Encoding Categorical Variables}{subsection.3.9.2}{}}
\newlabel{grouping-native.country-by-continent}{{3.9.2}{82}{\texorpdfstring {Grouping \texttt {native.country} by Continent}{Grouping native.country by Continent}}{section*.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grouping \texttt  {native.country} by Continent}{82}{section*.60}\protected@file@percent }
\newlabel{simplifying-workclass}{{3.9.2}{84}{\texorpdfstring {Simplifying \texttt {workclass}}{Simplifying workclass}}{section*.61}{}}
\@writefile{toc}{\contentsline {subsubsection}{Simplifying \texttt  {workclass}}{84}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.3}Outliers}{84}{subsection.3.9.3}\protected@file@percent }
\newlabel{outliers}{{3.9.3}{84}{Outliers}{subsection.3.9.3}{}}
\newlabel{summary-statistics}{{3.9.3}{84}{Summary Statistics}{section*.62}{}}
\@writefile{toc}{\contentsline {subsubsection}{Summary Statistics}{84}{section*.62}\protected@file@percent }
\newlabel{visualizing-outliers}{{3.9.3}{85}{Visualizing Outliers}{section*.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing Outliers}{85}{section*.63}\protected@file@percent }
\newlabel{zooming-into-the-nonzero-distribution}{{3.9.3}{86}{Zooming into the Nonzero Distribution}{section*.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{Zooming into the Nonzero Distribution}{86}{section*.64}\protected@file@percent }
\newlabel{handling-outliers}{{3.9.3}{87}{Handling Outliers}{section*.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{Handling Outliers}{87}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Exercises}{88}{section.3.10}\protected@file@percent }
\newlabel{exercises-2}{{3.10}{88}{Exercises}{section.3.10}{}}
\newlabel{understanding-data-types}{{3.10}{88}{Understanding Data Types}{section*.66}{}}
\@writefile{toc}{\contentsline {subsection}{Understanding Data Types}{88}{section*.66}\protected@file@percent }
\newlabel{exploring-the-diamonds-dataset}{{3.10}{88}{Exploring the diamonds Dataset}{section*.67}{}}
\@writefile{toc}{\contentsline {subsection}{Exploring the diamonds Dataset}{88}{section*.67}\protected@file@percent }
\newlabel{detecting-and-handling-outliers}{{3.10}{88}{Detecting and Handling Outliers}{section*.68}{}}
\@writefile{toc}{\contentsline {subsection}{Detecting and Handling Outliers}{88}{section*.68}\protected@file@percent }
\newlabel{encoding-categorical-variables-1}{{3.10}{89}{Encoding Categorical Variables}{section*.69}{}}
\@writefile{toc}{\contentsline {subsection}{Encoding Categorical Variables}{89}{section*.69}\protected@file@percent }
\newlabel{analyzing-the-adult-dataset}{{3.10}{89}{Analyzing the Adult Dataset}{section*.70}{}}
\@writefile{toc}{\contentsline {subsection}{Analyzing the Adult Dataset}{89}{section*.70}\protected@file@percent }
\newlabel{feature-engineering-challenge}{{3.10}{89}{Feature Engineering Challenge}{section*.71}{}}
\@writefile{toc}{\contentsline {subsection}{Feature Engineering Challenge}{89}{section*.71}\protected@file@percent }
\newlabel{advanced-data-preparation-challenges}{{3.10}{89}{Advanced Data Preparation Challenges}{section*.72}{}}
\@writefile{toc}{\contentsline {subsection}{Advanced Data Preparation Challenges}{89}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Exploratory Data Analysis}{91}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-EDA}{{4}{91}{Exploratory Data Analysis}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Key Areas of Focus in EDA}{92}{section.4.1}\protected@file@percent }
\newlabel{key-areas-of-focus-in-eda}{{4.1}{92}{Key Areas of Focus in EDA}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Types of EDA Questions}{92}{section.4.2}\protected@file@percent }
\newlabel{types-of-eda-questions}{{4.2}{92}{Types of EDA Questions}{section.4.2}{}}
\citation{neukom2019consistent}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}EDA as Data Storytelling}{93}{section.4.3}\protected@file@percent }
\newlabel{eda-as-data-storytelling}{{4.3}{93}{EDA as Data Storytelling}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Global mean surface temperature history over the Common Era. Temperature anomalies with respect to 1961–1990 CE. The coloured lines represent 30-year low-pass-filtered ensemble medians for the individual reconstruction methods.}}{94}{figure.4.1}\protected@file@percent }
\newlabel{fig:EDA-fig-1}{{4.1}{94}{Global mean surface temperature history over the Common Era. Temperature anomalies with respect to 1961–1990 CE. The coloured lines represent 30-year low-pass-filtered ensemble medians for the individual reconstruction methods}{figure.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}EDA in Practice: Working with the \emph  {Churn} Dataset}{94}{section.4.4}\protected@file@percent }
\newlabel{eda-in-practice-working-with-the-churn-dataset}{{4.4}{94}{\texorpdfstring {EDA in Practice: Working with the \emph {Churn} Dataset}{EDA in Practice: Working with the Churn Dataset}}{section.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Animated scatter plot of fertility rate and life expectancy at birth for different regions of the world from 1960 to 2015.}}{95}{figure.4.2}\protected@file@percent }
\newlabel{fig:EDA-fig-2}{{4.2}{95}{Animated scatter plot of fertility rate and life expectancy at birth for different regions of the world from 1960 to 2015}{figure.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Problem/Business Understanding}{95}{subsection.4.4.1}\protected@file@percent }
\newlabel{problembusiness-understanding}{{4.4.1}{95}{Problem/Business Understanding}{subsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Data Understanding}{95}{subsection.4.4.2}\protected@file@percent }
\newlabel{data-understanding}{{4.4.2}{95}{Data Understanding}{subsection.4.4.2}{}}
\gdef \LT@i {\LT@entry 
    {3}{72.02982pt}\LT@entry 
    {1}{63.39pt}\LT@entry 
    {3}{105.25pt}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Investigating Categorical Variables}{99}{section.4.5}\protected@file@percent }
\newlabel{chapter-EDA-categorical}{{4.5}{99}{Investigating Categorical Variables}{section.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Investigating Numerical Variables}{104}{section.4.6}\protected@file@percent }
\newlabel{EDA-sec-numeric}{{4.6}{104}{Investigating Numerical Variables}{section.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Envestigating Multivarate Relationships}{110}{section.4.7}\protected@file@percent }
\newlabel{EDA-sec-multivariate}{{4.7}{110}{Envestigating Multivarate Relationships}{section.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Investigating Correlated Variables}{114}{subsection.4.7.1}\protected@file@percent }
\newlabel{investigating-correlated-variables}{{4.7.1}{114}{Investigating Correlated Variables}{subsection.4.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Example scatterplots showing different correlation coefficients.}}{115}{figure.4.3}\protected@file@percent }
\newlabel{fig:correlation}{{4.3}{115}{Example scatterplots showing different correlation coefficients}{figure.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Key Findings and Insights}{118}{section.4.8}\protected@file@percent }
\newlabel{key-findings-and-insights}{{4.8}{118}{Key Findings and Insights}{section.4.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Statistical Inference and Hypothesis Testing}{121}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-statistics}{{5}{121}{Statistical Inference and Hypothesis Testing}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Estimation: Using Data to Make Predictions}{122}{section.5.1}\protected@file@percent }
\newlabel{estimation-using-data-to-make-predictions}{{5.1}{122}{Estimation: Using Data to Make Predictions}{section.5.1}{}}
\newlabel{exm:ex-est-churn-proportion}{{5.1}{122}{}{example.5.1}{}}
\newlabel{exm:ex-est-service-call}{{5.2}{122}{}{example.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Quantifying Uncertainty: Confidence Intervals}{123}{section.5.2}\protected@file@percent }
\newlabel{quantifying-uncertainty-confidence-intervals}{{5.2}{123}{Quantifying Uncertainty: Confidence Intervals}{section.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter.}}{124}{figure.5.1}\protected@file@percent }
\newlabel{fig:confidence-interval}{{5.1}{124}{Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter}{figure.5.1}{}}
\newlabel{exm:ex-confidence-service-call}{{5.3}{124}{}{example.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Hypothesis Testing}{125}{section.5.3}\protected@file@percent }
\newlabel{hypothesis-testing}{{5.3}{125}{Hypothesis Testing}{section.5.3}{}}
\gdef \LT@ii {\LT@entry 
    {1}{92.02972pt}\LT@entry 
    {1}{131.1211pt}\LT@entry 
    {1}{121.8149pt}}
\newlabel{tab:hypothesis-errors}{{5.1}{127}{Hypothesis Testing}{table.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{ Possible outcomes of hypothesis testing with two correct decisions and two types of errors.}}{127}{table.5.1}\protected@file@percent }
\gdef \LT@iii {\LT@entry 
    {1}{84.2271pt}\LT@entry 
    {1}{117.19098pt}\LT@entry 
    {1}{143.58192pt}}
\newlabel{tab:hypothesis-test}{{5.2}{128}{Hypothesis Testing}{table.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{ Seven commonly used hypothesis tests, their null hypotheses (\(H_0\)), and the types of variables they apply to.}}{128}{table.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}One-sample T-test}{128}{subsection.5.3.1}\protected@file@percent }
\newlabel{one-sample-t-test}{{5.3.1}{128}{One-sample T-test}{subsection.5.3.1}{}}
\newlabel{exm:ex-one-sample-test}{{5.4}{129}{}{example.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Hypothesis Testing for Proportion}{130}{subsection.5.3.2}\protected@file@percent }
\newlabel{hypothesis-testing-for-proportion}{{5.3.2}{130}{Hypothesis Testing for Proportion}{subsection.5.3.2}{}}
\newlabel{exm:ex-test-proportion}{{5.5}{131}{}{example.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Two-sample T-test}{132}{subsection.5.3.3}\protected@file@percent }
\newlabel{two-sample-t-test}{{5.3.3}{132}{Two-sample T-test}{subsection.5.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Two-Sample Z-test}{135}{subsection.5.3.4}\protected@file@percent }
\newlabel{two-sample-z-test}{{5.3.4}{135}{Two-Sample Z-test}{subsection.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Chi-square Test}{138}{subsection.5.3.5}\protected@file@percent }
\newlabel{chi-square-test}{{5.3.5}{138}{Chi-square Test}{subsection.5.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Analysis of Variance (ANOVA) Test}{140}{subsection.5.3.6}\protected@file@percent }
\newlabel{analysis-of-variance-anova-test}{{5.3.6}{140}{Analysis of Variance (ANOVA) Test}{subsection.5.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.7}Correlation Test}{142}{subsection.5.3.7}\protected@file@percent }
\newlabel{correlation-test}{{5.3.7}{142}{Correlation Test}{subsection.5.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Wrapping Up}{144}{section.5.4}\protected@file@percent }
\newlabel{wrapping-up}{{5.4}{144}{Wrapping Up}{section.5.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Preparing Data for Modeling}{147}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-modeling}{{6}{147}{Preparing Data for Modeling}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Statistical Inference in the Context of Data Science}{148}{section.6.1}\protected@file@percent }
\newlabel{statistical-inference-in-the-context-of-data-science}{{6.1}{148}{Statistical Inference in the Context of Data Science}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Why Is It Necessary to Partition the Data?}{149}{section.6.2}\protected@file@percent }
\newlabel{why-is-it-necessary-to-partition-the-data}{{6.2}{149}{Why Is It Necessary to Partition the Data?}{section.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The trade-off between model complexity and accuracy on the training and test sets. It highlights the optimal model complexity (sweet spot), where the test set accuracy reaches its highest value for unseen data.}}{150}{figure.6.1}\protected@file@percent }
\newlabel{fig:model-complexity}{{6.1}{150}{The trade-off between model complexity and accuracy on the training and test sets. It highlights the optimal model complexity (sweet spot), where the test set accuracy reaches its highest value for unseen data}{figure.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A general predictive machine learning process for building and evaluating models. The 80-20 split ratio is an example and may vary based on the dataset and task.}}{151}{figure.6.2}\protected@file@percent }
\newlabel{fig:modeling}{{6.2}{151}{A general predictive machine learning process for building and evaluating models. The 80-20 split ratio is an example and may vary based on the dataset and task}{figure.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Partitioning the Data}{151}{section.6.3}\protected@file@percent }
\newlabel{sec-partitioning}{{6.3}{151}{Partitioning the Data}{section.6.3}{}}
\gdef \LT@iv {\LT@entry 
    {1}{149.18756pt}\LT@entry 
    {1}{195.81244pt}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Validating the Partition}{153}{section.6.4}\protected@file@percent }
\newlabel{sec-validate-partition}{{6.4}{153}{Validating the Partition}{section.6.4}{}}
\newlabel{tab:partition-test}{{6.1}{153}{Validating the Partition}{table.6.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{ Suggested hypothesis tests for validating partitions, based on the type of target variable.}}{153}{table.6.1}\protected@file@percent }
\newlabel{exm:ex-test-partition}{{6.1}{153}{}{example.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Balancing the Training Dataset}{155}{section.6.5}\protected@file@percent }
\newlabel{balancing-the-training-dataset}{{6.5}{155}{Balancing the Training Dataset}{section.6.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Classification using k-Nearest Neighbors}{159}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-knn}{{7}{159}{Classification using k-Nearest Neighbors}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Classification}{159}{section.7.1}\protected@file@percent }
\newlabel{classification}{{7.1}{159}{Classification}{section.7.1}{}}
\newlabel{where-is-classification-used}{{7.1}{160}{Where Is Classification Used?}{section*.73}{}}
\@writefile{toc}{\contentsline {subsection}{Where Is Classification Used?}{160}{section*.73}\protected@file@percent }
\newlabel{how-does-classification-work}{{7.1}{160}{How Does Classification Work?}{section*.74}{}}
\@writefile{toc}{\contentsline {subsection}{How Does Classification Work?}{160}{section*.74}\protected@file@percent }
\newlabel{which-classification-algorithm-should-you-use}{{7.1}{160}{Which Classification Algorithm Should You Use?}{section*.75}{}}
\@writefile{toc}{\contentsline {subsection}{Which Classification Algorithm Should You Use?}{160}{section*.75}\protected@file@percent }
\newlabel{why-is-classification-important}{{7.1}{161}{Why Is Classification Important?}{section*.76}{}}
\@writefile{toc}{\contentsline {subsection}{Why Is Classification Important?}{161}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}How k-Nearest Neighbors Works}{161}{section.7.2}\protected@file@percent }
\newlabel{how-k-nearest-neighbors-works}{{7.2}{161}{How k-Nearest Neighbors Works}{section.7.2}{}}
\newlabel{how-does-knn-classify-a-new-observation}{{7.2}{162}{How Does kNN Classify a New Observation?}{section*.77}{}}
\@writefile{toc}{\contentsline {subsection}{How Does kNN Classify a New Observation?}{162}{section*.77}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces A two-dimensional toy dataset with two classes (Class A and Class B) and a new data point (dark star), illustrating the k-Nearest Neighbors algorithm with k = 3 and k = 6.}}{162}{figure.7.1}\protected@file@percent }
\newlabel{fig:knn-image}{{7.1}{162}{A two-dimensional toy dataset with two classes (Class A and Class B) and a new data point (dark star), illustrating the k-Nearest Neighbors algorithm with k = 3 and k = 6}{figure.7.1}{}}
\newlabel{strengths-and-limitations-of-knn}{{7.2}{163}{Strengths and Limitations of kNN}{section*.78}{}}
\@writefile{toc}{\contentsline {subsection}{Strengths and Limitations of kNN}{163}{section*.78}\protected@file@percent }
\newlabel{a-practical-example-of-knn-in-action}{{7.2}{163}{A Practical Example of kNN in Action}{section*.79}{}}
\@writefile{toc}{\contentsline {subsection}{A Practical Example of kNN in Action}{163}{section*.79}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Scatter plot of Age vs. Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape.}}{164}{figure.7.2}\protected@file@percent }
\newlabel{fig:scatter-plot-ex-drug}{{7.2}{164}{Scatter plot of Age vs. Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape}{figure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Scatter plot of Age vs. Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape. The three new patients are represented by large orange circles.}}{165}{figure.7.3}\protected@file@percent }
\newlabel{fig:scatter-plot-ex-drug-2}{{7.3}{165}{Scatter plot of Age vs. Sodium/Potassium Ratio for 200 patients, with drug type indicated by color and shape. The three new patients are represented by large orange circles}{figure.7.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Distance Metrics}{165}{section.7.3}\protected@file@percent }
\newlabel{distance-metrics}{{7.3}{165}{Distance Metrics}{section.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Zoom-in plots for the three new patients and their nearest neighbors. The left plot is for Patient 1, the middle plot is for Patient 2, and the right plot is for Patient 3.}}{166}{figure.7.4}\protected@file@percent }
\newlabel{fig:scatter-plot-ex-drug-3}{{7.4}{166}{Zoom-in plots for the three new patients and their nearest neighbors. The left plot is for Patient 1, the middle plot is for Patient 2, and the right plot is for Patient 3}{figure.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Example: Calculating Euclidean Distance}{167}{subsection.7.3.1}\protected@file@percent }
\newlabel{example-calculating-euclidean-distance}{{7.3.1}{167}{Example: Calculating Euclidean Distance}{subsection.7.3.1}{}}
\newlabel{a-note-on-choosing-distance-metrics}{{7.3.1}{167}{A Note on Choosing Distance Metrics}{section*.80}{}}
\@writefile{toc}{\contentsline {subsection}{A Note on Choosing Distance Metrics}{167}{section*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}How to Choose an Optimal \(k\)}{167}{section.7.4}\protected@file@percent }
\newlabel{how-to-choose-an-optimal-k}{{7.4}{167}{\texorpdfstring {How to Choose an Optimal \(k\)}{How to Choose an Optimal k}}{section.7.4}{}}
\newlabel{balancing-overfitting-and-underfitting}{{7.4}{167}{Balancing Overfitting and Underfitting}{section*.81}{}}
\@writefile{toc}{\contentsline {subsection}{Balancing Overfitting and Underfitting}{167}{section*.81}\protected@file@percent }
\newlabel{choosing-k-through-validation}{{7.4}{168}{\texorpdfstring {Choosing \(k\) Through Validation}{Choosing k Through Validation}}{section*.82}{}}
\@writefile{toc}{\contentsline {subsection}{Choosing \(k\) Through Validation}{168}{section*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Preparing Data for kNN}{168}{section.7.5}\protected@file@percent }
\newlabel{preparing-data-for-knn}{{7.5}{168}{Preparing Data for kNN}{section.7.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Accuracy of the k-Nearest Neighbors algorithm for different values of k in the range from 1 to 30.}}{169}{figure.7.5}\protected@file@percent }
\newlabel{fig:kNN-plot}{{7.5}{169}{Accuracy of the k-Nearest Neighbors algorithm for different values of k in the range from 1 to 30}{figure.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Feature Scaling}{169}{subsection.7.5.1}\protected@file@percent }
\newlabel{feature-scaling-1}{{7.5.1}{169}{Feature Scaling}{subsection.7.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Scaling Training and Test Data the Same Way}{170}{subsection.7.5.2}\protected@file@percent }
\newlabel{scaling-training-and-test-data-the-same-way}{{7.5.2}{170}{Scaling Training and Test Data the Same Way}{subsection.7.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}One-Hot Encoding}{171}{subsection.7.5.3}\protected@file@percent }
\newlabel{one-hot-encoding-1}{{7.5.3}{171}{One-Hot Encoding}{subsection.7.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Applying kNN Algorithm in Practice}{173}{section.7.6}\protected@file@percent }
\newlabel{sec-kNN-churn}{{7.6}{173}{Applying kNN Algorithm in Practice}{section.7.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Step 1: Preparing the Data}{174}{subsection.7.6.1}\protected@file@percent }
\newlabel{step-1-preparing-the-data}{{7.6.1}{174}{Step 1: Preparing the Data}{subsection.7.6.1}{}}
\newlabel{one-hot-encoding-2}{{7.6.1}{174}{One-Hot Encoding}{section*.83}{}}
\@writefile{toc}{\contentsline {subsubsection}{One-Hot Encoding}{174}{section*.83}\protected@file@percent }
\newlabel{feature-scaling-2}{{7.6.1}{176}{Feature Scaling}{section*.84}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Scaling}{176}{section*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}Step 2: Choosing an Optimal \(k\)}{176}{subsection.7.6.2}\protected@file@percent }
\newlabel{step-2-choosing-an-optimal-k}{{7.6.2}{176}{\texorpdfstring {Step 2: Choosing an Optimal \(k\)}{Step 2: Choosing an Optimal k}}{subsection.7.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.3}Step 3: Training the Model and Making Predictions}{177}{subsection.7.6.3}\protected@file@percent }
\newlabel{step-3-training-the-model-and-making-predictions}{{7.6.3}{177}{Step 3: Training the Model and Making Predictions}{subsection.7.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.4}Step 4: Evaluating the Model}{178}{subsection.7.6.4}\protected@file@percent }
\newlabel{step-4-evaluating-the-model}{{7.6.4}{178}{Step 4: Evaluating the Model}{subsection.7.6.4}{}}
\newlabel{final-remarks}{{7.6.4}{178}{Final Remarks}{section*.85}{}}
\@writefile{toc}{\contentsline {subsection}{Final Remarks}{178}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Summary}{178}{section.7.7}\protected@file@percent }
\newlabel{summary}{{7.7}{178}{Summary}{section.7.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Exercises}{179}{section.7.8}\protected@file@percent }
\newlabel{exercises-3}{{7.8}{179}{Exercises}{section.7.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Model Evaluation}{181}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-evaluation}{{8}{181}{Model Evaluation}{chapter.8}{}}
\newlabel{why-is-model-evaluation-important}{{8}{181}{Why Is Model Evaluation Important?}{section*.86}{}}
\@writefile{toc}{\contentsline {subsection}{Why Is Model Evaluation Important?}{181}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Confusion Matrix}{182}{section.8.1}\protected@file@percent }
\newlabel{confusion-matrix}{{8.1}{182}{Confusion Matrix}{section.8.1}{}}
\gdef \LT@v {\LT@entry 
    {1}{151.89395pt}\LT@entry 
    {1}{99.53833pt}\LT@entry 
    {1}{93.53833pt}}
\newlabel{tab:confusion-matrix}{{8.1}{183}{Confusion Matrix}{table.8.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{ Confusion matrix summarizing correct and incorrect predictions for binary classification problems. The \textbf  {positive class} refers to the class of interest, while the \textbf  {negative class} represents the other category.}}{183}{table.8.1}\protected@file@percent }
\newlabel{calculating-key-metrics}{{8.1}{183}{Calculating Key Metrics}{section*.87}{}}
\@writefile{toc}{\contentsline {subsection}{Calculating Key Metrics}{183}{section*.87}\protected@file@percent }
\newlabel{exm:ex-confusion-matrix-kNN}{{8.1}{184}{}{example.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Sensitivity and Specificity}{186}{section.8.2}\protected@file@percent }
\newlabel{sensitivity-and-specificity}{{8.2}{186}{Sensitivity and Specificity}{section.8.2}{}}
\newlabel{sensitivity}{{8.2}{186}{Sensitivity}{section*.88}{}}
\@writefile{toc}{\contentsline {subsection}{Sensitivity}{186}{section*.88}\protected@file@percent }
\newlabel{specificity}{{8.2}{187}{Specificity}{section*.89}{}}
\@writefile{toc}{\contentsline {subsection}{Specificity}{187}{section*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Precision, Recall, and F1-Score}{187}{section.8.3}\protected@file@percent }
\newlabel{precision-recall-and-f1-score}{{8.3}{187}{Precision, Recall, and F1-Score}{section.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Taking Uncertainty into Account}{189}{section.8.4}\protected@file@percent }
\newlabel{taking-uncertainty-into-account}{{8.4}{189}{Taking Uncertainty into Account}{section.8.4}{}}
\newlabel{exm:ex-confusion-matrix-kNN-prob}{{8.2}{190}{}{example.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}ROC Curve and AUC}{191}{section.8.5}\protected@file@percent }
\newlabel{roc-curve-and-auc}{{8.5}{191}{ROC Curve and AUC}{section.8.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces The ROC curve illustrates the trade-off between sensitivity and specificity at different thresholds. The diagonal line represents a classifier with no predictive value (gray dashed line), while the curves represent varying levels of performance: green for optimal and blue for good.}}{193}{figure.8.1}\protected@file@percent }
\newlabel{fig:roc-curve}{{8.1}{193}{The ROC curve illustrates the trade-off between sensitivity and specificity at different thresholds. The diagonal line represents a classifier with no predictive value (gray dashed line), while the curves represent varying levels of performance: green for optimal and blue for good}{figure.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces ROC curve for KNN with k = 5, based on churn data.}}{194}{figure.8.2}\protected@file@percent }
\newlabel{fig:roc-knn-churn}{{8.2}{194}{ROC curve for KNN with k = 5, based on churn data}{figure.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces The AUC summarizes the ROC curve into a single number, representing the model’s ability to rank positive cases higher than negative ones. AUC = 1: Perfect model. AUC = 0.5: No better than random guessing.}}{194}{figure.8.3}\protected@file@percent }
\newlabel{fig:auc}{{8.3}{194}{The AUC summarizes the ROC curve into a single number, representing the model’s ability to rank positive cases higher than negative ones. AUC = 1: Perfect model. AUC = 0.5: No better than random guessing}{figure.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}Metrics for Multi-Class Classification}{195}{section.8.6}\protected@file@percent }
\newlabel{metrics-for-multi-class-classification}{{8.6}{195}{Metrics for Multi-Class Classification}{section.8.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Evaluation Metrics for Continuous Targets}{196}{section.8.7}\protected@file@percent }
\newlabel{evaluation-metrics-for-continuous-targets}{{8.7}{196}{Evaluation Metrics for Continuous Targets}{section.8.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.8}Summary}{197}{section.8.8}\protected@file@percent }
\newlabel{summary-1}{{8.8}{197}{Summary}{section.8.8}{}}
\newlabel{key-takeaways}{{8.8}{197}{Key Takeaways}{section*.90}{}}
\@writefile{toc}{\contentsline {subsection}{Key Takeaways}{197}{section*.90}\protected@file@percent }
\newlabel{closing-thoughts}{{8.8}{198}{Closing Thoughts}{section*.91}{}}
\@writefile{toc}{\contentsline {subsection}{Closing Thoughts}{198}{section*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Naive Bayes Classifier}{199}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-bayes}{{9}{199}{Naive Bayes Classifier}{chapter.9}{}}
\newlabel{strengths-and-limitations}{{9}{200}{Strengths and Limitations}{section*.92}{}}
\@writefile{toc}{\contentsline {subsection}{Strengths and Limitations}{200}{section*.92}\protected@file@percent }
\newlabel{what-will-this-chapter-cover}{{9}{200}{What Will This Chapter Cover?}{section*.93}{}}
\@writefile{toc}{\contentsline {subsection}{What Will This Chapter Cover?}{200}{section*.93}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Bayes' Theorem and Probabilistic Foundations}{200}{section.9.1}\protected@file@percent }
\newlabel{bayes-theorem-and-probabilistic-foundations}{{9.1}{200}{Bayes' Theorem and Probabilistic Foundations}{section.9.1}{}}
\newlabel{the-essence-of-bayes-theorem}{{9.1}{201}{The Essence of Bayes' Theorem}{section*.94}{}}
\@writefile{toc}{\contentsline {subsection}{The Essence of Bayes' Theorem}{201}{section*.94}\protected@file@percent }
\newlabel{eq:bayes-theorem}{{9.1}{201}{The Essence of Bayes' Theorem}{equation.9.1.1}{}}
\newlabel{exm:ex-bayes-risk}{{9.1}{201}{}{example.9.1}{}}
\newlabel{eq1}{{9.2}{202}{}{equation.9.1.2}{}}
\newlabel{how-does-bayes-theorem-work}{{9.1}{202}{How Does Bayes' Theorem Work?}{section*.95}{}}
\@writefile{toc}{\contentsline {subsection}{How Does Bayes' Theorem Work?}{202}{section*.95}\protected@file@percent }
\newlabel{a-gateway-to-naive-bayes}{{9.1}{203}{A Gateway to Naive Bayes}{section*.96}{}}
\@writefile{toc}{\contentsline {subsection}{A Gateway to Naive Bayes}{203}{section*.96}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Why is it Called ``Naive''?}{203}{section.9.2}\protected@file@percent }
\newlabel{why-is-it-called-naive}{{9.2}{203}{Why is it Called ``Naive''?}{section.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}The Laplace Smoothing Technique}{204}{section.9.3}\protected@file@percent }
\newlabel{the-laplace-smoothing-technique}{{9.3}{204}{The Laplace Smoothing Technique}{section.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Types of Naive Bayes Classifiers}{206}{section.9.4}\protected@file@percent }
\newlabel{types-of-naive-bayes-classifiers}{{9.4}{206}{Types of Naive Bayes Classifiers}{section.9.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Case Study: Predicting Risk Profiles}{207}{section.9.5}\protected@file@percent }
\newlabel{case-study-predicting-risk-profiles}{{9.5}{207}{Case Study: Predicting Risk Profiles}{section.9.5}{}}
\newlabel{overview-of-the-dataset-1}{{9.5}{207}{Overview of the Dataset}{section*.97}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{207}{section*.97}\protected@file@percent }
\newlabel{data-preparation-1}{{9.5}{207}{Data Preparation}{section*.98}{}}
\@writefile{toc}{\contentsline {subsection}{Data Preparation}{207}{section*.98}\protected@file@percent }
\newlabel{applying-the-naive-bayes-classifier}{{9.5}{208}{Applying the Naive Bayes Classifier}{section*.99}{}}
\@writefile{toc}{\contentsline {subsection}{Applying the Naive Bayes Classifier}{208}{section*.99}\protected@file@percent }
\newlabel{prediction-and-model-evaluation}{{9.5}{211}{Prediction and Model Evaluation}{section*.100}{}}
\@writefile{toc}{\contentsline {subsection}{Prediction and Model Evaluation}{211}{section*.100}\protected@file@percent }
\newlabel{confusion-matrix-1}{{9.5}{212}{Confusion Matrix}{section*.101}{}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion Matrix}{212}{section*.101}\protected@file@percent }
\newlabel{roc-curve-and-auc-1}{{9.5}{213}{ROC Curve and AUC}{section*.102}{}}
\@writefile{toc}{\contentsline {subsubsection}{ROC Curve and AUC}{213}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Exercises}{215}{section.9.6}\protected@file@percent }
\newlabel{exercises-4}{{9.6}{215}{Exercises}{section.9.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Regression Modeling: From Basics to Advanced Techniques}{217}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-regression}{{10}{217}{Regression Modeling: From Basics to Advanced Techniques}{chapter.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Simple Linear Regression}{218}{section.10.1}\protected@file@percent }
\newlabel{sec-simple-regression}{{10.1}{218}{Simple Linear Regression}{section.10.1}{}}
\newlabel{fitting-a-simple-linear-regression-model}{{10.1}{219}{Fitting a Simple Linear Regression Model}{section*.103}{}}
\@writefile{toc}{\contentsline {subsection}{Fitting a Simple Linear Regression Model}{219}{section*.103}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Scatter plot of daily revenue (€) versus daily spend (€) for 40 observations, with the fitted least-squares regression line (blue) showing the linear relationship.}}{220}{figure.10.1}\protected@file@percent }
\newlabel{fig:scoter-plot-simple-reg}{{10.1}{220}{Scatter plot of daily revenue (€) versus daily spend (€) for 40 observations, with the fitted least-squares regression line (blue) showing the linear relationship}{figure.10.1}{}}
\newlabel{estimating-the-model-in-r}{{10.1}{220}{Estimating the Model in R}{section*.104}{}}
\@writefile{toc}{\contentsline {subsection}{Estimating the Model in R}{220}{section*.104}\protected@file@percent }
\newlabel{interpreting-the-regression-line}{{10.1}{221}{Interpreting the Regression Line}{section*.105}{}}
\@writefile{toc}{\contentsline {subsection}{Interpreting the Regression Line}{221}{section*.105}\protected@file@percent }
\newlabel{residuals-and-model-fit}{{10.1}{222}{Residuals and Model Fit}{section*.106}{}}
\@writefile{toc}{\contentsline {subsection}{Residuals and Model Fit}{222}{section*.106}\protected@file@percent }
\newlabel{eq:sse}{{10.1}{222}{Residuals and Model Fit}{equation.10.1.1}{}}
\newlabel{key-insights}{{10.1}{222}{Key Insights}{section*.107}{}}
\@writefile{toc}{\contentsline {subsection}{Key Insights}{222}{section*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Hypothesis Testing in Simple Linear Regression}{223}{section.10.2}\protected@file@percent }
\newlabel{hypothesis-testing-in-simple-linear-regression}{{10.2}{223}{Hypothesis Testing in Simple Linear Regression}{section.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Measuring the Quality of a Regression Model}{225}{section.10.3}\protected@file@percent }
\newlabel{measuring-the-quality-of-a-regression-model}{{10.3}{225}{Measuring the Quality of a Regression Model}{section.10.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Multiple Linear Regression}{227}{section.10.4}\protected@file@percent }
\newlabel{sec-multiple-regression}{{10.4}{227}{Multiple Linear Regression}{section.10.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Generalized Linear Models (GLMs)}{230}{section.10.5}\protected@file@percent }
\newlabel{generalized-linear-models-glms}{{10.5}{230}{Generalized Linear Models (GLMs)}{section.10.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.1}Logistic Regression}{230}{subsection.10.5.1}\protected@file@percent }
\newlabel{logistic-regression}{{10.5.1}{230}{Logistic Regression}{subsection.10.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.2}Logistic Regression in R}{230}{subsection.10.5.2}\protected@file@percent }
\newlabel{logistic-regression-in-r}{{10.5.2}{230}{Logistic Regression in R}{subsection.10.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.3}Poisson Regression}{232}{subsection.10.5.3}\protected@file@percent }
\newlabel{poisson-regression}{{10.5.3}{232}{Poisson Regression}{subsection.10.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.4}Poisson Regression in R}{232}{subsection.10.5.4}\protected@file@percent }
\newlabel{poisson-regression-in-r}{{10.5.4}{232}{Poisson Regression in R}{subsection.10.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Model Selection Using Stepwise Regression}{234}{section.10.6}\protected@file@percent }
\newlabel{sec-stepwise-regression}{{10.6}{234}{Model Selection Using Stepwise Regression}{section.10.6}{}}
\newlabel{exm:ex-stepwise-regression}{{10.1}{235}{}{example.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.7}Extending Linear Models to Capture Non-Linear Relationships}{240}{section.10.7}\protected@file@percent }
\newlabel{extending-linear-models-to-capture-non-linear-relationships}{{10.7}{240}{Extending Linear Models to Capture Non-Linear Relationships}{section.10.7}{}}
\newlabel{the-need-for-non-linear-regression}{{10.7}{240}{The Need for Non-Linear Regression}{section*.108}{}}
\@writefile{toc}{\contentsline {subsection}{The Need for Non-Linear Regression}{240}{section*.108}\protected@file@percent }
\newlabel{fig:scoter-plot-non-reg}{{10.7}{241}{The Need for Non-Linear Regression}{section*.108}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.7.1}Polynomial Regression}{241}{subsection.10.7.1}\protected@file@percent }
\newlabel{polynomial-regression}{{10.7.1}{241}{Polynomial Regression}{subsection.10.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.7.2}Example: Polynomial Regression on the \emph  {House} Dataset}{242}{subsection.10.7.2}\protected@file@percent }
\newlabel{example-polynomial-regression-on-the-house-dataset}{{10.7.2}{242}{\texorpdfstring {Example: Polynomial Regression on the \emph {House} Dataset}{Example: Polynomial Regression on the House Dataset}}{subsection.10.7.2}{}}
\newlabel{fitting-simple-linear-regression}{{10.7.2}{242}{Fitting Simple Linear Regression}{section*.109}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fitting Simple Linear Regression}{242}{section*.109}\protected@file@percent }
\newlabel{fitting-polynomial-regression}{{10.7.2}{243}{Fitting Polynomial Regression}{section*.110}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fitting Polynomial Regression}{243}{section*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.8}Diagnosing and Validating Regression Models}{244}{section.10.8}\protected@file@percent }
\newlabel{diagnosing-and-validating-regression-models}{{10.8}{244}{Diagnosing and Validating Regression Models}{section.10.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.8.1}Example: Diagnosing the Regression Model for the \emph  {Marketing} Dataset}{245}{subsection.10.8.1}\protected@file@percent }
\newlabel{example-diagnosing-the-regression-model-for-the-marketing-dataset}{{10.8.1}{245}{\texorpdfstring {Example: Diagnosing the Regression Model for the \emph {Marketing} Dataset}{Example: Diagnosing the Regression Model for the Marketing Dataset}}{subsection.10.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Diagnostic plots for assessing regression model assumptions.}}{246}{figure.10.2}\protected@file@percent }
\newlabel{fig:model-diagnostics}{{10.2}{246}{Diagnostic plots for assessing regression model assumptions}{figure.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.9}\textbf  {Exercises}}{247}{section.10.9}\protected@file@percent }
\newlabel{exercises-5}{{10.9}{247}{\texorpdfstring {\textbf {Exercises}}{Exercises}}{section.10.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Decision Trees and Random Forests}{249}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-tree}{{11}{249}{Decision Trees and Random Forests}{chapter.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Decision tree for predicting credit risk based on age and income.}}{250}{figure.11.1}\protected@file@percent }
\newlabel{fig:tree-0}{{11.1}{250}{Decision tree for predicting credit risk based on age and income}{figure.11.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}How Decision Trees Work}{250}{section.11.1}\protected@file@percent }
\newlabel{how-decision-trees-work}{{11.1}{250}{How Decision Trees Work}{section.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces A two-dimensional toy dataset (50 observations) with two classes (Class A and Class B), used to illustrate how to build Decision Trees.}}{251}{figure.11.2}\protected@file@percent }
\newlabel{fig:tree-1}{{11.2}{251}{A two-dimensional toy dataset (50 observations) with two classes (Class A and Class B), used to illustrate how to build Decision Trees}{figure.11.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Left: Decision boundary for a tree with depth 1. Right: The corresponding Decision Tree.}}{252}{figure.11.3}\protected@file@percent }
\newlabel{fig:tree-2}{{11.3}{252}{Left: Decision boundary for a tree with depth 1. Right: The corresponding Decision Tree}{figure.11.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Left: Decision boundary for a tree with depth 2. Right: The corresponding Decision Tree.}}{252}{figure.11.4}\protected@file@percent }
\newlabel{fig:tree-3}{{11.4}{252}{Left: Decision boundary for a tree with depth 2. Right: The corresponding Decision Tree}{figure.11.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces Left: Decision boundary for a tree with depth 5. Right: The corresponding Decision Tree.}}{253}{figure.11.5}\protected@file@percent }
\newlabel{fig:tree-4}{{11.5}{253}{Left: Decision boundary for a tree with depth 5. Right: The corresponding Decision Tree}{figure.11.5}{}}
\citation{breiman1984classification}
\citation{breiman1984classification}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Classification and Regression Trees (CART)}{254}{section.11.2}\protected@file@percent }
\newlabel{classification-and-regression-trees-cart}{{11.2}{254}{Classification and Regression Trees (CART)}{section.11.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}The C5.0 Algorithm for Building Decision Trees}{255}{section.11.3}\protected@file@percent }
\newlabel{the-c5.0-algorithm-for-building-decision-trees}{{11.3}{255}{The C5.0 Algorithm for Building Decision Trees}{section.11.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces C5.0 Decision Tree for predicting credit risk based on age and income.}}{257}{figure.11.6}\protected@file@percent }
\newlabel{fig:tree-C50}{{11.6}{257}{C5.0 Decision Tree for predicting credit risk based on age and income}{figure.11.6}{}}
\citation{breiman2001random}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Random Forests: An Ensemble Approach}{258}{section.11.4}\protected@file@percent }
\newlabel{random-forests-an-ensemble-approach}{{11.4}{258}{Random Forests: An Ensemble Approach}{section.11.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Case Study: Who Can Earn More Than \$50K Per Year?}{260}{section.11.5}\protected@file@percent }
\newlabel{tree-case-study}{{11.5}{260}{Case Study: Who Can Earn More Than \$50K Per Year?}{section.11.5}{}}
\newlabel{overview-of-the-dataset-2}{{11.5}{260}{Overview of the Dataset}{section*.111}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{260}{section*.111}\protected@file@percent }
\newlabel{data-cleaning-and-preparation}{{11.5}{261}{Data Cleaning and Preparation}{section*.112}{}}
\@writefile{toc}{\contentsline {subsection}{Data Cleaning and Preparation}{261}{section*.112}\protected@file@percent }
\newlabel{decision-tree-with-cart}{{11.5}{262}{Decision Tree with CART}{section*.113}{}}
\@writefile{toc}{\contentsline {subsection}{Decision Tree with CART}{262}{section*.113}\protected@file@percent }
\newlabel{decision-tree-with-c5.0}{{11.5}{263}{Decision Tree with C5.0}{section*.114}{}}
\@writefile{toc}{\contentsline {subsection}{Decision Tree with C5.0}{263}{section*.114}\protected@file@percent }
\newlabel{random-forest}{{11.5}{264}{Random Forest}{section*.115}{}}
\@writefile{toc}{\contentsline {subsection}{Random Forest}{264}{section*.115}\protected@file@percent }
\newlabel{model-evaluation}{{11.5}{265}{Model Evaluation}{section*.116}{}}
\@writefile{toc}{\contentsline {subsection}{Model Evaluation}{265}{section*.116}\protected@file@percent }
\newlabel{cart}{{11.5}{265}{CART:}{section*.117}{}}
\@writefile{toc}{\contentsline {subsubsection}{CART:}{265}{section*.117}\protected@file@percent }
\newlabel{c5.0}{{11.5}{266}{C5.0:}{section*.118}{}}
\@writefile{toc}{\contentsline {subsubsection}{C5.0:}{266}{section*.118}\protected@file@percent }
\newlabel{random-forest-1}{{11.5}{266}{Random Forest:}{section*.119}{}}
\@writefile{toc}{\contentsline {subsubsection}{Random Forest:}{266}{section*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Exercises}{268}{section.11.6}\protected@file@percent }
\newlabel{exercises-6}{{11.6}{268}{Exercises}{section.11.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Neural Networks: The Building Blocks of Artificial Intelligence}{269}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-nn}{{12}{269}{Neural Networks: The Building Blocks of Artificial Intelligence}{chapter.12}{}}
\newlabel{why-neural-networks-are-powerful}{{12}{270}{Why Neural Networks Are Powerful}{section*.120}{}}
\@writefile{toc}{\contentsline {subsection}{Why Neural Networks Are Powerful}{270}{section*.120}\protected@file@percent }
\newlabel{whats-ahead}{{12}{271}{What's Ahead}{section*.121}{}}
\@writefile{toc}{\contentsline {subsection}{What's Ahead}{271}{section*.121}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Neural Networks: Inspired by Biological Neurons}{271}{section.12.1}\protected@file@percent }
\newlabel{neural-networks-inspired-by-biological-neurons}{{12.1}{271}{Neural Networks: Inspired by Biological Neurons}{section.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Visualization of a biological neuron, which processes input signals through dendrites and sends outputs through the axon.}}{272}{figure.12.1}\protected@file@percent }
\newlabel{fig:net-brain}{{12.1}{272}{Visualization of a biological neuron, which processes input signals through dendrites and sends outputs through the axon}{figure.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Illustration of an artificial neuron, designed to emulate the structure and function of a biological neuron in a simplified way.}}{273}{figure.12.2}\protected@file@percent }
\newlabel{fig:net-1}{{12.2}{273}{Illustration of an artificial neuron, designed to emulate the structure and function of a biological neuron in a simplified way}{figure.12.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}How Neural Networks Work}{273}{section.12.2}\protected@file@percent }
\newlabel{how-neural-networks-work}{{12.2}{273}{How Neural Networks Work}{section.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces A graphical representation of a regression model: input features and predictions are shown as nodes, with the coefficients represented as connections between the nodes.}}{274}{figure.12.3}\protected@file@percent }
\newlabel{fig:net-reg}{{12.3}{274}{A graphical representation of a regression model: input features and predictions are shown as nodes, with the coefficients represented as connections between the nodes}{figure.12.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Visualization of a multilayer neural network model with two hidden layers.}}{274}{figure.12.4}\protected@file@percent }
\newlabel{fig:net-large}{{12.4}{274}{Visualization of a multilayer neural network model with two hidden layers}{figure.12.4}{}}
\newlabel{key-characteristics-of-neural-networks}{{12.2}{275}{Key Characteristics of Neural Networks}{section*.122}{}}
\@writefile{toc}{\contentsline {subsection}{Key Characteristics of Neural Networks}{275}{section*.122}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Activation Functions}{276}{section.12.3}\protected@file@percent }
\newlabel{activation-functions}{{12.3}{276}{Activation Functions}{section.12.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Visualization of the threshold activation function (unit step).}}{276}{figure.12.5}\protected@file@percent }
\newlabel{fig:active-fun-unit}{{12.5}{276}{Visualization of the threshold activation function (unit step)}{figure.12.5}{}}
\newlabel{the-sigmoid-activation-function}{{12.3}{277}{The Sigmoid Activation Function}{section*.123}{}}
\@writefile{toc}{\contentsline {subsection}{The Sigmoid Activation Function}{277}{section*.123}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces Visualization of the sigmoid activation function.}}{277}{figure.12.6}\protected@file@percent }
\newlabel{fig:active-fun-sigmoid}{{12.6}{277}{Visualization of the sigmoid activation function}{figure.12.6}{}}
\newlabel{other-common-activation-functions}{{12.3}{277}{Other Common Activation Functions}{section*.124}{}}
\@writefile{toc}{\contentsline {subsection}{Other Common Activation Functions}{277}{section*.124}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces Comparison of common activation functions: Sigmoid, tanh, and Gaussian.}}{278}{figure.12.7}\protected@file@percent }
\newlabel{fig:active-fun-comparison}{{12.7}{278}{Comparison of common activation functions: Sigmoid, tanh, and Gaussian}{figure.12.7}{}}
\newlabel{choosing-the-right-activation-function}{{12.3}{278}{Choosing the Right Activation Function}{section*.125}{}}
\@writefile{toc}{\contentsline {subsection}{Choosing the Right Activation Function}{278}{section*.125}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Network Architecture}{279}{section.12.4}\protected@file@percent }
\newlabel{network-architecture}{{12.4}{279}{Network Architecture}{section.12.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}How Neural Networks Learn}{281}{section.12.5}\protected@file@percent }
\newlabel{how-neural-networks-learn}{{12.5}{281}{How Neural Networks Learn}{section.12.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Case Study: Bank Marketing}{282}{section.12.6}\protected@file@percent }
\newlabel{case-study-bank-marketing}{{12.6}{282}{Case Study: Bank Marketing}{section.12.6}{}}
\newlabel{business-context}{{12.6}{283}{Business Context}{section*.126}{}}
\@writefile{toc}{\contentsline {subsection}{Business Context}{283}{section*.126}\protected@file@percent }
\newlabel{overview-of-the-dataset-3}{{12.6}{283}{Overview of the Dataset}{section*.127}{}}
\@writefile{toc}{\contentsline {subsection}{Overview of the Dataset}{283}{section*.127}\protected@file@percent }
\newlabel{data-cleaning-and-preparation-1}{{12.6}{284}{Data Cleaning and Preparation}{section*.128}{}}
\@writefile{toc}{\contentsline {subsection}{Data Cleaning and Preparation}{284}{section*.128}\protected@file@percent }
\newlabel{applying-the-neural-network-algorithm}{{12.6}{287}{Applying the Neural Network Algorithm}{section*.129}{}}
\@writefile{toc}{\contentsline {subsection}{Applying the Neural Network Algorithm}{287}{section*.129}\protected@file@percent }
\newlabel{prediction-and-model-evaluation-1}{{12.6}{289}{Prediction and Model Evaluation}{section*.130}{}}
\@writefile{toc}{\contentsline {subsection}{Prediction and Model Evaluation}{289}{section*.130}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Exercises}{290}{section.12.7}\protected@file@percent }
\newlabel{exercises-7}{{12.7}{290}{Exercises}{section.12.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Clustering}{291}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-cluster}{{13}{291}{Clustering}{chapter.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Clustering algorithms aim to minimize intra-cluster variation while maximizing inter-cluster separation.}}{293}{figure.13.1}\protected@file@percent }
\newlabel{fig:cluster-1}{{13.1}{293}{Clustering algorithms aim to minimize intra-cluster variation while maximizing inter-cluster separation}{figure.13.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}K-means Clustering}{293}{section.13.1}\protected@file@percent }
\newlabel{kmeans}{{13.1}{293}{K-means Clustering}{section.13.1}{}}
\citation{arthur2006k}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces A simple dataset with 50 records and two features, ready for clustering.}}{294}{figure.13.2}\protected@file@percent }
\newlabel{fig:cluster-ex-1}{{13.2}{294}{A simple dataset with 50 records and two features, ready for clustering}{figure.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Initial random cluster centers (left) and first cluster assignments (right).}}{295}{figure.13.3}\protected@file@percent }
\newlabel{fig:cluster-ex-2}{{13.3}{295}{Initial random cluster centers (left) and first cluster assignments (right)}{figure.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Updated cluster centers (left) and new assignments after centroid adjustment (right).}}{295}{figure.13.4}\protected@file@percent }
\newlabel{fig:cluster-ex-3}{{13.4}{295}{Updated cluster centers (left) and new assignments after centroid adjustment (right)}{figure.13.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Updated cluster centers and assignments after another iteration.}}{296}{figure.13.5}\protected@file@percent }
\newlabel{fig:cluster-ex-6}{{13.5}{296}{Updated cluster centers and assignments after another iteration}{figure.13.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces Final cluster assignments after K-means convergence.}}{296}{figure.13.6}\protected@file@percent }
\newlabel{fig:cluster-ex-8}{{13.6}{296}{Final cluster assignments after K-means convergence}{figure.13.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Choosing the Number of Clusters}{297}{section.13.2}\protected@file@percent }
\newlabel{kmeans-choose}{{13.2}{297}{Choosing the Number of Clusters}{section.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces The elbow method helps determine the optimal number of clusters in K-means clustering.}}{298}{figure.13.7}\protected@file@percent }
\newlabel{fig:cluster-elbow}{{13.7}{298}{The elbow method helps determine the optimal number of clusters in K-means clustering}{figure.13.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Case Study: Clustering Cereal Data}{299}{section.13.3}\protected@file@percent }
\newlabel{kmeans-cereal}{{13.3}{299}{Case Study: Clustering Cereal Data}{section.13.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Dataset Overview}{299}{subsection.13.3.1}\protected@file@percent }
\newlabel{dataset-overview}{{13.3.1}{299}{Dataset Overview}{subsection.13.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}Data Preprocessing}{300}{subsection.13.3.2}\protected@file@percent }
\newlabel{data-preprocessing}{{13.3.2}{300}{Data Preprocessing}{subsection.13.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.3}Applying K-means Clustering}{303}{subsection.13.3.3}\protected@file@percent }
\newlabel{applying-k-means-clustering}{{13.3.3}{303}{Applying K-means Clustering}{subsection.13.3.3}{}}
\newlabel{choosing-the-optimal-number-of-clusters}{{13.3.3}{303}{Choosing the Optimal Number of Clusters}{section*.131}{}}
\@writefile{toc}{\contentsline {subsubsection}{Choosing the Optimal Number of Clusters}{303}{section*.131}\protected@file@percent }
\newlabel{performing-k-means-clustering}{{13.3.3}{304}{Performing K-means Clustering}{section*.132}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performing K-means Clustering}{304}{section*.132}\protected@file@percent }
\newlabel{visualizing-the-clusters}{{13.3.3}{305}{Visualizing the Clusters}{section*.133}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing the Clusters}{305}{section*.133}\protected@file@percent }
\newlabel{interpreting-the-results}{{13.3.3}{305}{Interpreting the Results}{section*.134}{}}
\@writefile{toc}{\contentsline {subsubsection}{Interpreting the Results}{305}{section*.134}\protected@file@percent }
\bibdata{book.bib,packages.bib}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Exercises}{306}{section.13.4}\protected@file@percent }
\newlabel{exercises-8}{{13.4}{306}{Exercises}{section.13.4}{}}
\bibcite{arthur2006k}{{1}{2006}{{Arthur and Vassilvitskii}}{{}}}
\bibcite{breiman2001random}{{2}{2001}{{Breiman}}{{}}}
\bibcite{breiman1984classification}{{3}{1984}{{Breiman et~al.}}{{}}}
\bibcite{grolemund2014hands}{{4}{2014}{{Grolemund}}{{}}}
\bibcite{neukom2019consistent}{{5}{2019}{{Neukom et~al.}}{{}}}
\gdef \@abspage@last{307}
