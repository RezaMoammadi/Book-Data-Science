<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Data Preparation | Uncovering Data Science with R</title>
<meta name="author" content="Reza Mohammadi">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Chapter 3 Data Preparation | Uncovering Data Science with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://uncovering-data-science.netlify.app/chapter-data-prep.html">
<meta property="og:image" content="https://uncovering-data-science.netlify.app/images/cover.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Data Preparation | Uncovering Data Science with R">
<meta name="twitter:image" content="https://uncovering-data-science.netlify.app/images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Data preparation is a foundational step in any data science project, ensuring that raw data is transformed into a clean and structured format suitable for analysis. This process is often the most...">
<meta property="og:description" content="Data preparation is a foundational step in any data science project, ensuring that raw data is transformed into a clean and structured format suitable for analysis. This process is often the most...">
<meta name="twitter:description" content="Data preparation is a foundational step in any data science project, ensuring that raw data is transformed into a clean and structured format suitable for analysis. This process is often the most...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Uncovering Data Science with R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="chapter-into-R.html"><span class="header-section-number">1</span> The Basics for R</a></li>
<li><a class="" href="chapter-intro-DS.html"><span class="header-section-number">2</span> Introduction to Data Science</a></li>
<li><a class="active" href="chapter-data-prep.html"><span class="header-section-number">3</span> Data Preparation</a></li>
<li><a class="" href="chapter-EDA.html"><span class="header-section-number">4</span> Exploratory Data Analysis</a></li>
<li><a class="" href="chapter-statistics.html"><span class="header-section-number">5</span> Statistical Inference and Hypothesis Testing</a></li>
<li><a class="" href="chapter-modeling.html"><span class="header-section-number">6</span> Preparing Data for Modeling</a></li>
<li><a class="" href="chapter-knn.html"><span class="header-section-number">7</span> Classification using k-Nearest Neighbors</a></li>
<li><a class="" href="chapter-evaluation.html"><span class="header-section-number">8</span> Model Evaluation</a></li>
<li><a class="" href="chapter-bayes.html"><span class="header-section-number">9</span> Naive Bayes Classifier</a></li>
<li><a class="" href="chapter-regression.html"><span class="header-section-number">10</span> Regression Modeling: From Basics to Advanced Techniques</a></li>
<li><a class="" href="chapter-tree.html"><span class="header-section-number">11</span> Decision Trees and Random Forests</a></li>
<li><a class="" href="chapter-nn.html"><span class="header-section-number">12</span> Neural Networks: The Building Blocks of Artificial Intelligence</a></li>
<li><a class="" href="chapter-cluster.html"><span class="header-section-number">13</span> Clustering</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/RezaMoammadi/Book-Data-Science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chapter-data-prep" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Data Preparation<a class="anchor" aria-label="anchor" href="#chapter-data-prep"><i class="fas fa-link"></i></a>
</h1>
<p>Data preparation is a foundational step in any data science project, ensuring that raw data is transformed into a clean and structured format suitable for analysis. This process is often the most time-consuming yet crucial stage, as the quality of data directly influences the accuracy of insights and the effectiveness of predictive models.</p>
<p>This chapter explores key data preparation techniques, including <em>handling missing values</em>, <em>detecting outliers</em>, <em>transforming data</em>, and <em>feature engineering</em>. By the end of this chapter, you will have a clear understanding of how to preprocess raw data, enabling robust statistical modeling and machine learning applications.</p>
<p>To illustrate these concepts, we will use the <em>diamonds</em> dataset from the <strong>ggplot2</strong> package. This dataset contains detailed attributes of diamonds, such as carat, cut, color, clarity, and price, making it an excellent case study for data preprocessing. In this chapter, we focus on the first two steps of the Data Science Workflow—data cleaning and transformation—laying the groundwork for further analysis in subsequent chapters.</p>
<div id="problem-understanding" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Problem Understanding<a class="anchor" aria-label="anchor" href="#problem-understanding"><i class="fas fa-link"></i></a>
</h2>
<p>Before preparing data for analysis, it is essential to define the problem and establish clear objectives. In this case, we aim to analyze the <em>diamonds</em> dataset to gain insights into <em>diamond pricing</em>, a critical factor in industries such as <em>jewelry retail, gemology, and e-commerce</em>. The dataset includes attributes that influence diamond value, allowing us to explore the key factors affecting pricing.</p>
<div id="objectives-and-key-questions" class="section level3 unnumbered">
<h3>Objectives and Key Questions<a class="anchor" aria-label="anchor" href="#objectives-and-key-questions"><i class="fas fa-link"></i></a>
</h3>
<p>Our primary objectives with the <em>diamonds</em> dataset are to:</p>
<ol style="list-style-type: decimal">
<li>
<em>Examine relationships</em> between diamond attributes (e.g., carat, cut, color, clarity) and price.<br>
</li>
<li>
<em>Identify patterns</em> that could improve price estimation.<br>
</li>
<li>
<em>Assess data quality</em>, ensuring consistency and detecting missing values or outliers that may affect analysis.</li>
</ol>
<p>To achieve these objectives, we will address key questions such as:</p>
<ul>
<li>Which attributes have the most significant influence on price?<br>
</li>
<li>Are there pricing trends based on characteristics such as <em>carat weight</em> or <em>cut quality</em>?<br>
</li>
<li>Are there inconsistencies, errors, or missing values that need to be corrected?</li>
</ul>
</div>
<div id="framing-the-problem-as-a-data-science-task" class="section level3 unnumbered">
<h3>Framing the Problem as a Data Science Task<a class="anchor" aria-label="anchor" href="#framing-the-problem-as-a-data-science-task"><i class="fas fa-link"></i></a>
</h3>
<p>From a business perspective, understanding diamond pricing can provide valuable insights for <em>jewelers, e-commerce platforms, and gemologists</em>. From a <em>data science</em> perspective, this problem can be approached in two ways:</p>
<ol style="list-style-type: decimal">
<li>
<em>Predictive modeling</em>: Developing a model that estimates <em>diamond price</em> based on its attributes.<br>
</li>
<li>
<em>Exploratory data analysis (EDA)</em>: Identifying trends and relationships without building a predictive model.</li>
</ol>
<p>Clearly defining these objectives ensures that our data preparation efforts align with the intended analytical approach, whether for exploratory insights or building robust predictive models that generalize well to unseen data. This structured problem framing will guide decisions during data cleaning, transformation, and feature engineering, ensuring that our analysis remains focused and actionable.</p>
</div>
</div>
<div id="diamonds-dataset-overview" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> diamonds Dataset Overview<a class="anchor" aria-label="anchor" href="#diamonds-dataset-overview"><i class="fas fa-link"></i></a>
</h2>
<p>The <em>diamonds</em> dataset, included in the <strong>ggplot2</strong> package, provides structured information on various characteristics of diamonds. Each row represents a unique diamond, with 54,940 entries in total, and contains 10 descriptive variables, including <em>price</em>, <em>carat</em>, <em>cut</em>, <em>clarity</em>, and <em>color</em>. The goal of our analysis is to gain deeper insights into the factors that influence diamond pricing, understand the distribution of data across these attributes, and explore both quantitative and qualitative relationships between variables.</p>
<p>To use the <em>diamonds</em> dataset in <strong>R</strong>, first ensure that the <strong>ggplot2</strong> package is installed. If not, install it using:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"ggplot2"</span><span class="op">)</span> </span></code></pre></div>
<p>Then, load the package and dataset:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>  <span class="co"># Load ggplot2 package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">)</span>    <span class="co"># Load diamonds dataset</span></span></code></pre></div>
<p>To inspect the dataset structure, use:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="chapter-data-prep.html#cb54-1" tabindex="-1"></a><span class="fu">str</span>(diamonds)   </span>
<span id="cb54-2"><a href="chapter-data-prep.html#cb54-2" tabindex="-1"></a>   tibble [<span class="dv">53</span>,<span class="dv">940</span> × <span class="dv">10</span>] (S3<span class="sc">:</span> tbl_df<span class="sc">/</span>tbl<span class="sc">/</span>data.frame)</span>
<span id="cb54-3"><a href="chapter-data-prep.html#cb54-3" tabindex="-1"></a>    <span class="sc">$</span> carat  <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="fl">0.23</span> <span class="fl">0.21</span> <span class="fl">0.23</span> <span class="fl">0.29</span> <span class="fl">0.31</span> <span class="fl">0.24</span> <span class="fl">0.24</span> <span class="fl">0.26</span> <span class="fl">0.22</span> <span class="fl">0.23</span> ...</span>
<span id="cb54-4"><a href="chapter-data-prep.html#cb54-4" tabindex="-1"></a>    <span class="sc">$</span> cut    <span class="sc">:</span> Ord.factor w<span class="sc">/</span> <span class="dv">5</span> levels <span class="st">"Fair"</span><span class="sc">&lt;</span><span class="st">"Good"</span><span class="sc">&lt;</span>..<span class="sc">:</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">3</span> ...</span>
<span id="cb54-5"><a href="chapter-data-prep.html#cb54-5" tabindex="-1"></a>    <span class="sc">$</span> color  <span class="sc">:</span> Ord.factor w<span class="sc">/</span> <span class="dv">7</span> levels <span class="st">"D"</span><span class="sc">&lt;</span><span class="st">"E"</span><span class="sc">&lt;</span><span class="st">"F"</span><span class="sc">&lt;</span><span class="st">"G"</span><span class="sc">&lt;</span>..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">7</span> <span class="dv">6</span> <span class="dv">5</span> <span class="dv">2</span> <span class="dv">5</span> ...</span>
<span id="cb54-6"><a href="chapter-data-prep.html#cb54-6" tabindex="-1"></a>    <span class="sc">$</span> clarity<span class="sc">:</span> Ord.factor w<span class="sc">/</span> <span class="dv">8</span> levels <span class="st">"I1"</span><span class="sc">&lt;</span><span class="st">"SI2"</span><span class="sc">&lt;</span><span class="st">"SI1"</span><span class="sc">&lt;</span>..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">5</span> ...</span>
<span id="cb54-7"><a href="chapter-data-prep.html#cb54-7" tabindex="-1"></a>    <span class="sc">$</span> depth  <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="fl">61.5</span> <span class="fl">59.8</span> <span class="fl">56.9</span> <span class="fl">62.4</span> <span class="fl">63.3</span> <span class="fl">62.8</span> <span class="fl">62.3</span> <span class="fl">61.9</span> <span class="fl">65.1</span> <span class="fl">59.4</span> ...</span>
<span id="cb54-8"><a href="chapter-data-prep.html#cb54-8" tabindex="-1"></a>    <span class="sc">$</span> table  <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="dv">55</span> <span class="dv">61</span> <span class="dv">65</span> <span class="dv">58</span> <span class="dv">58</span> <span class="dv">57</span> <span class="dv">57</span> <span class="dv">55</span> <span class="dv">61</span> <span class="dv">61</span> ...</span>
<span id="cb54-9"><a href="chapter-data-prep.html#cb54-9" tabindex="-1"></a>    <span class="sc">$</span> price  <span class="sc">:</span> int [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="dv">326</span> <span class="dv">326</span> <span class="dv">327</span> <span class="dv">334</span> <span class="dv">335</span> <span class="dv">336</span> <span class="dv">336</span> <span class="dv">337</span> <span class="dv">337</span> <span class="dv">338</span> ...</span>
<span id="cb54-10"><a href="chapter-data-prep.html#cb54-10" tabindex="-1"></a>    <span class="sc">$</span> x      <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="fl">3.95</span> <span class="fl">3.89</span> <span class="fl">4.05</span> <span class="fl">4.2</span> <span class="fl">4.34</span> <span class="fl">3.94</span> <span class="fl">3.95</span> <span class="fl">4.07</span> <span class="fl">3.87</span> <span class="dv">4</span> ...</span>
<span id="cb54-11"><a href="chapter-data-prep.html#cb54-11" tabindex="-1"></a>    <span class="sc">$</span> y      <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="fl">3.98</span> <span class="fl">3.84</span> <span class="fl">4.07</span> <span class="fl">4.23</span> <span class="fl">4.35</span> <span class="fl">3.96</span> <span class="fl">3.98</span> <span class="fl">4.11</span> <span class="fl">3.78</span> <span class="fl">4.05</span> ...</span>
<span id="cb54-12"><a href="chapter-data-prep.html#cb54-12" tabindex="-1"></a>    <span class="sc">$</span> z      <span class="sc">:</span> num [<span class="dv">1</span><span class="sc">:</span><span class="dv">53940</span>] <span class="fl">2.43</span> <span class="fl">2.31</span> <span class="fl">2.31</span> <span class="fl">2.63</span> <span class="fl">2.75</span> <span class="fl">2.48</span> <span class="fl">2.47</span> <span class="fl">2.53</span> <span class="fl">2.49</span> <span class="fl">2.39</span> ...</span></code></pre></div>
<p>This function reveals that the dataset has 53940 observations and 10 variables. Below is a summary of the key attributes:</p>
<ul>
<li>
<code>price</code>: price in US dollars ($326–$18,823).</li>
<li>
<code>carat</code>: weight of the diamond (0.2–5.01).</li>
<li>
<code>cut</code>: quality of the cut (Fair, Good, Very Good, Premium, Ideal).</li>
<li>
<code>color</code>: diamond color, from D (best) to J (worst).</li>
<li>
<code>clarity</code>: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)).</li>
<li>
<code>x</code>: length in mm (0–10.74).</li>
<li>
<code>y</code>: width in mm (0–58.9).</li>
<li>
<code>z</code>: depth in mm (0–31.8).</li>
<li>
<code>depth</code>: total depth percentage = <code>2 * z / (x + y)</code>.</li>
<li>
<code>table</code>: width of the top of the diamond relative to its widest point.</li>
</ul>
<div id="types-of-features-in-the-diamonds-dataset" class="section level3 unnumbered">
<h3>Types of Features in the <code>diamonds</code> Dataset<a class="anchor" aria-label="anchor" href="#types-of-features-in-the-diamonds-dataset"><i class="fas fa-link"></i></a>
</h3>
<p>Understanding the types of features in the dataset is essential for determining the appropriate data preparation steps:</p>
<ol style="list-style-type: decimal">
<li>
<em>Quantitative (or Numerical) Variables</em>: These are represented by numbers and can be continuous or discrete.
<ul>
<li>
<em>Continuous Variables</em>: These variables can take any value within a range. In this dataset, <code>carat</code>, <code>price</code>, <code>x</code>, <code>y</code>, <code>z</code>, and <code>depth</code> are continuous.</li>
<li>
<em>Discrete Variables</em>: These variables take countable values, often integers. For example, a count of customers or the number of purchases would be discrete, though this dataset doesn’t include such a variable.</li>
</ul>
</li>
<li>
<em>Categorical (or Qualitative) Variables</em>: These describe data that fits into categories rather than having a numerical value. They are divided into three types:
<ul>
<li>
<em>Ordinal Variables</em>: Categorical variables with a meaningful order, but where the intervals between categories are not equal. For instance, <code>cut</code>, <code>color</code>, and <code>clarity</code> are ordinal variables in this dataset. The ordering of levels in these variables (e.g., from “Fair” to “Ideal” in <code>cut</code>) has meaning.</li>
<li>
<em>Nominal Variables</em>: Categorical variables without any intrinsic ordering among categories. In other datasets, examples might include “gender” or “product type,” but the <em>diamonds</em> dataset does not contain any nominal variables.</li>
<li>
<em>Binary Variables</em>: Variables with only two levels, often coded as 0 and 1. While the <em>diamonds</em> dataset doesn’t contain binary variables, an example could be a feature like “has_certificate” with values “yes” or “no.”</li>
</ul>
</li>
</ol>
<p>Knowing the type of each feature guides decisions about data preparation. For instance:
- <em>Numerical variables</em> can be normalized or standardized using techniques like Min-Max Scaling or Z-score Scaling.
- <em>Ordinal variables</em> may be encoded using ordinal encoding or one-hot encoding, depending on whether the model should recognize the order.
- <em>Categorical variables</em> without a meaningful order are typically one-hot encoded.</p>
<p>By understanding the types of variables in the <em>diamonds</em> dataset, we can select appropriate transformations and encoding methods to prepare the data effectively for analysis and modeling.</p>
</div>
<div id="key-considerations-for-data-preparation" class="section level3 unnumbered">
<h3>Key Considerations for Data Preparation<a class="anchor" aria-label="anchor" href="#key-considerations-for-data-preparation"><i class="fas fa-link"></i></a>
</h3>
<p>With our objectives in mind, here are the main priorities for preparing this dataset:</p>
<ul>
<li>
<em>Data Quality</em>: Ensure that the data is accurate, consistent, and free from major issues. This involves checking for missing values, outliers, and inconsistencies that could bias our analysis.</li>
<li>
<em>Feature Engineering</em>: Explore the possibility of creating new features to improve predictive accuracy. For instance, calculating <em>volume</em> (using the product of <em>x</em>, <em>y</em>, and <em>z</em> dimensions) could provide an additional measure of a diamond’s size.</li>
<li>
<em>Data Transformation</em>: Ensure that all features are in appropriate formats. Categorical variables like <em>cut</em> and <em>color</em> may need to be converted into numeric codes or dummy variables to work with machine learning algorithms effectively.</li>
</ul>
</div>
</div>
<div id="Data-pre-outliers" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Outliers<a class="anchor" aria-label="anchor" href="#Data-pre-outliers"><i class="fas fa-link"></i></a>
</h2>
<p>Outliers are data points that significantly deviate from the general distribution of a dataset. They can arise due to measurement variability, data entry errors, or genuinely unique observations. Identifying and handling outliers is crucial, as they can skew statistical analyses, affect model performance, and lead to misleading insights.</p>
<p>Outliers play a critical role in multiple industries:</p>
<ul>
<li>
<em>Finance</em>: Outliers in transaction data can indicate fraud. Detecting unusually high spending patterns is key to fraud detection models.</li>
<li>
<em>Healthcare</em>: Medical records often contain anomalous lab results, which may indicate rare diseases or measurement errors.</li>
<li>
<em>Manufacturing</em>: Sensors in factories may detect equipment failures through unusual temperature spikes.</li>
</ul>
<p>In many cases, outliers are not errors but signals of important events. Understanding their role in data analysis ensures that we don’t remove valuable insights unintentionally.</p>
<div id="identifying-outliers-using-visualization-techniques" class="section level3 unnumbered">
<h3>Identifying Outliers Using Visualization Techniques<a class="anchor" aria-label="anchor" href="#identifying-outliers-using-visualization-techniques"><i class="fas fa-link"></i></a>
</h3>
<div id="boxplots-detecting-extreme-values" class="section level4 unnumbered">
<h4>Boxplots: Detecting Extreme Values<a class="anchor" aria-label="anchor" href="#boxplots-detecting-extreme-values"><i class="fas fa-link"></i></a>
</h4>
<p>Boxplots are a visual tool for detecting extreme values. Below is a boxplot of the <code>y</code> variable (diamond width) by using the <strong>ggplot()</strong> and <code><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot()</a></code> functions from the <strong>ggplot2</strong> package:</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Here, boxplots highlight values beyond the whiskers, which may indicate potential outliers. Since diamonds cannot have a width of 0 mm, values like 32 mm or 59 mm likely result from data entry errors.</p>
</div>
<div id="histograms-understanding-outlier-distribution" class="section level4 unnumbered">
<h4>Histograms: Understanding Outlier Distribution<a class="anchor" aria-label="anchor" href="#histograms-understanding-outlier-distribution"><i class="fas fa-link"></i></a>
</h4>
<p>Histograms provide another visual approach to detecting outliers by displaying the frequency distribution of values. Below is a histogram of the <code>y</code> variable by using the <em>ggplot()</em> and <em>geom_histogram()</em> functions:</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, binwidth <span class="op">=</span> <span class="fl">0.5</span>, color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>To enhance visibility, we can zoom in on smaller frequencies by using the <em>coord_cartesian()</em> function from the <strong>ggplot2</strong> package:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, binwidth <span class="op">=</span> <span class="fl">0.5</span>, color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">30</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-6-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Other useful visualization techniques include:</p>
<ul>
<li>Violin plots – Show both outliers and density distributions.</li>
<li>Density plots – Provide smoother insights into rare values and multimodal distributions.</li>
</ul>
</div>
</div>
<div id="handling-outliers-best-practices" class="section level3 unnumbered">
<h3>Handling Outliers: Best Practices<a class="anchor" aria-label="anchor" href="#handling-outliers-best-practices"><i class="fas fa-link"></i></a>
</h3>
<p>Once outliers are identified, there are several strategies for handling them:</p>
<ol style="list-style-type: decimal">
<li>
<em>Removing outliers</em>: This is appropriate when an outlier is clearly an error (e.g., negative height, duplicate data entry).</li>
<li>
<em>Transforming values</em>: Techniques such as log transformation or square root scaling can reduce the influence of extreme values while preserving trends.</li>
<li>
<em>Winsorization</em>: Instead of removing outliers, replace them with the nearest percentile-based value (e.g., capping extreme values at the 95th percentile).</li>
<li>
<em>Using robust statistical methods</em>: Some algorithms, like median-based regression or random forests, are less sensitive to outliers.</li>
<li>
<em>Treating outliers as a separate category</em>: In fraud detection or rare event prediction, outliers may contain valuable insights and should not be removed.</li>
</ol>
<p>Choosing the right strategy depends on the context of the analysis and the potential impact of the outlier.</p>
</div>
<div id="expanded-code-example-handling-outliers-in-r" class="section level3 unnumbered">
<h3>Expanded Code Example: Handling Outliers in R<a class="anchor" aria-label="anchor" href="#expanded-code-example-handling-outliers-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>After detecting outliers, we can choose to either replace them with <code>NA</code> values or remove them. For this, we could consider using the <code>mutate()</code> function from the <strong>dplyr</strong> package. Here’s an example of treating outliers as missing values using <code>mutate()</code> and <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code>:</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">diamonds_2</span> <span class="op">&lt;-</span> <span class="fu">mutate</span><span class="op">(</span><span class="va">diamonds</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">y</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">y</span> <span class="op">&gt;</span> <span class="fl">30</span>, <span class="cn">NA</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Here’s how to verify the update:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="chapter-data-prep.html#cb59-1" tabindex="-1"></a><span class="fu">summary</span>(diamonds_2<span class="sc">$</span>y)</span>
<span id="cb59-2"><a href="chapter-data-prep.html#cb59-2" tabindex="-1"></a>      Min. <span class="dv">1</span>st Qu.  Median    Mean <span class="dv">3</span>rd Qu.    Max.    NA<span class="st">'s </span></span>
<span id="cb59-3"><a href="chapter-data-prep.html#cb59-3" tabindex="-1"></a><span class="st">     3.680   4.720   5.710   5.734   6.540  10.540       9</span></span></code></pre></div>
<p>This method ensures that outliers do not distort the dataset while allowing for further imputation or analysis.</p>
</div>
</div>
<div id="missing-values" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Missing Values<a class="anchor" aria-label="anchor" href="#missing-values"><i class="fas fa-link"></i></a>
</h2>
<p>Missing values pose significant challenges in data analysis, as they can lead to biased results, reduce statistical power, and impact the performance of machine learning models. When handling missing data, we typically consider two approaches:</p>
<ol style="list-style-type: decimal">
<li>Imputation: Replacing missing values with estimated values to retain data integrity.<br>
</li>
<li>Removal: Deleting records with missing values, though this may lead to data loss and potential bias.</li>
</ol>
<div id="imputation-techniques" class="section level3 unnumbered">
<h3>Imputation Techniques<a class="anchor" aria-label="anchor" href="#imputation-techniques"><i class="fas fa-link"></i></a>
</h3>
<p>There are several strategies for imputing missing values, each with different use cases:</p>
<ul>
<li>Mean, median, or mode imputation: Replaces missing values with the mean, median, or mode of the corresponding column.<br>
</li>
<li>Random sampling: Fills missing values with random observations drawn from the existing data distribution.<br>
</li>
<li>Predictive imputation: Uses machine learning models such as regression or k-nearest neighbors to estimate missing values.<br>
</li>
<li>Multiple imputation: Generates several possible values for missing entries and averages the results to reduce uncertainty.<br>
### Example: Random Sampling Imputation in R {-}</li>
</ul>
<p>To impute missing values in <code>y</code> using random sampling, we use the <code><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute()</a></code> function from the <strong>Hmisc</strong> package:</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">diamonds_2</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">impute</span><span class="op">(</span><span class="va">diamonds_2</span><span class="op">$</span><span class="va">y</span>, <span class="st">"random"</span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute()</a></code> function replaces missing values with randomly sampled values from the existing distribution of <code>y</code>, maintaining the overall statistical properties of the dataset.</p>
</div>
<div id="best-practices" class="section level3 unnumbered">
<h3>Best Practices<a class="anchor" aria-label="anchor" href="#best-practices"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Use mean or median imputation for numerical variables when the missing values are missing at random (MAR).<br>
</li>
<li>Use mode imputation for categorical variables.<br>
</li>
<li>Consider predictive models when the dataset is large and missing values are not completely random.<br>
</li>
<li>Always assess the proportion of missing data—if too many values are missing, removing the variable may be a better approach than imputation.</li>
</ul>
</div>
</div>
<div id="feature-scaling" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Feature Scaling<a class="anchor" aria-label="anchor" href="#feature-scaling"><i class="fas fa-link"></i></a>
</h2>
<p>Feature scaling, also known as normalization or standardization, is a crucial step in data preprocessing. It adjusts the range and distribution of numerical features so they are on a similar scale. Many machine learning algorithms, especially those based on distance metrics such as k-nearest neighbors, benefit significantly from scaled input features, as this prevents variables with larger ranges from disproportionately influencing the model’s outcome.</p>
<p>For instance, in the <em>diamonds</em> dataset, the <code>carat</code> variable ranges from 0.2 to 5, while <code>price</code> ranges from 326 to 18823. Without scaling, variables like <code>price</code> with a wider range can dominate the model’s predictions, potentially leading to suboptimal results. To address this, we apply feature scaling techniques to bring all numeric variables onto a comparable scale. In this section, we explore two common scaling methods:</p>
<ol style="list-style-type: decimal">
<li>
<em>Min-Max Scaling</em>: Also known as min-max normalization or min-max transformation.</li>
<li>
<em>Z-score Scaling</em>: Also known as standardization or Z-score normalization.</li>
</ol>
<p>Feature scaling provides several benefits:</p>
<ul>
<li>
<em>Improved Model Performance</em>: Ensures that features contribute equally to the model, preventing features with larger numerical ranges from dominating learning algorithms.</li>
<li>
<em>Better Model Convergence</em>: Particularly useful for gradient-based optimization methods such as logistic regression and neural networks.</li>
<li>
<em>More Effective Distance-Based Learning</em>: Algorithms such as k-means clustering and support vector machines rely on distance calculations, making feature scaling essential.</li>
<li>
<em>Consistent Feature Interpretation</em>: By standardizing numerical values, models become easier to compare and interpret.</li>
</ul>
<p>However, feature scaling also has some drawbacks:</p>
<ul>
<li>
<em>Potential Loss of Information</em>: In some cases, scaling can obscure meaningful differences between data points.</li>
<li>
<em>Impact on Outliers</em>: Min-max scaling, in particular, is sensitive to extreme values, which can distort the scaled representation.</li>
<li>
<em>Additional Computation</em>: Scaling adds preprocessing overhead, particularly when working with large datasets.</li>
<li>
<em>Reduced Interpretability</em>: The original units of measurement are lost, making it harder to relate scaled values to real-world meanings.</li>
</ul>
<p>Selecting the right scaling method depends on the characteristics of the data and the requirements of the model. In the next sections, we will explore these methods in more detail and apply them to the <em>diamonds</em> dataset.</p>
</div>
<div id="min-max-scaling" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Min-Max Scaling<a class="anchor" aria-label="anchor" href="#min-max-scaling"><i class="fas fa-link"></i></a>
</h2>
<p>Min-Max Scaling transforms the values of a feature to a fixed range, typically <span class="math inline">\([0, 1]\)</span>. This transformation ensures that the minimum value of each feature becomes 0 and the maximum value becomes 1. It is especially useful for algorithms that rely on distance metrics, as it equalizes the contributions of all features, making comparisons more balanced.</p>
<p>The formula for Min-Max Scaling is:</p>
<p><span class="math display">\[
x_{\text{scaled}} = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}},
\]</span>
where <span class="math inline">\(x\)</span> is the original feature value, <span class="math inline">\(x_{\text{min}}\)</span> and <span class="math inline">\(x_{\text{max}}\)</span> are the minimum and maximum values of the feature, and <span class="math inline">\(x_{\text{scaled}}\)</span> is the scaled value, ranging between 0 and 1.</p>
<p>Min-Max Scaling is particularly useful for models that require bounded input values, such as neural networks and algorithms relying on gradient-based optimization. However, this method is sensitive to outliers, as extreme values significantly affect the scaled distribution.</p>
<div class="example">
<p><span id="exm:ex-min-max" class="example"><strong>Example 3.1  </strong></span>To demonstrate Min-Max Scaling, we’ll apply it to the <code>carat</code> variable in the <em>diamonds</em> dataset, where <code>carat</code> values range from approximately 0.2 to 5. Using the <code><a href="https://rdrr.io/pkg/liver/man/minmax.html">minmax()</a></code> function from the <strong>liver</strong> package, we can scale <code>carat</code> values to fit within the range [0, 1].</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                 color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Histogram for `carat` without scaling"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Values for variable `carat`"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/liver/man/minmax.html">minmax</a></span><span class="op">(</span><span class="va">carat</span><span class="op">)</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                 color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Histogram for `carat` with Min-Max Scaling"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Values for variable `carat`"</span><span class="op">)</span></span></code></pre></div>
<p><img src="data-preparation_files/figure-html/unnamed-chunk-10-1.png" width="50%"><img src="data-preparation_files/figure-html/unnamed-chunk-10-2.png" width="50%"></p>
<p>The first histogram (left) shows the distribution of <code>carat</code> without scaling, while the second histogram (right) shows it after Min-Max Scaling. After scaling, the <code>carat</code> values are compressed to a range between 0 and 1, allowing it to be more comparable to other features that may have different original scales. This scaling method is particularly beneficial for distance-based algorithms, as it prevents features with wider ranges from having undue influence.</p>
</div>
</div>
<div id="z-score-scaling" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> Z-score Scaling<a class="anchor" aria-label="anchor" href="#z-score-scaling"><i class="fas fa-link"></i></a>
</h2>
<p>Z-score Scaling, also known as standardization, transforms feature values so they have a mean of 0 and a standard deviation of 1. This method is particularly useful for algorithms that assume normally distributed data, such as linear regression and logistic regression, because it centers the data around 0 and normalizes the spread of values.</p>
<p>The formula for Z-score Scaling is:</p>
<p><span class="math display">\[
x_{\text{scaled}} = \frac{x - \text{mean}(x)}{\text{sd}(x)}
\]</span></p>
<p>where <span class="math inline">\(x\)</span> is the original feature value, <span class="math inline">\(\text{mean}(x)\)</span> is the mean of the feature, <span class="math inline">\(\text{sd}(x)\)</span> is the standard deviation of the feature, and <span class="math inline">\(x_{\text{scaled}}\)</span> is the standardized value, now having a mean of 0 and a standard deviation of 1.</p>
<p>Z-score Scaling is particularly beneficial for models that assume normality or use gradient-based optimization, ensuring that all numerical features contribute equally. However, since it relies on mean and standard deviation, it is <strong>sensitive to outliers</strong>, which can distort the transformation.</p>
<div class="example">
<p><span id="exm:ex-zscore" class="example"><strong>Example 3.2  </strong></span>Applying Z-score Scaling to the <code>carat</code> variable in the <em>diamonds</em> dataset, where the mean and standard deviation of <code>carat</code> are approximately 0.8 and 0.47, respectively. We use the <code><a href="https://rdrr.io/pkg/liver/man/zscore.html">zscore()</a></code> function from the <strong>liver</strong> package to standardize these values.</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                 color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Histogram for `carat` without scaling"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Values for variable `carat`"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/liver/man/zscore.html">zscore</a></span><span class="op">(</span><span class="va">carat</span><span class="op">)</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                 color <span class="op">=</span> <span class="st">'blue'</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Histogram for `carat` with Z-score Scaling"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Values for variable `carat`"</span><span class="op">)</span></span></code></pre></div>
<p><img src="data-preparation_files/figure-html/unnamed-chunk-11-1.png" width="50%"><img src="data-preparation_files/figure-html/unnamed-chunk-11-2.png" width="50%"></p>
<p>The first histogram (left) displays the distribution of <code>carat</code> without scaling, while the second histogram (right) shows the distribution after Z-score Scaling. This transformation makes feature values comparable across different scales and ensures that each feature contributes equally to distance-based computations and model training.</p>
</div>
<blockquote>
<p>Note: A common misconception is that after Z-score Scaling, the data follows a standard normal distribution. While Z-score Scaling centers the data to a mean of 0 and scales it to a standard deviation of 1, it does not alter the shape of the distribution. If the original distribution is skewed, it will remain skewed after scaling, as seen in the histograms above.</p>
</blockquote>
<p>The choice between Min-Max Scaling and Z-score Scaling depends on the requirements of the model and the characteristics of the data. Min-Max Scaling is preferable for algorithms that require a fixed input range, while Z-score Scaling is better suited for models that assume normally distributed features. By selecting the appropriate scaling method, we ensure balanced feature contributions and improved model performance.</p>
</div>
<div id="how-to-reexpress-categorical-field-values" class="section level2" number="3.8">
<h2>
<span class="header-section-number">3.8</span> How to Reexpress Categorical Field Values<a class="anchor" aria-label="anchor" href="#how-to-reexpress-categorical-field-values"><i class="fas fa-link"></i></a>
</h2>
<p>In data science, categorical features often need to be transformed into a numeric format before they can be used in machine learning models. Algorithms like decision trees, neural networks, and linear regression require numeric inputs to process the data effectively. Converting categorical variables into numerical representations ensures that all features contribute appropriately to the model, rather than being ignored or treated incorrectly.</p>
<p>This process of reexpressing categorical values is a crucial part of data preparation, as it enables us to leverage the full range of features in our dataset. In this section, we explore several methods to convert categorical fields into numeric representations, with a focus on techniques like one-hot encoding and ordinal encoding. We demonstrate these techniques using the <em>diamonds</em> dataset, which includes several categorical features such as <code>cut</code>, <code>color</code>, and <code>clarity</code>.</p>
<div id="why-reexpress-categorical-fields" class="section level3" number="3.8.1">
<h3>
<span class="header-section-number">3.8.1</span> Why Reexpress Categorical Fields?<a class="anchor" aria-label="anchor" href="#why-reexpress-categorical-fields"><i class="fas fa-link"></i></a>
</h3>
<p>Categorical fields, also known as nominal or ordinal variables, often represent qualitative aspects of data, such as product types, user locations, or levels of satisfaction. In the <em>diamonds</em> dataset, for example:</p>
<ul>
<li>
<code>cut</code> indicates the quality of the diamond’s cut (e.g., “Fair,” “Good,” “Very Good,” “Premium,” “Ideal”).</li>
<li>
<code>color</code> represents the diamond’s color grade (e.g., “D,” “E,” “F,” with “D” being the most colorless and thus most valuable).</li>
<li>
<code>clarity</code> describes the diamond’s clarity, reflecting the absence of internal or external flaws.</li>
</ul>
<p>These fields are essential for understanding and predicting diamond pricing, but in their raw form as text labels, they are not suitable for most machine learning algorithms. Transforming them into numeric form allows us to include these valuable insights in our analysis.</p>
</div>
<div id="techniques-for-reexpressing-categorical-variables" class="section level3" number="3.8.2">
<h3>
<span class="header-section-number">3.8.2</span> Techniques for Reexpressing Categorical Variables<a class="anchor" aria-label="anchor" href="#techniques-for-reexpressing-categorical-variables"><i class="fas fa-link"></i></a>
</h3>
<p>There are several approaches to converting categorical variables into numeric representations. The method we choose depends on the type of categorical variable and the nature of the data.</p>
<div id="ordinal-encoding" class="section level4 unnumbered">
<h4>Ordinal Encoding<a class="anchor" aria-label="anchor" href="#ordinal-encoding"><i class="fas fa-link"></i></a>
</h4>
<p>Ordinal encoding is suitable when the categorical variable has a meaningful order. For example, the <code>cut</code> feature in the <em>diamonds</em> dataset is ordinal, as there is a natural hierarchy from “Fair” to “Ideal.” In ordinal encoding, each category is assigned a unique integer based on its rank or level of importance.</p>
<p>In this example, we might assign values as follows:</p>
<ul>
<li>“Fair” → 1</li>
<li>“Good” → 2</li>
<li>“Very Good” → 3</li>
<li>“Premium” → 4</li>
<li>“Ideal” → 5</li>
</ul>
<p>This approach preserves the order of the categories, which can be useful in models that interpret numeric values in a relative way, such as linear regression. However, it is important to apply ordinal encoding only when the order is meaningful. For non-ordinal variables, other methods like one-hot encoding are more appropriate.</p>
</div>
<div id="one-hot-encoding" class="section level4 unnumbered">
<h4>One-Hot Encoding<a class="anchor" aria-label="anchor" href="#one-hot-encoding"><i class="fas fa-link"></i></a>
</h4>
<p>One-hot encoding is the preferred technique for nominal variables—categorical fields without an intrinsic order. In this approach, each unique category in a field is transformed into a new binary (0 or 1) feature. This method is particularly useful for variables like <code>color</code> and <code>clarity</code> in the <em>diamonds</em> dataset, where the categories do not follow a clear sequence.</p>
<p>For example, if we one-hot encode the <code>color</code> feature, we create a set of binary columns, one for each color grade:</p>
<ul>
<li>
<code>color_D</code>: 1 if the diamond color is “D,” 0 otherwise.</li>
<li>
<code>color_E</code>: 1 if the diamond color is “E,” 0 otherwise.</li>
<li>
<code>color_F</code>: 1 if the diamond color is “F,” 0 otherwise.</li>
</ul>
<p>One-hot encoding avoids introducing false ordinal relationships, ensuring that the model treats each category as an independent entity. However, one downside is that it can significantly increase the dimensionality of the dataset if the categorical field has many unique values.</p>
<blockquote>
<p>Note: Many machine learning libraries automatically drop one of the binary columns to avoid multicollinearity (perfect correlation among features). For instance, if we have seven color categories, only six binary columns are created, and the missing category is implied when all columns are zero. This approach, known as dummy encoding, helps avoid redundancy and keeps the model simpler.</p>
</blockquote>
</div>
<div id="frequency-encoding" class="section level4 unnumbered">
<h4>Frequency Encoding<a class="anchor" aria-label="anchor" href="#frequency-encoding"><i class="fas fa-link"></i></a>
</h4>
<p>Another useful approach, especially for high-cardinality categorical variables (those with many unique values), is frequency encoding. This technique replaces each category with its frequency in the dataset, allowing the model to capture information about how common each category is. Frequency encoding can be particularly helpful for fields like <code>clarity</code> if you want to give the model an indication of how prevalent each level is.</p>
<p>For example:</p>
<ul>
<li>If “VS2” appears 10,000 times in the dataset, it would be encoded as 10,000.</li>
<li>If “IF” appears only 500 times, it would be encoded as 500.</li>
</ul>
<p>Frequency encoding is less commonly used in basic machine learning workflows but can be valuable when dealing with very large datasets, or when one-hot encoding would introduce too many columns. However, be cautious with this approach, as it may inadvertently add an implicit weight to more common categories.</p>
</div>
</div>
<div id="choosing-the-right-encoding-technique" class="section level3" number="3.8.3">
<h3>
<span class="header-section-number">3.8.3</span> Choosing the Right Encoding Technique<a class="anchor" aria-label="anchor" href="#choosing-the-right-encoding-technique"><i class="fas fa-link"></i></a>
</h3>
<p>Selecting the appropriate encoding technique depends on the nature of your categorical variable and the requirements of your analysis:</p>
<ul>
<li>Ordinal variables (like <code>cut</code>): Use ordinal encoding to preserve the natural order.</li>
<li>Nominal variables with few unique values (like <code>color</code> and <code>clarity</code>): Use one-hot encoding to represent each category as a binary column.</li>
<li>High-cardinality categorical variables: Consider frequency encoding if one-hot encoding would introduce too many features.</li>
</ul>
<div class="example">
<p><span id="exm:ex-encoding" class="example"><strong>Example 3.3  </strong></span>Applying these techniques to the <em>diamonds</em> dataset:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example: Ordinal encoding for `cut`</span></span>
<span><span class="va">diamonds</span> <span class="op">&lt;-</span> <span class="va">diamonds</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>cut_encoded <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">cut</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Fair"</span>, <span class="st">"Good"</span>, <span class="st">"Very Good"</span>, <span class="st">"Premium"</span>, <span class="st">"Ideal"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Example: One-hot encoding for `color`</span></span>
<span><span class="va">diamonds</span> <span class="op">&lt;-</span> <span class="va">diamonds</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    color_D <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"D"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_E <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"E"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_F <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"F"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_G <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"G"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_H <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"H"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_I <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"I"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>    color_J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">color</span> <span class="op">==</span> <span class="st">"J"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>In this example:</p>
<ul>
<li>Ordinal Encoding: We have encoded the <code>cut</code> variable based on its quality hierarchy.</li>
<li>One-Hot Encoding: We have applied one-hot encoding to <code>color</code>, creating binary columns for each color grade.</li>
</ul>
</div>
<p>By encoding the categorical fields in this way, we transform the dataset into a format compatible with most machine learning algorithms while preserving the essential information about each categorical feature.</p>
<p>With our dataset now cleaned, scaled, and encoded, we are ready to move into the next stage of data analysis. In the upcoming chapter, we will explore Exploratory Data Analysis (EDA), where we will use visualizations and summary statistics to gain insights into the structure and relationships within the data. By combining the prepared data with EDA techniques, we can better understand which features may hold predictive value for our model and set the stage for successful machine learning outcomes.</p>
</div>
</div>
<div id="Data-pre-adult" class="section level2" number="3.9">
<h2>
<span class="header-section-number">3.9</span> Case Study: Who Can Earn More Than $50K Per Year?<a class="anchor" aria-label="anchor" href="#Data-pre-adult"><i class="fas fa-link"></i></a>
</h2>
<p>In this case study, we will explore the <em>Adult</em> dataset, sourced from the <a href="https://www.census.gov">US Census Bureau</a>. This dataset contains demographic information about individuals, including age, education, occupation, and income. The dataset is available in the <strong>liver</strong> package. For more details, refer to the <a href="https://www.rdocumentation.org/packages/liver/versions/1.3/topics/adult">documentation</a>.</p>
<p>The goal of this study is to predict whether an individual earns more than $50,000 per year based on their attributes. In Section <a href="chapter-tree.html#tree-case-study">11.5</a> of Chapter <a href="chapter-tree.html#chapter-tree">11</a>, we will apply decision tree and random forest algorithms to build a predictive model. Before applying these techniques, we need to preprocess the dataset by handling missing values, encoding categorical variables, and scaling numerical features. Let’s begin by loading the dataset and examining its structure.</p>
<div id="overview-of-the-dataset" class="section level3 unnumbered">
<h3>Overview of the Dataset<a class="anchor" aria-label="anchor" href="#overview-of-the-dataset"><i class="fas fa-link"></i></a>
</h3>
<p>To use the <em>Adult</em> dataset, first ensure that the <strong>liver</strong> package is installed. If not, install it using:</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"liver"</span><span class="op">)</span></span></code></pre></div>
<p>Next, load the package and dataset:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.uva.nl/profile/a.mohammadi">liver</a></span><span class="op">)</span>  <span class="co"># Load liver package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">adult</span><span class="op">)</span>     <span class="co"># Load Adult dataset</span></span></code></pre></div>
<p>To inspect the dataset structure, use:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="chapter-data-prep.html#cb66-1" tabindex="-1"></a><span class="fu">str</span>(adult)</span>
<span id="cb66-2"><a href="chapter-data-prep.html#cb66-2" tabindex="-1"></a>   <span class="st">'data.frame'</span><span class="sc">:</span>    <span class="dv">48598</span> obs. of  <span class="dv">15</span> variables<span class="sc">:</span></span>
<span id="cb66-3"><a href="chapter-data-prep.html#cb66-3" tabindex="-1"></a>    <span class="er">$</span> age           <span class="sc">:</span> int  <span class="dv">25</span> <span class="dv">38</span> <span class="dv">28</span> <span class="dv">44</span> <span class="dv">18</span> <span class="dv">34</span> <span class="dv">29</span> <span class="dv">63</span> <span class="dv">24</span> <span class="dv">55</span> ...</span>
<span id="cb66-4"><a href="chapter-data-prep.html#cb66-4" tabindex="-1"></a>    <span class="sc">$</span> workclass     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">6</span> levels <span class="st">"?"</span>,<span class="st">"Gov"</span>,<span class="st">"Never-worked"</span>,..<span class="sc">:</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">4</span> ...</span>
<span id="cb66-5"><a href="chapter-data-prep.html#cb66-5" tabindex="-1"></a>    <span class="sc">$</span> demogweight   <span class="sc">:</span> int  <span class="dv">226802</span> <span class="dv">89814</span> <span class="dv">336951</span> <span class="dv">160323</span> <span class="dv">103497</span> <span class="dv">198693</span> <span class="dv">227026</span> <span class="dv">104626</span> <span class="dv">369667</span> <span class="dv">104996</span> ...</span>
<span id="cb66-6"><a href="chapter-data-prep.html#cb66-6" tabindex="-1"></a>    <span class="sc">$</span> education     <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">16</span> levels <span class="st">"10th"</span>,<span class="st">"11th"</span>,..<span class="sc">:</span> <span class="dv">2</span> <span class="dv">12</span> <span class="dv">8</span> <span class="dv">16</span> <span class="dv">16</span> <span class="dv">1</span> <span class="dv">12</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">6</span> ...</span>
<span id="cb66-7"><a href="chapter-data-prep.html#cb66-7" tabindex="-1"></a>    <span class="sc">$</span> education.num <span class="sc">:</span> int  <span class="dv">7</span> <span class="dv">9</span> <span class="dv">12</span> <span class="dv">10</span> <span class="dv">10</span> <span class="dv">6</span> <span class="dv">9</span> <span class="dv">15</span> <span class="dv">10</span> <span class="dv">4</span> ...</span>
<span id="cb66-8"><a href="chapter-data-prep.html#cb66-8" tabindex="-1"></a>    <span class="sc">$</span> marital.status<span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">5</span> levels <span class="st">"Divorced"</span>,<span class="st">"Married"</span>,..<span class="sc">:</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> ...</span>
<span id="cb66-9"><a href="chapter-data-prep.html#cb66-9" tabindex="-1"></a>    <span class="sc">$</span> occupation    <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">15</span> levels <span class="st">"?"</span>,<span class="st">"Adm-clerical"</span>,..<span class="sc">:</span> <span class="dv">8</span> <span class="dv">6</span> <span class="dv">12</span> <span class="dv">8</span> <span class="dv">1</span> <span class="dv">9</span> <span class="dv">1</span> <span class="dv">11</span> <span class="dv">9</span> <span class="dv">4</span> ...</span>
<span id="cb66-10"><a href="chapter-data-prep.html#cb66-10" tabindex="-1"></a>    <span class="sc">$</span> relationship  <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">6</span> levels <span class="st">"Husband"</span>,<span class="st">"Not-in-family"</span>,..<span class="sc">:</span> <span class="dv">4</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">5</span> <span class="dv">1</span> <span class="dv">5</span> <span class="dv">1</span> ...</span>
<span id="cb66-11"><a href="chapter-data-prep.html#cb66-11" tabindex="-1"></a>    <span class="sc">$</span> race          <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">5</span> levels <span class="st">"Amer-Indian-Eskimo"</span>,..<span class="sc">:</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">3</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">5</span> ...</span>
<span id="cb66-12"><a href="chapter-data-prep.html#cb66-12" tabindex="-1"></a>    <span class="sc">$</span> gender        <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"Female"</span>,<span class="st">"Male"</span><span class="sc">:</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">2</span> ...</span>
<span id="cb66-13"><a href="chapter-data-prep.html#cb66-13" tabindex="-1"></a>    <span class="sc">$</span> capital.gain  <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">7688</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">3103</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb66-14"><a href="chapter-data-prep.html#cb66-14" tabindex="-1"></a>    <span class="sc">$</span> capital.loss  <span class="sc">:</span> int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> ...</span>
<span id="cb66-15"><a href="chapter-data-prep.html#cb66-15" tabindex="-1"></a>    <span class="sc">$</span> hours.per.week<span class="sc">:</span> int  <span class="dv">40</span> <span class="dv">50</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">30</span> <span class="dv">30</span> <span class="dv">40</span> <span class="dv">32</span> <span class="dv">40</span> <span class="dv">10</span> ...</span>
<span id="cb66-16"><a href="chapter-data-prep.html#cb66-16" tabindex="-1"></a>    <span class="sc">$</span> native.country<span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">42</span> levels <span class="st">"?"</span>,<span class="st">"Cambodia"</span>,..<span class="sc">:</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> <span class="dv">40</span> ...</span>
<span id="cb66-17"><a href="chapter-data-prep.html#cb66-17" tabindex="-1"></a>    <span class="sc">$</span> income        <span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">"&lt;=50K"</span>,<span class="st">"&gt;50K"</span><span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">1</span> ...</span></code></pre></div>
<p>The dataset contains 48598 records and 15 variables. Of these, 14 are predictors, while the target variable, <code>income</code>, is a categorical variable with two levels: <code>&lt;=50K</code> and <code>&gt;50K</code>. The features include both numerical and categorical variables:</p>
<ul>
<li>
<code>age</code>: Age in years (numerical).<br>
</li>
<li>
<code>workclass</code>: Employment type (categorical, 6 levels).<br>
</li>
<li>
<code>demogweight</code>: Census weighting factor (numerical).<br>
</li>
<li>
<code>education</code>: Highest level of education (categorical, 16 levels).<br>
</li>
<li>
<code>education.num</code>: Number of years of education (numerical).<br>
</li>
<li>
<code>marital.status</code>: Marital status (categorical, 5 levels).<br>
</li>
<li>
<code>occupation</code>: Job category (categorical, 15 levels).<br>
</li>
<li>
<code>relationship</code>: Family relationship status (categorical, 6 levels).<br>
</li>
<li>
<code>race</code>: Racial background (categorical, 5 levels).<br>
</li>
<li>
<code>gender</code>: Gender identity (categorical, Male/Female).<br>
</li>
<li>
<code>capital.gain</code>: Capital gains (numerical).<br>
</li>
<li>
<code>capital.loss</code>: Capital losses (numerical).<br>
</li>
<li>
<code>hours.per.week</code>: Hours worked per week (numerical).<br>
</li>
<li>
<code>native.country</code>: Country of origin (categorical, 42 levels).<br>
</li>
<li>
<code>income</code>: Target variable indicating annual income (<code>&lt;=50K</code> or <code>&gt;50K</code>).</li>
</ul>
<p>For clarity, we categorize the dataset’s variables:</p>
<ul>
<li>
<strong>Nominal variables</strong>: <code>workclass</code>, <code>marital.status</code>, <code>occupation</code>, <code>relationship</code>, <code>race</code>, <code>native.country</code>, and <code>gender</code>.<br>
</li>
<li>
<strong>Ordinal variable</strong>: <code>education</code>.<br>
</li>
<li>
<strong>Numerical variables</strong>: <code>age</code>, <code>demogweight</code>, <code>education.num</code>, <code>capital.gain</code>, <code>capital.loss</code>, and <code>hours.per.week</code>.</li>
</ul>
<p>To better understand the dataset, we generate summary statistics:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="chapter-data-prep.html#cb67-1" tabindex="-1"></a><span class="fu">summary</span>(adult)</span>
<span id="cb67-2"><a href="chapter-data-prep.html#cb67-2" tabindex="-1"></a>         age              workclass      demogweight             education    </span>
<span id="cb67-3"><a href="chapter-data-prep.html#cb67-3" tabindex="-1"></a>    Min.   <span class="sc">:</span><span class="fl">17.0</span>   ?           <span class="sc">:</span> <span class="dv">2794</span>   Min.   <span class="sc">:</span>  <span class="dv">12285</span>   HS<span class="sc">-</span>grad     <span class="sc">:</span><span class="dv">15750</span>  </span>
<span id="cb67-4"><a href="chapter-data-prep.html#cb67-4" tabindex="-1"></a>    <span class="dv">1</span>st Qu.<span class="sc">:</span><span class="fl">28.0</span>   Gov         <span class="sc">:</span> <span class="dv">6536</span>   <span class="dv">1</span>st Qu.<span class="sc">:</span> <span class="dv">117550</span>   Some<span class="sc">-</span>college<span class="sc">:</span><span class="dv">10860</span>  </span>
<span id="cb67-5"><a href="chapter-data-prep.html#cb67-5" tabindex="-1"></a>    Median <span class="sc">:</span><span class="fl">37.0</span>   Never<span class="sc">-</span>worked<span class="sc">:</span>   <span class="dv">10</span>   Median <span class="sc">:</span> <span class="dv">178215</span>   Bachelors   <span class="sc">:</span> <span class="dv">7962</span>  </span>
<span id="cb67-6"><a href="chapter-data-prep.html#cb67-6" tabindex="-1"></a>    Mean   <span class="sc">:</span><span class="fl">38.6</span>   Private     <span class="sc">:</span><span class="dv">33780</span>   Mean   <span class="sc">:</span> <span class="dv">189685</span>   Masters     <span class="sc">:</span> <span class="dv">2627</span>  </span>
<span id="cb67-7"><a href="chapter-data-prep.html#cb67-7" tabindex="-1"></a>    <span class="dv">3</span>rd Qu.<span class="sc">:</span><span class="fl">48.0</span>   Self<span class="sc">-</span>emp    <span class="sc">:</span> <span class="dv">5457</span>   <span class="dv">3</span>rd Qu.<span class="sc">:</span> <span class="dv">237713</span>   Assoc<span class="sc">-</span>voc   <span class="sc">:</span> <span class="dv">2058</span>  </span>
<span id="cb67-8"><a href="chapter-data-prep.html#cb67-8" tabindex="-1"></a>    Max.   <span class="sc">:</span><span class="fl">90.0</span>   Without<span class="sc">-</span>pay <span class="sc">:</span>   <span class="dv">21</span>   Max.   <span class="sc">:</span><span class="dv">1490400</span>   <span class="dv">11</span>th        <span class="sc">:</span> <span class="dv">1812</span>  </span>
<span id="cb67-9"><a href="chapter-data-prep.html#cb67-9" tabindex="-1"></a>                                                          (Other)     <span class="sc">:</span> <span class="dv">7529</span>  </span>
<span id="cb67-10"><a href="chapter-data-prep.html#cb67-10" tabindex="-1"></a>    education.num         marital.status            occupation   </span>
<span id="cb67-11"><a href="chapter-data-prep.html#cb67-11" tabindex="-1"></a>    Min.   <span class="sc">:</span> <span class="fl">1.00</span>   Divorced     <span class="sc">:</span> <span class="dv">6613</span>   Craft<span class="sc">-</span>repair   <span class="sc">:</span> <span class="dv">6096</span>  </span>
<span id="cb67-12"><a href="chapter-data-prep.html#cb67-12" tabindex="-1"></a>    <span class="dv">1</span>st Qu.<span class="sc">:</span> <span class="fl">9.00</span>   Married      <span class="sc">:</span><span class="dv">22847</span>   Prof<span class="sc">-</span>specialty <span class="sc">:</span> <span class="dv">6071</span>  </span>
<span id="cb67-13"><a href="chapter-data-prep.html#cb67-13" tabindex="-1"></a>    Median <span class="sc">:</span><span class="fl">10.00</span>   Never<span class="sc">-</span>married<span class="sc">:</span><span class="dv">16096</span>   Exec<span class="sc">-</span>managerial<span class="sc">:</span> <span class="dv">6019</span>  </span>
<span id="cb67-14"><a href="chapter-data-prep.html#cb67-14" tabindex="-1"></a>    Mean   <span class="sc">:</span><span class="fl">10.06</span>   Separated    <span class="sc">:</span> <span class="dv">1526</span>   Adm<span class="sc">-</span>clerical   <span class="sc">:</span> <span class="dv">5603</span>  </span>
<span id="cb67-15"><a href="chapter-data-prep.html#cb67-15" tabindex="-1"></a>    <span class="dv">3</span>rd Qu.<span class="sc">:</span><span class="fl">12.00</span>   Widowed      <span class="sc">:</span> <span class="dv">1516</span>   Sales          <span class="sc">:</span> <span class="dv">5470</span>  </span>
<span id="cb67-16"><a href="chapter-data-prep.html#cb67-16" tabindex="-1"></a>    Max.   <span class="sc">:</span><span class="fl">16.00</span>                         Other<span class="sc">-</span>service  <span class="sc">:</span> <span class="dv">4920</span>  </span>
<span id="cb67-17"><a href="chapter-data-prep.html#cb67-17" tabindex="-1"></a>                                          (Other)        <span class="sc">:</span><span class="dv">14419</span>  </span>
<span id="cb67-18"><a href="chapter-data-prep.html#cb67-18" tabindex="-1"></a>            relationship                   race          gender     </span>
<span id="cb67-19"><a href="chapter-data-prep.html#cb67-19" tabindex="-1"></a>    Husband       <span class="sc">:</span><span class="dv">19537</span>   Amer<span class="sc">-</span>Indian<span class="sc">-</span>Eskimo<span class="sc">:</span>  <span class="dv">470</span>   Female<span class="sc">:</span><span class="dv">16156</span>  </span>
<span id="cb67-20"><a href="chapter-data-prep.html#cb67-20" tabindex="-1"></a>    Not<span class="sc">-</span><span class="cf">in</span><span class="sc">-</span>family <span class="sc">:</span><span class="dv">12546</span>   Asian<span class="sc">-</span>Pac<span class="sc">-</span>Islander<span class="sc">:</span> <span class="dv">1504</span>   Male  <span class="sc">:</span><span class="dv">32442</span>  </span>
<span id="cb67-21"><a href="chapter-data-prep.html#cb67-21" tabindex="-1"></a>    Other<span class="sc">-</span>relative<span class="sc">:</span> <span class="dv">1506</span>   Black             <span class="sc">:</span> <span class="dv">4675</span>                 </span>
<span id="cb67-22"><a href="chapter-data-prep.html#cb67-22" tabindex="-1"></a>    Own<span class="sc">-</span>child     <span class="sc">:</span> <span class="dv">7577</span>   Other             <span class="sc">:</span>  <span class="dv">403</span>                 </span>
<span id="cb67-23"><a href="chapter-data-prep.html#cb67-23" tabindex="-1"></a>    Unmarried     <span class="sc">:</span> <span class="dv">5118</span>   White             <span class="sc">:</span><span class="dv">41546</span>                 </span>
<span id="cb67-24"><a href="chapter-data-prep.html#cb67-24" tabindex="-1"></a>    Wife          <span class="sc">:</span> <span class="dv">2314</span>                                            </span>
<span id="cb67-25"><a href="chapter-data-prep.html#cb67-25" tabindex="-1"></a>                                                                    </span>
<span id="cb67-26"><a href="chapter-data-prep.html#cb67-26" tabindex="-1"></a>     capital.gain      capital.loss     hours.per.week        native.country </span>
<span id="cb67-27"><a href="chapter-data-prep.html#cb67-27" tabindex="-1"></a>    Min.   <span class="sc">:</span>    <span class="fl">0.0</span>   Min.   <span class="sc">:</span>   <span class="fl">0.00</span>   Min.   <span class="sc">:</span> <span class="fl">1.00</span>   United<span class="sc">-</span>States<span class="sc">:</span><span class="dv">43613</span>  </span>
<span id="cb67-28"><a href="chapter-data-prep.html#cb67-28" tabindex="-1"></a>    <span class="dv">1</span>st Qu.<span class="sc">:</span>    <span class="fl">0.0</span>   <span class="dv">1</span>st Qu.<span class="sc">:</span>   <span class="fl">0.00</span>   <span class="dv">1</span>st Qu.<span class="sc">:</span><span class="fl">40.00</span>   Mexico       <span class="sc">:</span>  <span class="dv">949</span>  </span>
<span id="cb67-29"><a href="chapter-data-prep.html#cb67-29" tabindex="-1"></a>    Median <span class="sc">:</span>    <span class="fl">0.0</span>   Median <span class="sc">:</span>   <span class="fl">0.00</span>   Median <span class="sc">:</span><span class="fl">40.00</span>   ?            <span class="sc">:</span>  <span class="dv">847</span>  </span>
<span id="cb67-30"><a href="chapter-data-prep.html#cb67-30" tabindex="-1"></a>    Mean   <span class="sc">:</span>  <span class="fl">582.4</span>   Mean   <span class="sc">:</span>  <span class="fl">87.94</span>   Mean   <span class="sc">:</span><span class="fl">40.37</span>   Philippines  <span class="sc">:</span>  <span class="dv">292</span>  </span>
<span id="cb67-31"><a href="chapter-data-prep.html#cb67-31" tabindex="-1"></a>    <span class="dv">3</span>rd Qu.<span class="sc">:</span>    <span class="fl">0.0</span>   <span class="dv">3</span>rd Qu.<span class="sc">:</span>   <span class="fl">0.00</span>   <span class="dv">3</span>rd Qu.<span class="sc">:</span><span class="fl">45.00</span>   Germany      <span class="sc">:</span>  <span class="dv">206</span>  </span>
<span id="cb67-32"><a href="chapter-data-prep.html#cb67-32" tabindex="-1"></a>    Max.   <span class="sc">:</span><span class="fl">41310.0</span>   Max.   <span class="sc">:</span><span class="fl">4356.00</span>   Max.   <span class="sc">:</span><span class="fl">99.00</span>   Puerto<span class="sc">-</span>Rico  <span class="sc">:</span>  <span class="dv">184</span>  </span>
<span id="cb67-33"><a href="chapter-data-prep.html#cb67-33" tabindex="-1"></a>                                                        (Other)      <span class="sc">:</span> <span class="dv">2507</span>  </span>
<span id="cb67-34"><a href="chapter-data-prep.html#cb67-34" tabindex="-1"></a>      income     </span>
<span id="cb67-35"><a href="chapter-data-prep.html#cb67-35" tabindex="-1"></a>    <span class="sc">&lt;=</span><span class="dv">50</span>K<span class="sc">:</span><span class="dv">37155</span>  </span>
<span id="cb67-36"><a href="chapter-data-prep.html#cb67-36" tabindex="-1"></a>    <span class="sc">&gt;</span><span class="dv">50</span>K <span class="sc">:</span><span class="dv">11443</span>  </span>
<span id="cb67-37"><a href="chapter-data-prep.html#cb67-37" tabindex="-1"></a>                 </span>
<span id="cb67-38"><a href="chapter-data-prep.html#cb67-38" tabindex="-1"></a>                 </span>
<span id="cb67-39"><a href="chapter-data-prep.html#cb67-39" tabindex="-1"></a>                 </span>
<span id="cb67-40"><a href="chapter-data-prep.html#cb67-40" tabindex="-1"></a>                 </span>
<span id="cb67-41"><a href="chapter-data-prep.html#cb67-41" tabindex="-1"></a>   </span></code></pre></div>
<p>This summary provides insights into the distribution of numerical variables, missing values, and categorical variable levels, guiding us in preparing the data for further analysis.</p>
</div>
<div id="missing-values-1" class="section level3" number="3.9.1">
<h3>
<span class="header-section-number">3.9.1</span> Missing Values<a class="anchor" aria-label="anchor" href="#missing-values-1"><i class="fas fa-link"></i></a>
</h3>
<p>The <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function reveals that the variables <code>workclass</code> and <code>native.country</code> contain missing values, represented by the <code>"?"</code> category. Specifically, 2794 records in <code>workclass</code> and 847 records in <code>native.country</code> have missing values. Since <code>"?"</code> is used as a placeholder for missing data, we first convert these entries to <code>NA</code>:</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">adult</span><span class="op">[</span><span class="va">adult</span> <span class="op">==</span> <span class="st">"?"</span><span class="op">]</span> <span class="op">=</span> <span class="cn">NA</span></span></code></pre></div>
<p>After replacing <code>"?"</code> with <code>NA</code>, we remove unused factor levels to clean up the dataset:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">adult</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">adult</span><span class="op">)</span></span></code></pre></div>
<p>To visualize the distribution of missing values, we use the <code><a href="https://rdrr.io/pkg/naniar/man/gg_miss_var.html">gg_miss_var()</a></code> function from the <strong>naniar</strong> package:</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/njtierney/naniar">naniar</a></span><span class="op">)</span>  <span class="co"># Load package for visualizing missing values</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/naniar/man/gg_miss_var.html">gg_miss_var</a></span><span class="op">(</span><span class="va">adult</span>, show_pct <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The plot indicates that <code>workclass</code>, <code>occupation</code>, and <code>native.country</code> contain missing values. The percentage of missing values in these variables is relatively low, with <code>workclass</code> and <code>occupation</code> having less than 0.06 percent missing data, while <code>native.country</code> has about 0.02 percent.</p>
<div id="imputing-missing-values" class="section level4 unnumbered">
<h4>Imputing Missing Values<a class="anchor" aria-label="anchor" href="#imputing-missing-values"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of removing records with missing values, which can lead to information loss, we apply <em>random imputation</em>, where missing values are filled with randomly selected values from the existing distribution of each variable. This maintains the natural proportions of each category.</p>
<p>We use the <code><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute()</a></code> function from the <strong>Hmisc</strong> package for this purpose:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://hbiostat.org/R/Hmisc/">Hmisc</a></span><span class="op">)</span>  <span class="co"># Load package for imputation</span></span>
<span></span>
<span><span class="co"># Impute missing values using random sampling from existing categories</span></span>
<span><span class="va">adult</span><span class="op">$</span><span class="va">workclass</span>      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute</a></span><span class="op">(</span><span class="va">adult</span><span class="op">$</span><span class="va">workclass</span>,      <span class="st">'random'</span><span class="op">)</span></span>
<span><span class="va">adult</span><span class="op">$</span><span class="va">native.country</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute</a></span><span class="op">(</span><span class="va">adult</span><span class="op">$</span><span class="va">native.country</span>, <span class="st">'random'</span><span class="op">)</span></span>
<span><span class="va">adult</span><span class="op">$</span><span class="va">occupation</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute</a></span><span class="op">(</span><span class="va">adult</span><span class="op">$</span><span class="va">occupation</span>,     <span class="st">'random'</span><span class="op">)</span></span></code></pre></div>
<p>To confirm that missing values have been successfully imputed, we generate another missing values plot:</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/naniar/man/gg_miss_var.html">gg_miss_var</a></span><span class="op">(</span><span class="va">adult</span>, show_pct <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-20-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The updated plot should show no missing values, indicating successful imputation.</p>
</div>
<div id="alternative-approaches" class="section level4 unnumbered">
<h4>Alternative Approaches<a class="anchor" aria-label="anchor" href="#alternative-approaches"><i class="fas fa-link"></i></a>
</h4>
<p>The <code><a href="https://rdrr.io/pkg/Hmisc/man/impute.html">impute()</a></code> function allows for different statistical methods such as mean, median, or mode imputation. Its default behavior is <em>median</em> imputation. For more advanced techniques, the <code><a href="https://rdrr.io/pkg/Hmisc/man/aregImpute.html">aregImpute()</a></code> function from the <strong>Hmisc</strong> package offers predictive imputation using additive regression, bootstrapping, and predictive mean matching.</p>
<p>Although removing records with missing values using <code><a href="https://rdrr.io/r/stats/na.fail.html">na.omit()</a></code> is an option, it is generally discouraged unless missing values are excessive or biased in a way that could distort analysis.</p>
<p>By properly handling missing values, we ensure data completeness and maintain the integrity of the dataset for subsequent preprocessing steps, such as recoding categorical variables and grouping country-level data into broader regions.</p>
</div>
</div>
<div id="encoding-categorical-variables" class="section level3" number="3.9.2">
<h3>
<span class="header-section-number">3.9.2</span> Encoding Categorical Variables<a class="anchor" aria-label="anchor" href="#encoding-categorical-variables"><i class="fas fa-link"></i></a>
</h3>
<p>Categorical variables often contain a large number of unique values, making them challenging to use in predictive models. In the <em>Adult</em> dataset, <code>native.country</code> and <code>workclass</code> have multiple categories, which can introduce complexity and redundancy. To simplify these variables, we group similar categories together while preserving their interpretability.</p>
<div id="grouping-native.country-by-continent" class="section level4 unnumbered">
<h4>Grouping <code>native.country</code> by Continent<a class="anchor" aria-label="anchor" href="#grouping-native.country-by-continent"><i class="fas fa-link"></i></a>
</h4>
<p>The <code>native.country</code> variable contains 41 distinct countries. To make it more manageable, we categorize countries into broader geographical regions:</p>
<ul>
<li>
<strong>Europe</strong>: England, France, Germany, Greece, Netherlands, Hungary, Ireland, Italy, Poland, Portugal, Scotland, Yugoslavia<br>
</li>
<li>
<strong>Asia</strong>: China, Hong Kong, India, Iran, Cambodia, Japan, Laos, Philippines, Vietnam, Taiwan, Thailand<br>
</li>
<li>
<strong>North America</strong>: Canada, United States, Puerto Rico<br>
</li>
<li>
<strong>South America</strong>: Colombia, Cuba, Dominican Republic, Ecuador, El Salvador, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Outlying US territories, Peru, Jamaica, Trinidad &amp; Tobago<br>
</li>
<li>
<strong>Other</strong>: This includes the ambiguous “South” category, as its meaning is unclear in the dataset documentation.<br>
We use the <code><a href="https://forcats.tidyverse.org/reference/fct_collapse.html">fct_collapse()</a></code> function from the <strong>forcats</strong> package to reassign categories:</li>
</ul>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://forcats.tidyverse.org/">forcats</a></span><span class="op">)</span>  <span class="co"># Load package for categorical variable transformation</span></span>
<span></span>
<span><span class="co"># To create a new factor variable with fewer levels for `native.country`</span></span>
<span><span class="va">Europe</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"England"</span>, <span class="st">"France"</span>, <span class="st">"Germany"</span>, <span class="st">"Greece"</span>, <span class="st">"Holand-Netherlands"</span>, <span class="st">"Hungary"</span>, <span class="st">"Ireland"</span>, <span class="st">"Italy"</span>, <span class="st">"Poland"</span>, <span class="st">"Portugal"</span>, <span class="st">"Scotland"</span>, <span class="st">"Yugoslavia"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Asia</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"China"</span>, <span class="st">"Hong"</span>, <span class="st">"India"</span>, <span class="st">"Iran"</span>, <span class="st">"Cambodia"</span>, <span class="st">"Japan"</span>, <span class="st">"Laos"</span>, <span class="st">"Philippines"</span>, <span class="st">"Vietnam"</span>, <span class="st">"Taiwan"</span>, <span class="st">"Thailand"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">N.America</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Canada"</span>, <span class="st">"United-States"</span>, <span class="st">"Puerto-Rico"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">S.America</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Columbia"</span>, <span class="st">"Cuba"</span>, <span class="st">"Dominican-Republic"</span>, <span class="st">"Ecuador"</span>, <span class="st">"El-Salvador"</span>, <span class="st">"Guatemala"</span>, <span class="st">"Haiti"</span>, <span class="st">"Honduras"</span>, <span class="st">"Mexico"</span>, <span class="st">"Nicaragua"</span>, <span class="st">"Outlying-US(Guam-USVI-etc)"</span>, <span class="st">"Peru"</span>, <span class="st">"Jamaica"</span>, <span class="st">"Trinadad&amp;Tobago"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Reclassify native.country into broader regions</span></span>
<span><span class="va">adult</span><span class="op">$</span><span class="va">native.country</span> <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/fct_collapse.html">fct_collapse</a></span><span class="op">(</span><span class="va">adult</span><span class="op">$</span><span class="va">native.country</span>, </span>
<span>                                    <span class="st">"Europe"</span>    <span class="op">=</span> <span class="va">Europe</span>,</span>
<span>                                    <span class="st">"Asia"</span>      <span class="op">=</span> <span class="va">Asia</span>,</span>
<span>                                    <span class="st">"N.America"</span> <span class="op">=</span> <span class="va">N.America</span>,</span>
<span>                                    <span class="st">"S.America"</span> <span class="op">=</span> <span class="va">S.America</span>,</span>
<span>                                    <span class="st">"Other"</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"South"</span><span class="op">)</span> <span class="op">)</span></span></code></pre></div>
<p>To confirm the changes, we display the frequency distribution of <code>native.country</code>:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="chapter-data-prep.html#cb74-1" tabindex="-1"></a><span class="fu">table</span>(adult<span class="sc">$</span>native.country)</span>
<span id="cb74-2"><a href="chapter-data-prep.html#cb74-2" tabindex="-1"></a>   </span>
<span id="cb74-3"><a href="chapter-data-prep.html#cb74-3" tabindex="-1"></a>        Asia N.America S.America    Europe     Other </span>
<span id="cb74-4"><a href="chapter-data-prep.html#cb74-4" tabindex="-1"></a>         <span class="dv">993</span>     <span class="dv">44747</span>      <span class="dv">1946</span>       <span class="dv">797</span>       <span class="dv">115</span></span></code></pre></div>
<p>By grouping the original 42 countries into 5 broader regions, we simplify the variable while maintaining its relevance for analysis.</p>
</div>
<div id="simplifying-workclass" class="section level4 unnumbered">
<h4>Simplifying <code>workclass</code><a class="anchor" aria-label="anchor" href="#simplifying-workclass"><i class="fas fa-link"></i></a>
</h4>
<p>The <code>workclass</code> variable originally contains several employment categories. Since “Never-worked” and “Without-pay” represent similar employment statuses, we merge them into a single category labeled “Unemployed”:</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">adult</span><span class="op">$</span><span class="va">workclass</span> <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/fct_collapse.html">fct_collapse</a></span><span class="op">(</span><span class="va">adult</span><span class="op">$</span><span class="va">workclass</span>, <span class="st">"Unemployed"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Never-worked"</span>, <span class="st">"Without-pay"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>To verify the updated categories, we check the frequency distribution:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="chapter-data-prep.html#cb76-1" tabindex="-1"></a><span class="fu">table</span>(adult<span class="sc">$</span>workclass)</span>
<span id="cb76-2"><a href="chapter-data-prep.html#cb76-2" tabindex="-1"></a>   </span>
<span id="cb76-3"><a href="chapter-data-prep.html#cb76-3" tabindex="-1"></a>          Gov Unemployed    Private   Self<span class="sc">-</span>emp </span>
<span id="cb76-4"><a href="chapter-data-prep.html#cb76-4" tabindex="-1"></a>         <span class="dv">6919</span>         <span class="dv">32</span>      <span class="dv">35851</span>       <span class="dv">5796</span></span></code></pre></div>
<p>By reducing the number of unique categories in <code>workclass</code> and <code>native.country</code>, we improve model interpretability and reduce the risk of overfitting when applying machine learning algorithms.</p>
</div>
</div>
<div id="outliers" class="section level3" number="3.9.3">
<h3>
<span class="header-section-number">3.9.3</span> Outliers<a class="anchor" aria-label="anchor" href="#outliers"><i class="fas fa-link"></i></a>
</h3>
<p>Detecting and handling outliers is an essential step in data preprocessing, as extreme values can significantly impact statistical analysis and model performance. Here, we examine potential outliers in the <code>capital.loss</code> variable to determine whether adjustments are necessary.</p>
<div id="summary-statistics" class="section level4 unnumbered">
<h4>Summary Statistics<a class="anchor" aria-label="anchor" href="#summary-statistics"><i class="fas fa-link"></i></a>
</h4>
<p>To gain an initial understanding of <code>capital.loss</code>, we compute its summary statistics:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="chapter-data-prep.html#cb77-1" tabindex="-1"></a><span class="fu">summary</span>(adult<span class="sc">$</span>capital.loss)</span>
<span id="cb77-2"><a href="chapter-data-prep.html#cb77-2" tabindex="-1"></a>      Min. <span class="dv">1</span>st Qu.  Median    Mean <span class="dv">3</span>rd Qu.    Max. </span>
<span id="cb77-3"><a href="chapter-data-prep.html#cb77-3" tabindex="-1"></a>      <span class="fl">0.00</span>    <span class="fl">0.00</span>    <span class="fl">0.00</span>   <span class="fl">87.94</span>    <span class="fl">0.00</span> <span class="fl">4356.00</span></span></code></pre></div>
<p>The summary output reveals the following insights:</p>
<ul>
<li>The minimum value is 0, while the maximum is 4356.<br>
</li>
<li>The <em>median</em> is 0, which is significantly lower than the <em>mean</em>, indicating a highly skewed distribution.<br>
</li>
<li>More than 75% of the observations have a capital loss of 0, confirming a strong right-skew.<br>
</li>
<li>The mean capital loss is 87.94, which is influenced by a small number of extreme values.</li>
</ul>
</div>
<div id="visualizing-outliers" class="section level4 unnumbered">
<h4>Visualizing Outliers<a class="anchor" aria-label="anchor" href="#visualizing-outliers"><i class="fas fa-link"></i></a>
</h4>
<p>To further investigate the distribution of <code>capital.loss</code>, we use a boxplot and histogram:</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">adult</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">capital.loss</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>     <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-26-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">adult</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">capital.loss</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>     <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">30</span>, color <span class="op">=</span> <span class="st">"blue"</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-27-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>From these plots, we observe:</p>
<ul>
<li>The boxplot shows a strong <em>positive skew</em>, with many extreme values above the upper whisker.<br>
</li>
<li>The histogram indicates that most observations have <em>zero capital loss</em>, with a few cases around 2,000 and 4,000.</li>
</ul>
<p>Since a large proportion of observations report no capital loss, we further examine the nonzero cases.</p>
</div>
<div id="zooming-into-the-nonzero-distribution" class="section level4 unnumbered">
<h4>Zooming into the Nonzero Distribution<a class="anchor" aria-label="anchor" href="#zooming-into-the-nonzero-distribution"><i class="fas fa-link"></i></a>
</h4>
<p>To better visualize the spread of nonzero values, we focus on observations with <code>capital.loss &gt; 0</code>:</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">adult</span>, mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">capital.loss</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">30</span>, color <span class="op">=</span> <span class="st">"blue"</span>, fill <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">500</span>, <span class="fl">4000</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1000</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-28-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">adult</span>, <span class="va">capital.loss</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>     <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">capital.loss</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="data-preparation_files/figure-html/unnamed-chunk-29-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Key takeaways from these refined plots:</p>
<ul>
<li>The majority of nonzero values are below 500, with a small number extending beyond 4,000.<br>
</li>
<li>The distribution of nonzero values is approximately symmetric, suggesting that while there are extreme values, they follow a structured pattern rather than random anomalies.</li>
</ul>
</div>
<div id="handling-outliers" class="section level4 unnumbered">
<h4>Handling Outliers<a class="anchor" aria-label="anchor" href="#handling-outliers"><i class="fas fa-link"></i></a>
</h4>
<p>Although <code>capital.loss</code> contains many high values, these do not appear to be erroneous. Instead, they reflect genuine cases within the dataset. Since these values provide meaningful information about particular individuals, we retain them rather than applying transformations or removals.</p>
<p>However, if model performance is significantly affected by these extreme values, we might consider:</p>
<ol style="list-style-type: decimal">
<li>
<em>Winsorization</em>: Capping values at a reasonable percentile (e.g., the 95th percentile).<br>
</li>
<li>
<em>Log Transformation</em>: Applying a log transformation to reduce skewness.<br>
</li>
<li>
<em>Creating a Binary Indicator</em>: Introducing a new variable indicating whether a capital loss occurred (<code>capital.loss &gt; 0</code>).</li>
</ol>
<p>Next, we perform a similar outlier analysis for the <code>capital.gain</code> variable. See the exercises below for a guided approach.</p>
</div>
</div>
</div>
<div id="exercises-2" class="section level2" number="3.10">
<h2>
<span class="header-section-number">3.10</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises-2"><i class="fas fa-link"></i></a>
</h2>
<p>This section provides hands-on exercises to reinforce the key concepts covered in this chapter. These questions include theoretical, exploratory, and practical challenges related to data types, outliers, encoding techniques, and feature engineering.</p>
<div id="understanding-data-types" class="section level3 unnumbered">
<h3>Understanding Data Types<a class="anchor" aria-label="anchor" href="#understanding-data-types"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>What is the difference between continuous and discrete numerical variables? Provide an example of each from real-world data.<br>
</li>
<li>How do ordinal categorical variables differ from nominal categorical variables? Give an example for both.</li>
</ol>
</div>
<div id="exploring-the-diamonds-dataset" class="section level3 unnumbered">
<h3>Exploring the diamonds Dataset<a class="anchor" aria-label="anchor" href="#exploring-the-diamonds-dataset"><i class="fas fa-link"></i></a>
</h3>
<ol start="3" style="list-style-type: decimal">
<li>Report the summary statistics for the diamonds dataset using the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function. What insights can you derive from the output?<br>
</li>
<li>In the diamonds dataset, which variables are nominal, ordinal, and numerical? List them accordingly.</li>
</ol>
</div>
<div id="detecting-and-handling-outliers" class="section level3 unnumbered">
<h3>Detecting and Handling Outliers<a class="anchor" aria-label="anchor" href="#detecting-and-handling-outliers"><i class="fas fa-link"></i></a>
</h3>
<ol start="5" style="list-style-type: decimal">
<li>Identify outliers in the variable <code>x</code>. If any exist, handle them appropriately. Follow the same approach as in Section <a href="chapter-data-prep.html#Data-pre-outliers">3.3</a> for the <code>y</code> variable in the diamonds dataset.<br>
</li>
<li>Repeat the outlier detection process for the variable <code>z</code>. If necessary, apply transformations or filtering techniques.<br>
</li>
<li>Check for outliers in the <code>depth</code> variable. What method would you use to detect and handle them?</li>
</ol>
</div>
<div id="encoding-categorical-variables-1" class="section level3 unnumbered">
<h3>Encoding Categorical Variables<a class="anchor" aria-label="anchor" href="#encoding-categorical-variables-1"><i class="fas fa-link"></i></a>
</h3>
<ol start="8" style="list-style-type: decimal">
<li>The <code>cut</code> variable in the diamonds dataset is ordinal. How can we encode it properly using ordinal encoding?<br>
</li>
<li>The <code>color</code> variable in the diamonds dataset is nominal. How can we encode it using one-hot encoding?</li>
</ol>
</div>
<div id="analyzing-the-adult-dataset" class="section level3 unnumbered">
<h3>Analyzing the Adult Dataset<a class="anchor" aria-label="anchor" href="#analyzing-the-adult-dataset"><i class="fas fa-link"></i></a>
</h3>
<ol start="10" style="list-style-type: decimal">
<li>Load the Adult dataset from the <strong>liver</strong> package and examine its structure. Identify the categorical variables and classify them as nominal or ordinal.<br>
</li>
<li>Compute the proportion of individuals who earn more than 50K (<code>&gt;50K</code>). What does this distribution tell you about income levels in this dataset?<br>
</li>
<li>For the Adult dataset, generate the summary statistics, boxplot, and histogram for the variable <code>capital.gain</code>. What do you observe?<br>
</li>
<li>Based on the visualizations from the previous question, are there outliers in the <code>capital.gain</code> variable? If so, suggest a strategy to handle them.</li>
</ol>
</div>
<div id="feature-engineering-challenge" class="section level3 unnumbered">
<h3>Feature Engineering Challenge<a class="anchor" aria-label="anchor" href="#feature-engineering-challenge"><i class="fas fa-link"></i></a>
</h3>
<ol start="14" style="list-style-type: decimal">
<li>Create a new categorical variable <code>Age_Group</code> in the Adult dataset, grouping ages into:<br>
</li>
</ol>
<ul>
<li>Young (≤30 years old)<br>
</li>
<li>Middle-aged (31-50 years old)<br>
</li>
<li>Senior (&gt;50 years old)<br>
Use the <code><a href="https://rdrr.io/r/base/cut.html">cut()</a></code> function to implement this transformation.</li>
</ul>
<ol start="15" style="list-style-type: decimal">
<li>Compute the mean <code>capital.gain</code> for each <code>Age_Group</code>. What insights do you gain about income levels across different age groups?</li>
</ol>
</div>
<div id="advanced-data-preparation-challenges" class="section level3 unnumbered">
<h3>Advanced Data Preparation Challenges<a class="anchor" aria-label="anchor" href="#advanced-data-preparation-challenges"><i class="fas fa-link"></i></a>
</h3>
<ol start="16" style="list-style-type: decimal">
<li><p>In the Adult dataset, the <code>education</code> variable contains 16 distinct levels. Reduce these categories into broader groups such as “No Diploma,” “High School Graduate,” “Some College,” and “Postgraduate.” Implement this transformation using the <code><a href="https://forcats.tidyverse.org/reference/fct_collapse.html">fct_collapse()</a></code> function.</p></li>
<li><p>The <code>capital.gain</code> and <code>capital.loss</code> variables represent financial assets. Create a new variable <code>net.capital</code> that computes the difference between <code>capital.gain</code> and <code>capital.loss</code>. Analyze its distribution.</p></li>
<li><p>Perform Min-Max scaling on the numerical variables in the Adult dataset (<code>age</code>, <code>capital.gain</code>, <code>capital.loss</code>, <code>hours.per.week</code>). Use the <code>mutate()</code> function to apply this transformation.</p></li>
<li><p>Perform Z-score normalization on the same set of numerical variables. Compare the results with Min-Max scaling. In what scenarios would one approach be preferable over the other?</p></li>
<li><p>Construct a logistic regression model to predict whether an individual earns more than 50K (<code>&gt;50K</code>) based on selected numerical features (<code>age</code>, <code>education.num</code>, <code>hours.per.week</code>). Preprocess the data accordingly and interpret the coefficients of the model.</p></li>
</ol>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="chapter-intro-DS.html"><span class="header-section-number">2</span> Introduction to Data Science</a></div>
<div class="next"><a href="chapter-EDA.html"><span class="header-section-number">4</span> Exploratory Data Analysis</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chapter-data-prep"><span class="header-section-number">3</span> Data Preparation</a></li>
<li>
<a class="nav-link" href="#problem-understanding"><span class="header-section-number">3.1</span> Problem Understanding</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#objectives-and-key-questions">Objectives and Key Questions</a></li>
<li><a class="nav-link" href="#framing-the-problem-as-a-data-science-task">Framing the Problem as a Data Science Task</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#diamonds-dataset-overview"><span class="header-section-number">3.2</span> diamonds Dataset Overview</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#types-of-features-in-the-diamonds-dataset">Types of Features in the diamonds Dataset</a></li>
<li><a class="nav-link" href="#key-considerations-for-data-preparation">Key Considerations for Data Preparation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#Data-pre-outliers"><span class="header-section-number">3.3</span> Outliers</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#identifying-outliers-using-visualization-techniques">Identifying Outliers Using Visualization Techniques</a></li>
<li><a class="nav-link" href="#handling-outliers-best-practices">Handling Outliers: Best Practices</a></li>
<li><a class="nav-link" href="#expanded-code-example-handling-outliers-in-r">Expanded Code Example: Handling Outliers in R</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#missing-values"><span class="header-section-number">3.4</span> Missing Values</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#imputation-techniques">Imputation Techniques</a></li>
<li><a class="nav-link" href="#best-practices">Best Practices</a></li>
</ul>
</li>
<li><a class="nav-link" href="#feature-scaling"><span class="header-section-number">3.5</span> Feature Scaling</a></li>
<li><a class="nav-link" href="#min-max-scaling"><span class="header-section-number">3.6</span> Min-Max Scaling</a></li>
<li><a class="nav-link" href="#z-score-scaling"><span class="header-section-number">3.7</span> Z-score Scaling</a></li>
<li>
<a class="nav-link" href="#how-to-reexpress-categorical-field-values"><span class="header-section-number">3.8</span> How to Reexpress Categorical Field Values</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#why-reexpress-categorical-fields"><span class="header-section-number">3.8.1</span> Why Reexpress Categorical Fields?</a></li>
<li><a class="nav-link" href="#techniques-for-reexpressing-categorical-variables"><span class="header-section-number">3.8.2</span> Techniques for Reexpressing Categorical Variables</a></li>
<li><a class="nav-link" href="#choosing-the-right-encoding-technique"><span class="header-section-number">3.8.3</span> Choosing the Right Encoding Technique</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#Data-pre-adult"><span class="header-section-number">3.9</span> Case Study: Who Can Earn More Than $50K Per Year?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#overview-of-the-dataset">Overview of the Dataset</a></li>
<li><a class="nav-link" href="#missing-values-1"><span class="header-section-number">3.9.1</span> Missing Values</a></li>
<li><a class="nav-link" href="#encoding-categorical-variables"><span class="header-section-number">3.9.2</span> Encoding Categorical Variables</a></li>
<li><a class="nav-link" href="#outliers"><span class="header-section-number">3.9.3</span> Outliers</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#exercises-2"><span class="header-section-number">3.10</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#understanding-data-types">Understanding Data Types</a></li>
<li><a class="nav-link" href="#exploring-the-diamonds-dataset">Exploring the diamonds Dataset</a></li>
<li><a class="nav-link" href="#detecting-and-handling-outliers">Detecting and Handling Outliers</a></li>
<li><a class="nav-link" href="#encoding-categorical-variables-1">Encoding Categorical Variables</a></li>
<li><a class="nav-link" href="#analyzing-the-adult-dataset">Analyzing the Adult Dataset</a></li>
<li><a class="nav-link" href="#feature-engineering-challenge">Feature Engineering Challenge</a></li>
<li><a class="nav-link" href="#advanced-data-preparation-challenges">Advanced Data Preparation Challenges</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/RezaMoammadi/Book-Data-Science/blob/master/data-preparation.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/RezaMoammadi/Book-Data-Science/edit/master/data-preparation.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Uncovering Data Science with R</strong>" was written by Reza Mohammadi. It was last built on 2025-02-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
