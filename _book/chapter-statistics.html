<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Statistical Inference and Hypothesis Testing | Uncovering Data Science with R</title>
<meta name="author" content="Reza Mohammadi">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Chapter 5 Statistical Inference and Hypothesis Testing | Uncovering Data Science with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://uncovering-data-science.netlify.app/chapter-statistics.html">
<meta property="og:image" content="https://uncovering-data-science.netlify.app/images/cover.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Statistical Inference and Hypothesis Testing | Uncovering Data Science with R">
<meta name="twitter:image" content="https://uncovering-data-science.netlify.app/images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Statistical inference bridges the gap between what we observe in a sample and what we want to understand about the population. While exploratory data analysis (EDA) helps us identify patterns and...">
<meta property="og:description" content="Statistical inference bridges the gap between what we observe in a sample and what we want to understand about the population. While exploratory data analysis (EDA) helps us identify patterns and...">
<meta name="twitter:description" content="Statistical inference bridges the gap between what we observe in a sample and what we want to understand about the population. While exploratory data analysis (EDA) helps us identify patterns and...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Uncovering Data Science with R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="chapter-into-R.html"><span class="header-section-number">1</span> The Basics for R</a></li>
<li><a class="" href="chapter-intro-DS.html"><span class="header-section-number">2</span> Introduction to Data Science</a></li>
<li><a class="" href="chapter-data-prep.html"><span class="header-section-number">3</span> Data Preparation</a></li>
<li><a class="" href="chapter-EDA.html"><span class="header-section-number">4</span> Exploratory Data Analysis</a></li>
<li><a class="active" href="chapter-statistics.html"><span class="header-section-number">5</span> Statistical Inference and Hypothesis Testing</a></li>
<li><a class="" href="chapter-modeling.html"><span class="header-section-number">6</span> Preparing Data for Modeling</a></li>
<li><a class="" href="chapter-knn.html"><span class="header-section-number">7</span> Classification using k-Nearest Neighbors</a></li>
<li><a class="" href="chapter-evaluation.html"><span class="header-section-number">8</span> Model Evaluation</a></li>
<li><a class="" href="chapter-bayes.html"><span class="header-section-number">9</span> Naive Bayes Classifier</a></li>
<li><a class="" href="chapter-regression.html"><span class="header-section-number">10</span> Regression Modeling: From Basics to Advanced Techniques</a></li>
<li><a class="" href="chapter-tree.html"><span class="header-section-number">11</span> Decision Trees and Random Forests</a></li>
<li><a class="" href="chapter-nn.html"><span class="header-section-number">12</span> Neural Networks: The Building Blocks of Artificial Intelligence</a></li>
<li><a class="" href="chapter-cluster.html"><span class="header-section-number">13</span> Clustering</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/RezaMoammadi/Book-Data-Science">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chapter-statistics" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Statistical Inference and Hypothesis Testing<a class="anchor" aria-label="anchor" href="#chapter-statistics"><i class="fas fa-link"></i></a>
</h1>
<p>Statistical inference bridges the gap between <em>what we observe in a sample</em> and <em>what we want to understand about the population</em>. While exploratory data analysis (EDA) helps us identify patterns and relationships, statistical inference allows us to determine whether these patterns hold beyond our sample—or whether they could have arisen by chance. In this chapter, we transition from <em>exploring</em> data to <em>validating</em> insights through estimation, hypothesis testing, and quantifying uncertainty.</p>
<p>The goals of statistical inference can be summarized into three fundamental tasks:</p>
<ol style="list-style-type: decimal">
<li>
<em>Estimating population characteristics</em>, such as averages or proportions, based on sample data.<br>
</li>
<li>
<em>Quantifying uncertainty</em> to measure how confident we can be in our results.<br>
</li>
<li>
<em>Testing hypotheses</em> to evaluate whether observed patterns are statistically meaningful or simply due to random variation.</li>
</ol>
<p>These tasks form the foundation of <em>data-driven decision-making</em>, enabling us to distinguish meaningful insights from statistical noise. In this chapter, we will explore these three pillars—estimation, uncertainty, and hypothesis testing—using intuitive explanations and practical examples.</p>
<p>But statistical inference isn’t just about applying formulas—it’s also about <em>critical thinking</em>. By the end of this chapter, you’ll develop two essential skills:</p>
<ul>
<li>
<em>How to detect statistical misuses and misleading claims</em>, helping you critically evaluate data-driven arguments.<br>
</li>
<li>
<em>How to avoid common pitfalls in statistical analysis</em>, ensuring that your own conclusions are both sound and defensible.</li>
</ul>
<p>For those interested in the art of identifying statistical manipulation, Darrell Huff’s classic book, <a href="https://www.goodreads.com/book/show/51291.How_to_Lie_with_Statistics"><em>How to Lie with Statistics</em></a>, offers timeless lessons in statistical skepticism. Understanding these techniques is valuable not just for avoiding errors but also for recognizing when data is being used to mislead.</p>
<p>Let’s dive in and learn how to make statistical inferences with confidence, curiosity, and a healthy dose of skepticism.</p>
<div id="estimation-using-data-to-make-predictions" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Estimation: Using Data to Make Predictions<a class="anchor" aria-label="anchor" href="#estimation-using-data-to-make-predictions"><i class="fas fa-link"></i></a>
</h2>
<p>Estimation is a fundamental aspect of statistical inference that allows us to make informed guesses about a population based on a sample. Rather than relying on the entire population, which is often impractical, we use sample data to estimate key characteristics such as averages or proportions. For instance, in the churn dataset, we might want to estimate:</p>
<ul>
<li>The <em>average number of customer service calls</em> among churners.<br>
</li>
<li>The <em>proportion of customers</em> subscribed to the International Plan.</li>
</ul>
<p>There are two main types of estimation:</p>
<ol style="list-style-type: decimal">
<li>
<em>Point estimation</em> provides a single best guess for a population parameter, such as using the sample mean to estimate the population mean.<br>
</li>
<li>
<em>Interval estimation</em> gives a range of plausible values (a confidence interval) within which the true population parameter is likely to fall.</li>
</ol>
<p>Let’s explore some examples:</p>
<div class="example">
<p><span id="exm:ex-est-churn-proportion" class="example"><strong>Example 5.1  </strong></span>To estimate the <em>proportion of churners</em> in the dataset, we use the <em>sample proportion</em> as a point estimate for the population proportion. Here’s how to calculate it in R:</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">churn</span><span class="op">$</span><span class="va">churn</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="st">"yes"</span><span class="op">]</span></span>
<span>      <span class="va">yes</span> </span>
<span>   <span class="fl">0.1414</span></span></code></pre></div>
<p>The estimated proportion of churners in the dataset is 0.14, serving as our best guess for the proportion of churners in the population.</p>
</div>
<div class="example">
<p><span id="exm:ex-est-service-call" class="example"><strong>Example 5.2  </strong></span>Now, let’s estimate the <em>average number of customer service calls</em> for customers who churned. The <em>sample mean</em> serves as a point estimate for the population mean:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="chapter-statistics.html#cb103-1" tabindex="-1"></a><span class="co"># Filter churners</span></span>
<span id="cb103-2"><a href="chapter-statistics.html#cb103-2" tabindex="-1"></a>churned_customers <span class="ot">&lt;-</span> churn[churn<span class="sc">$</span>churn <span class="sc">==</span> <span class="st">"yes"</span>, ]</span>
<span id="cb103-3"><a href="chapter-statistics.html#cb103-3" tabindex="-1"></a></span>
<span id="cb103-4"><a href="chapter-statistics.html#cb103-4" tabindex="-1"></a><span class="co"># Calculate the mean</span></span>
<span id="cb103-5"><a href="chapter-statistics.html#cb103-5" tabindex="-1"></a>mean_calls <span class="ot">&lt;-</span> <span class="fu">mean</span>(churned_customers<span class="sc">$</span>customer.calls)</span>
<span id="cb103-6"><a href="chapter-statistics.html#cb103-6" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Point Estimate: Average Customer Service Calls for Churners:"</span>, mean_calls)</span>
<span id="cb103-7"><a href="chapter-statistics.html#cb103-7" tabindex="-1"></a>   Point Estimate<span class="sc">:</span> Average Customer Service Calls <span class="cf">for</span> Churners<span class="sc">:</span> <span class="fl">2.254597</span></span></code></pre></div>
<p>If the sample mean is <strong>4 calls</strong>, this would be our best estimate of the average number of customer service calls among all churners in the population.</p>
</div>
<blockquote>
<p><em>While point estimates are useful, they provide no information about uncertainty. Confidence intervals help quantify the precision of an estimate, which we explore next.</em></p>
</blockquote>
</div>
<div id="statistics-confidence-interval" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Quantifying Uncertainty: Confidence Intervals<a class="anchor" aria-label="anchor" href="#statistics-confidence-interval"><i class="fas fa-link"></i></a>
</h2>
<p>Confidence intervals help quantify uncertainty when estimating population parameters. Instead of simply stating that “the average number of customer service calls is 4,” a confidence interval provides a range, such as “we are 95% confident that the true average is between 3.8 and 4.2.” This range accounts for sampling variability, offering a clearer picture of how reliable the estimate is.</p>
<p>A confidence interval consists of a point estimate, such as a sample mean or proportion, and a margin of error, which accounts for uncertainty. The general form of a confidence interval is:</p>
<p><span class="math display">\[
\text{Point Estimate}  \pm \text{Margin of Error}
\]</span></p>
<p>For a population mean, the confidence interval is calculated as:</p>
<p><span class="math display">\[
\bar{x} \pm z_{\frac{\alpha}{2}} \times \left( \frac{s}{\sqrt{n}} \right),
\]</span></p>
<p>where <span class="math inline">\(\bar{x}\)</span> is the sample mean, <span class="math inline">\(z_{\frac{\alpha}{2}}\)</span> is a critical value from the standard normal distribution (such as 1.96 for a 95% confidence level), <span class="math inline">\(s\)</span> is the sample standard deviation, and <span class="math inline">\(n\)</span> is the sample size. This concept is illustrated in Figure <a href="chapter-statistics.html#fig:confidence-interval">5.1</a>, where the interval is centered around the point estimate and its width depends on the margin of error.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:confidence-interval"></span>
<img src="images/confidence_interval.png" alt="Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter." width="80%"><p class="caption">
Figure 5.1: Confidence interval for the population mean. The interval is centered around the point estimate, with the width determined by the margin of error. The confidence level specifies the probability that the interval contains the true population parameter.
</p>
</div>
<p>Several factors influence the width of a confidence interval. Larger sample sizes generally yield narrower intervals, increasing precision, while higher variability in the data results in wider intervals. The choice of confidence level also affects the width; for example, a 99% confidence level produces a wider interval than a 90% confidence level because it must capture more possible values.</p>
<p>Imagine you want to estimate the average height of all students in a university. If you survey only 10 students, your confidence interval will be wide because you have little data. But if you survey 1,000 students, your estimate becomes much more precise, and the confidence interval shrinks. This illustrates why larger sample sizes lead to more reliable estimates—more data reduces uncertainty and results in tighter confidence intervals.</p>
<p>To illustrate, suppose we want to estimate the average number of customer service calls among churners with 95% confidence:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="chapter-statistics.html#cb104-1" tabindex="-1"></a><span class="co"># Calculate mean and standard error</span></span>
<span id="cb104-2"><a href="chapter-statistics.html#cb104-2" tabindex="-1"></a>mean_calls <span class="ot">&lt;-</span> <span class="fu">mean</span>(churned_customers<span class="sc">$</span>customer.calls)</span>
<span id="cb104-3"><a href="chapter-statistics.html#cb104-3" tabindex="-1"></a>se_calls <span class="ot">&lt;-</span> <span class="fu">sd</span>(churned_customers<span class="sc">$</span>customer.calls) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">nrow</span>(churned_customers))</span>
<span id="cb104-4"><a href="chapter-statistics.html#cb104-4" tabindex="-1"></a></span>
<span id="cb104-5"><a href="chapter-statistics.html#cb104-5" tabindex="-1"></a><span class="co"># Confidence Interval</span></span>
<span id="cb104-6"><a href="chapter-statistics.html#cb104-6" tabindex="-1"></a>z_score <span class="ot">&lt;-</span> <span class="fl">1.96</span>  <span class="co"># For 95% confidence</span></span>
<span id="cb104-7"><a href="chapter-statistics.html#cb104-7" tabindex="-1"></a>ci_lower <span class="ot">&lt;-</span> mean_calls <span class="sc">-</span> z_score <span class="sc">*</span> se_calls</span>
<span id="cb104-8"><a href="chapter-statistics.html#cb104-8" tabindex="-1"></a>ci_upper <span class="ot">&lt;-</span> mean_calls <span class="sc">+</span> z_score <span class="sc">*</span> se_calls</span>
<span id="cb104-9"><a href="chapter-statistics.html#cb104-9" tabindex="-1"></a></span>
<span id="cb104-10"><a href="chapter-statistics.html#cb104-10" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"95% Confidence Interval: ["</span>, ci_lower, <span class="st">","</span>, ci_upper, <span class="st">"]"</span>)</span>
<span id="cb104-11"><a href="chapter-statistics.html#cb104-11" tabindex="-1"></a>   <span class="dv">95</span>% Confidence Interval<span class="sc">:</span> [ <span class="fl">2.120737</span> , <span class="fl">2.388457</span> ]</span></code></pre></div>
<p>If the computed interval is [2.12, 2.39], we can say with 95% confidence that the true average number of service calls for churners falls within this range.</p>
<p>For smaller sample sizes, it is better to use the t-distribution instead of the normal distribution, as it accounts for the added uncertainty when estimating the population standard deviation. This adjustment is applied automatically in R when using the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="chapter-statistics.html#cb105-1" tabindex="-1"></a><span class="fu">t.test</span>(churned_customers<span class="sc">$</span>customer.calls, <span class="at">conf.level =</span> <span class="fl">0.95</span>)<span class="sc">$</span>conf.int</span>
<span id="cb105-2"><a href="chapter-statistics.html#cb105-2" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">2.120509</span> <span class="fl">2.388685</span></span>
<span id="cb105-3"><a href="chapter-statistics.html#cb105-3" tabindex="-1"></a>   <span class="fu">attr</span>(,<span class="st">"conf.level"</span>)</span>
<span id="cb105-4"><a href="chapter-statistics.html#cb105-4" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.95</span></span></code></pre></div>
<p>Confidence intervals are particularly useful for comparing groups. If confidence intervals for two groups, such as churners and non-churners, do not overlap significantly, it suggests meaningful differences in behavior. By providing a range rather than a single estimate, confidence intervals help balance precision and uncertainty, making them a valuable tool in statistical inference.</p>
</div>
<div id="hypothesis-testing" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Hypothesis Testing<a class="anchor" aria-label="anchor" href="#hypothesis-testing"><i class="fas fa-link"></i></a>
</h2>
<p>Hypothesis testing provides a structured framework for evaluating claims about population parameters using sample data. It helps us assess whether patterns observed during exploratory analysis are statistically significant or simply the result of random variation. This method is fundamental to data-driven decision-making, enabling us to distinguish meaningful insights from noise.</p>
<p>At its core, hypothesis testing involves two competing statements about a population parameter:</p>
<ul>
<li>The <em>null hypothesis</em> (<span class="math inline">\(H_0\)</span>) represents the default assumption or status quo, often stating that there is no difference between groups, no effect of a treatment, or no relationship between variables.<br>
</li>
<li>The <em>alternative hypothesis</em> (<span class="math inline">\(H_a\)</span>) challenges <span class="math inline">\(H_0\)</span>, suggesting that a difference, effect, or relationship does exist.</li>
</ul>
<p>Using sample evidence, we decide whether to:</p>
<ul>
<li>
<em>Reject <span class="math inline">\(H_0\)</span></em> and conclude that the data supports <span class="math inline">\(H_a\)</span>.<br>
</li>
<li>
<em>Fail to reject <span class="math inline">\(H_0\)</span></em>, meaning the evidence is insufficient to dismiss <span class="math inline">\(H_0\)</span>, though this does not prove it to be true.</li>
</ul>
<p>The strength of the evidence against <span class="math inline">\(H_0\)</span> is quantified using the <em>p</em>-value, which represents the probability of obtaining the observed data—or something more extreme—if <span class="math inline">\(H_0\)</span> were true. A smaller <em>p</em>-value suggests stronger evidence against <span class="math inline">\(H_0\)</span>.</p>
<ul>
<li>If <span class="math inline">\(p &lt; 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span> and conclude there is statistical evidence for <span class="math inline">\(H_a\)</span>.<br>
</li>
<li>If <span class="math inline">\(p &gt; 0.05\)</span>, we fail to reject <span class="math inline">\(H_0\)</span>, meaning the evidence is not strong enough to support <span class="math inline">\(H_a\)</span>.</li>
</ul>
<p>The threshold for decision-making is called the <em>significance level</em> (<span class="math inline">\(\alpha\)</span>), typically set at 0.05 (5%). This value represents the maximum probability of making a <em>Type I error</em>—incorrectly rejecting <span class="math inline">\(H_0\)</span>. In fields where errors have serious consequences, such as medicine or aerospace, stricter thresholds (e.g., <span class="math inline">\(\alpha = 0.01\)</span>) are often used.</p>
<p>A simple takeaway, often emphasized in hypothesis testing, is:</p>
<div style="text-align: center; font-style: italic;">
<p>Reject <span class="math inline">\(H_0\)</span> if the <span class="math inline">\(p\)</span>-value &lt; <span class="math inline">\(\alpha\)</span>.</p>
</div>
<p>For example:<br>
- If <span class="math inline">\(p = 0.03\)</span> and <span class="math inline">\(\alpha = 0.05\)</span>, we reject <span class="math inline">\(H_0\)</span> because <span class="math inline">\(p &lt; \alpha\)</span>.<br>
- If <span class="math inline">\(p = 0.12\)</span>, we fail to reject <span class="math inline">\(H_0\)</span> because <span class="math inline">\(p &gt; \alpha\)</span>.</p>
<p>Although <em>p</em>-values provide a structured way to make decisions, they have limitations. A small <em>p</em>-value does not necessarily mean a result is practically important—it only indicates statistical significance. Large datasets can generate small <em>p</em>-values for trivial effects, while small datasets may fail to detect meaningful differences. Additionally, the binary reject/fail-to-reject approach can sometimes oversimplify interpretation.</p>
<div id="types-of-hypothesis-tests" class="section level3" number="5.3.1">
<h3>
<span class="header-section-number">5.3.1</span> Types of Hypothesis Tests<a class="anchor" aria-label="anchor" href="#types-of-hypothesis-tests"><i class="fas fa-link"></i></a>
</h3>
<p>Depending on the research question, hypothesis tests can take different forms:</p>
<ul>
<li>
<em>Left-tailed test</em>: The alternative hypothesis states that the parameter is <em>less than</em> a specified value (<span class="math inline">\(H_a: \theta &lt; \theta_0\)</span>). Example: Testing whether the average number of customer service calls is <em>less than</em> 3.<br>
</li>
<li>
<em>Right-tailed test</em>: The alternative hypothesis states that the parameter is <em>greater than</em> a specified value (<span class="math inline">\(H_a: \theta &gt; \theta_0\)</span>). Example: Testing whether the churn rate is <em>greater than</em> 30%.<br>
</li>
<li>
<em>Two-tailed test</em>: The alternative hypothesis states that the parameter is <em>not equal to</em> a specified value (<span class="math inline">\(H_a: \theta \neq \theta_0\)</span>), evaluating deviations in either direction. Example: Testing whether the mean monthly charges differ from $50.</li>
</ul>
<p>A useful analogy for hypothesis testing is a criminal trial. The <em>null hypothesis</em> (<span class="math inline">\(H_0\)</span>) represents the presumption of innocence, while the <em>alternative hypothesis</em> (<span class="math inline">\(H_a\)</span>) represents guilt. The jury weighs the evidence and either rejects <span class="math inline">\(H_0\)</span> (convicts the defendant) or fails to reject <span class="math inline">\(H_0\)</span> (acquits due to insufficient evidence). Just as juries can make errors, hypothesis tests also have two types of errors summarized in Table <a href="chapter-statistics.html#tab:hypothesis-errors">5.1</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:hypothesis-errors">Table 5.1: </span> Possible outcomes of hypothesis testing with two correct decisions and two types of errors.</caption>
<colgroup>
<col width="26%">
<col width="37%">
<col width="36%">
</colgroup>
<thead><tr>
<th><em>Decision</em></th>
<th><em>Reality: <span class="math inline">\(H_0\)</span> is True</em></th>
<th><em>Reality: <span class="math inline">\(H_0\)</span> is False</em></th>
</tr></thead>
<tbody>
<tr>
<td>Fail to Reject <span class="math inline">\(H_0\)</span>
</td>
<td><span style="color: green;"><em>Correct Decision</em>: Acquit an innocent person.</span></td>
<td><span style="color: red;"><em>Type II Error (<span class="math inline">\(\beta\)</span>)</em>: Acquit a guilty person.</span></td>
</tr>
<tr>
<td>Reject <span class="math inline">\(H_0\)</span>
</td>
<td><span style="color: red;"><em>Type I Error (<span class="math inline">\(\alpha\)</span>)</em>: Convict an innocent person.</span></td>
<td><span style="color: green;"><em>Correct Decision</em>: Convict a guilty person.</span></td>
</tr>
</tbody>
</table></div>
<p>A <em>Type I Error</em> (<span class="math inline">\(\alpha\)</span>) occurs when <span class="math inline">\(H_0\)</span> is rejected even though it is true—similar to convicting an innocent person. A <em>Type II Error</em> (<span class="math inline">\(\beta\)</span>) happens when <span class="math inline">\(H_0\)</span> is not rejected even though it is false—similar to acquitting a guilty person. The probability of a Type I error is controlled by the chosen significance level (<span class="math inline">\(\alpha\)</span>), while the probability of a Type II error depends on factors like sample size and test sensitivity.</p>
</div>
<div id="common-hypothesis-tests" class="section level3 unnumbered">
<h3>Common Hypothesis Tests<a class="anchor" aria-label="anchor" href="#common-hypothesis-tests"><i class="fas fa-link"></i></a>
</h3>
<p>There are several widely used hypothesis tests, as listed in Table <a href="chapter-statistics.html#tab:hypothesis-errors">5.1</a>, each suited to different types of data.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:hypothesis-test">Table 5.2: </span> Seven commonly used hypothesis tests, their null hypotheses (<span class="math inline">\(H_0\)</span>), and the types of variables they apply to.</caption>
<colgroup>
<col width="24%">
<col width="32%">
<col width="42%">
</colgroup>
<thead><tr>
<th>Test</th>
<th><span class="math inline">\(H_0\)</span></th>
<th>Can be used for</th>
</tr></thead>
<tbody>
<tr>
<td>One-sample t-test</td>
<td><span class="math inline">\(H_0: \mu = \mu_0\)</span></td>
<td>A numerical variable</td>
</tr>
<tr>
<td>Test for Proportion</td>
<td><span class="math inline">\(H_0: \pi = \pi_0\)</span></td>
<td>A categorical variable</td>
</tr>
<tr>
<td>Two-sample t-test</td>
<td><span class="math inline">\(H_0: \mu_1 = \mu_2\)</span></td>
<td>A numerical and a binary variable</td>
</tr>
<tr>
<td>Two-sample Z-test</td>
<td><span class="math inline">\(H_0: \pi_1 = \pi_2\)</span></td>
<td>Two binary variables</td>
</tr>
<tr>
<td>Chi-square Test</td>
<td><span class="math inline">\(H_0: \pi_1 = \pi_2 = \pi_3\)</span></td>
<td>Two categorical variables (with &gt; 2 categories)</td>
</tr>
<tr>
<td>Analysis of Variance (ANOVA)</td>
<td><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3\)</span></td>
<td>A numerical and a categorical variable</td>
</tr>
<tr>
<td>Correlation Test</td>
<td><span class="math inline">\(H_0: \rho = 0\)</span></td>
<td>Two numerical variables</td>
</tr>
</tbody>
</table></div>
<p>Each test serves a specific purpose. The <em>t-test</em> compares means, the <em>Z-test</em> compares proportions, the <em>Chi-square test</em> assesses categorical relationships, and <em>ANOVA</em> compares means across multiple groups. These tests will be explored in the following sections with practical examples.</p>
</div>
</div>
<div id="one-sample-t-test" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> One-sample t-test<a class="anchor" aria-label="anchor" href="#one-sample-t-test"><i class="fas fa-link"></i></a>
</h2>
<p>The one-sample t-test evaluates whether the mean of a numerical variable in a population is equal to a specified value. It is commonly used to compare a sample mean to a benchmark or theoretical expectation. The term “one-sample” reflects that only a single group is being tested against a fixed value, while “t-test” refers to the fact that the test statistic follows a t-distribution, which is used to compute the <em>p</em>-value.</p>
<p>The hypotheses for a one-sample t-test depend on the research question and can be formulated in different ways. A two-tailed test assesses whether the mean differs from a specified value, regardless of direction. A left-tailed test evaluates whether the mean is lower than the specified value, while a right-tailed test examines whether the mean is greater. The mathematical formulation is:</p>
<ul>
<li>
<em>Two-Tailed Test</em>:
<span class="math display">\[
\begin{cases}
H_0:  \mu   =  \mu_0 \\
H_a:  \mu \neq \mu_0
\end{cases}
\]</span>
</li>
<li>
<em>Left-Tailed Test</em>:
<span class="math display">\[
\begin{cases}
H_0:  \mu \geq \mu_0 \\
H_a:  \mu  &lt;   \mu_0
\end{cases}
\]</span>
</li>
<li>
<em>Right-Tailed Test</em>:
<span class="math display">\[
\begin{cases}
H_0:  \mu \leq \mu_0 \\
H_a:  \mu &gt;   \mu_0
\end{cases}
\]</span>
</li>
</ul>
<p>The <em>p</em>-value represents the probability of observing the sample mean, or a more extreme value, under the assumption that the null hypothesis is true. A smaller <em>p</em>-value provides stronger evidence against <span class="math inline">\(H_0\)</span>. If the <em>p</em>-value is less than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), the null hypothesis is rejected, indicating that the sample mean differs significantly from the specified value.</p>
<p>The following example demonstrates how to apply a one-sample t-test in R using the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function.</p>
<div class="example">
<p><span id="exm:ex-one-sample-test" class="example"><strong>Example 5.3  </strong></span>A company assumes that, on average, customers make two service calls before churning. To test whether the actual average number of customer service calls among churners differs from this assumed value, we conduct a one-sample t-test using the <em>churn</em> dataset provided in the <strong>liver</strong> package.</p>
<p>To conduct the test, we set up the following hypotheses:</p>
<ol style="list-style-type: decimal">
<li>
<em>Null Hypothesis (<span class="math inline">\(H_0\)</span>)</em>: <span class="math inline">\(H_0: \mu = 2\)</span> (The average number of customer service calls is 2.)<br>
</li>
<li>
<em>Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</em>: <span class="math inline">\(H_a: \mu \neq 2\)</span> (The average number of customer service calls is not 2.)</li>
</ol>
<p>We can present the hypotheses in mathematical form as:
<span class="math display">\[
\begin{cases}
    H_0: \mu = 2   \\
    H_a: \mu \neq 2  
\end{cases}
\]</span></p>
<p>We begin by loading the <em>churn</em> dataset and filtering the customers who have churned:</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.uva.nl/profile/a.mohammadi">liver</a></span><span class="op">)</span>  <span class="co"># Load the liver package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">churn</span><span class="op">)</span>     <span class="co"># Load the churn dataset</span></span>
<span></span>
<span><span class="co"># Filter churned customers</span></span>
<span><span class="va">churned_customers</span> <span class="op">&lt;-</span> <span class="va">churn</span><span class="op">[</span><span class="va">churn</span><span class="op">$</span><span class="va">churn</span> <span class="op">==</span> <span class="st">"yes"</span>, <span class="op">]</span></span></code></pre></div>
<p>Now, we conduct a two-tailed one-sample t-test in R using the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function; If you want to know more about the functionality of the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function, you can find more by typing <code><a href="https://rdrr.io/r/stats/t.test.html">?t.test</a></code> in the R console.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="chapter-statistics.html#cb107-1" tabindex="-1"></a>t_test <span class="ot">&lt;-</span> <span class="fu">t.test</span>(churned_customers<span class="sc">$</span>customer.calls, <span class="at">mu =</span> <span class="dv">2</span>)</span>
<span id="cb107-2"><a href="chapter-statistics.html#cb107-2" tabindex="-1"></a>t_test</span>
<span id="cb107-3"><a href="chapter-statistics.html#cb107-3" tabindex="-1"></a>   </span>
<span id="cb107-4"><a href="chapter-statistics.html#cb107-4" tabindex="-1"></a>    One Sample t<span class="sc">-</span>test</span>
<span id="cb107-5"><a href="chapter-statistics.html#cb107-5" tabindex="-1"></a>   </span>
<span id="cb107-6"><a href="chapter-statistics.html#cb107-6" tabindex="-1"></a>   data<span class="sc">:</span>  churned_customers<span class="sc">$</span>customer.calls</span>
<span id="cb107-7"><a href="chapter-statistics.html#cb107-7" tabindex="-1"></a>   t <span class="ot">=</span> <span class="fl">3.7278</span>, df <span class="ot">=</span> <span class="dv">706</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">0.0002086</span></span>
<span id="cb107-8"><a href="chapter-statistics.html#cb107-8" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true mean is not equal to <span class="dv">2</span></span>
<span id="cb107-9"><a href="chapter-statistics.html#cb107-9" tabindex="-1"></a>   <span class="dv">95</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb107-10"><a href="chapter-statistics.html#cb107-10" tabindex="-1"></a>    <span class="fl">2.120509</span> <span class="fl">2.388685</span></span>
<span id="cb107-11"><a href="chapter-statistics.html#cb107-11" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb107-12"><a href="chapter-statistics.html#cb107-12" tabindex="-1"></a>   mean of x </span>
<span id="cb107-13"><a href="chapter-statistics.html#cb107-13" tabindex="-1"></a>    <span class="fl">2.254597</span></span></code></pre></div>
<p>The output includes the <em>p</em>-value, test statistic, degrees of freedom, and confidence interval for the population mean. Since the <em>p</em>-value = 2^{-4} is less than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), we reject the null hypothesis (<span class="math inline">\(H_0\)</span>). This would indicate that there is sufficient evidence, at the 5% significance level, to conclude that the true average number of customer service calls differs from 2.</p>
<p>The test also provides a 95% confidence interval, [2.12, 2.39], which represents the range of plausible values for the true population mean. Since 2 is outside this interval, we have further evidence that the true average number of service calls is different from the assumed value. Additionally, the sample mean, 2.25, is reported as the best estimate of the population mean.</p>
<p>Since the sample standard deviation is used in place of the population standard deviation, the test statistic follows a t-distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom. It measures how far the sample mean deviates from the hypothesized mean in terms of standard error. A larger absolute value indicates stronger evidence against <span class="math inline">\(H_0\)</span>.</p>
</div>
<p>The one-sample t-test provides a structured approach for comparing a sample mean to a predefined benchmark. It not only determines statistical significance but also offers additional insights through the confidence interval, sample mean, and test statistic. While statistical significance is important, practical relevance must also be evaluated to determine whether the observed difference has meaningful real-world implications. Even if a statistically significant difference is detected, the magnitude of the difference determines whether it has real-world implications. A deviation of 0.1 calls may be negligible, whereas a difference of two calls could impact customer service strategies.</p>
<p>By integrating statistical inference with domain knowledge, the one-sample t-test allows analysts to determine whether deviations from expectations are both statistically significant and practically meaningful.</p>
</div>
<div id="hypothesis-testing-for-proportion" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Hypothesis Testing for Proportion<a class="anchor" aria-label="anchor" href="#hypothesis-testing-for-proportion"><i class="fas fa-link"></i></a>
</h2>
<p>The <em>test for proportion</em> evaluates whether the proportion (<span class="math inline">\(\pi\)</span>) of a specific category in the population aligns with a hypothesized value (<span class="math inline">\(\pi_0\)</span>). It is particularly useful for binary categorical variables, where observations fall into one of two groups, such as churned vs. not churned. This test helps determine whether an observed sample proportion deviates significantly from a specified benchmark, making it valuable in business and scientific contexts.</p>
<p>For instance, a company might want to assess whether the proportion of churners in the population aligns with an expected value based on historical data or industry standards. The following example demonstrates how to apply the proportion test in R using the <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code> function.</p>
<div class="example">
<p><span id="exm:ex-test-proportion" class="example"><strong>Example 5.4  </strong></span>A company assumes that 15% of its customers churn. To test whether the actual churn rate in the <em>churn</em> dataset differs from this assumption, we conduct a proportion test. The hypotheses are:</p>
<p><span class="math display">\[
\begin{cases}
H_0: \pi  =   0.15 \\
H_a: \pi \neq 0.15
\end{cases}
\]</span></p>
<p>The test is performed in R using the <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code> function. If you would like to explore the details of this function, you can type <code><a href="https://rdrr.io/r/stats/prop.test.html">?prop.test</a></code> in the R console.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="chapter-statistics.html#cb108-1" tabindex="-1"></a>prop_test <span class="ot">&lt;-</span> <span class="fu">prop.test</span>(<span class="at">x =</span> <span class="fu">sum</span>(churn<span class="sc">$</span>churn <span class="sc">==</span> <span class="st">"yes"</span>), </span>
<span id="cb108-2"><a href="chapter-statistics.html#cb108-2" tabindex="-1"></a>                       <span class="at">n =</span> <span class="fu">nrow</span>(churn), </span>
<span id="cb108-3"><a href="chapter-statistics.html#cb108-3" tabindex="-1"></a>                       <span class="at">p =</span> <span class="fl">0.15</span>)</span>
<span id="cb108-4"><a href="chapter-statistics.html#cb108-4" tabindex="-1"></a>prop_test</span>
<span id="cb108-5"><a href="chapter-statistics.html#cb108-5" tabindex="-1"></a>   </span>
<span id="cb108-6"><a href="chapter-statistics.html#cb108-6" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">-</span>sample proportions test with continuity correction</span>
<span id="cb108-7"><a href="chapter-statistics.html#cb108-7" tabindex="-1"></a>   </span>
<span id="cb108-8"><a href="chapter-statistics.html#cb108-8" tabindex="-1"></a>   data<span class="sc">:</span>  <span class="fu">sum</span>(churn<span class="sc">$</span>churn <span class="sc">==</span> <span class="st">"yes"</span>) out of <span class="fu">nrow</span>(churn), null probability <span class="fl">0.15</span></span>
<span id="cb108-9"><a href="chapter-statistics.html#cb108-9" tabindex="-1"></a>   X<span class="sc">-</span>squared <span class="ot">=</span> <span class="fl">2.8333</span>, df <span class="ot">=</span> <span class="dv">1</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">0.09233</span></span>
<span id="cb108-10"><a href="chapter-statistics.html#cb108-10" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true p is not equal to <span class="fl">0.15</span></span>
<span id="cb108-11"><a href="chapter-statistics.html#cb108-11" tabindex="-1"></a>   <span class="dv">95</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb108-12"><a href="chapter-statistics.html#cb108-12" tabindex="-1"></a>    <span class="fl">0.1319201</span> <span class="fl">0.1514362</span></span>
<span id="cb108-13"><a href="chapter-statistics.html#cb108-13" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb108-14"><a href="chapter-statistics.html#cb108-14" tabindex="-1"></a>        p </span>
<span id="cb108-15"><a href="chapter-statistics.html#cb108-15" tabindex="-1"></a>   <span class="fl">0.1414</span></span></code></pre></div>
<p>The output provides key results, including the <em>p</em>-value, confidence interval, and sample proportion. These results are interpreted as follows:</p>
<p>The <em>p</em>-value indicates the probability of obtaining the observed sample proportion if the assumed population proportion were true. Since the <em>p</em>-value = 0.0923, and it is greater than <span class="math inline">\(\alpha = 0.05\)</span>, we do not reject the null hypothesis. This means there is insufficient evidence to conclude that the churn rate in the population differs from 15%. In this case, we report:<br><em>“There is no statistically significant evidence to suggest that the population proportion of churners deviates from 15%.”</em><br>
If the <em>p</em>-value were smaller than 0.05, we would reject the null hypothesis, concluding that the churn rate is significantly different from 15%.</p>
<p>The test also provides a <em>95% confidence interval</em>, [0.13, 0.15], which represents the plausible range for the true population proportion (<span class="math inline">\(\pi\)</span>). If 0.15 lies within this interval, it supports failing to reject <span class="math inline">\(H_0\)</span>. If 0.15 is outside the interval, it strengthens the evidence against <span class="math inline">\(H_0\)</span>.</p>
<p>Additionally, the test reports the <em>sample proportion</em>, 0.14, which is the observed proportion of churners in the dataset. This value serves as an estimate of the true population proportion.</p>
</div>
<p>This test helps assess whether the observed churn rate aligns with the company’s expectation. The <em>p</em>-value determines statistical significance, while the confidence interval and sample proportion provide additional context for interpretation. By considering both statistical results and practical implications, businesses can evaluate whether their assumptions about churn are accurate or require adjustment.</p>
</div>
<div id="two-sample-t-test" class="section level2" number="5.6">
<h2>
<span class="header-section-number">5.6</span> Two-sample T-test<a class="anchor" aria-label="anchor" href="#two-sample-t-test"><i class="fas fa-link"></i></a>
</h2>
<p>The <em>two-sample t-test</em>, also known as Student’s t-test, is a statistical method used to compare the means of a numerical variable between two independent groups. It assesses whether the observed difference between the group means is statistically significant or simply due to random variation. The test is named after <a href="https://en.wikipedia.org/wiki/William_Sealy_Gosset">William Sealy Gosset</a>, who worked at Guinness Brewery in Dublin and published under the pseudonym “Student” to maintain confidentiality regarding statistical quality control methods.</p>
<p>In Section <a href="chapter-EDA.html#EDA-sec-numeric">4.5</a> of the previous chapter, we explored the relationship between <em>International Calls</em> (<code>intl.calls</code>) and churn status using visualizations like box plots and density plots. While visualizations help identify potential differences, statistical testing quantifies the likelihood that these differences are due to chance.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-9-1.png" width="50%"><img src="statistics_files/figure-html/unnamed-chunk-9-2.png" width="50%"></p>
<p>The boxplot (left) and density plot (right) illustrate the distributions of <code>intl.calls</code> for churners and non-churners. While the visualizations suggest only minor differences, we perform a two-sample t-test to assess whether these differences are statistically significant.</p>
<p>To conduct the test, we first establish the hypotheses:</p>
<ul>
<li>
<em>Null Hypothesis (<span class="math inline">\(H_0\)</span>)</em>: The mean number of international calls is the same for churners and non-churners (<span class="math inline">\(\mu_1 = \mu_2\)</span>).</li>
<li>
<em>Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</em>: The mean number of international calls differs between churners and non-churners (<span class="math inline">\(\mu_1 \neq \mu_2\)</span>).</li>
</ul>
<p>This can also be expressed mathematically as:
<span class="math display">\[
\begin{cases}
    H_0: \mu_1 = \mu_2   \\
    H_a: \mu_1 \neq \mu_2
\end{cases}
\]</span></p>
<p>We perform the test in R using the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="chapter-statistics.html#cb109-1" tabindex="-1"></a>t_test_calls <span class="ot">&lt;-</span> <span class="fu">t.test</span>(intl.calls <span class="sc">~</span> churn, <span class="at">data =</span> churn)</span>
<span id="cb109-2"><a href="chapter-statistics.html#cb109-2" tabindex="-1"></a>t_test_calls</span>
<span id="cb109-3"><a href="chapter-statistics.html#cb109-3" tabindex="-1"></a>   </span>
<span id="cb109-4"><a href="chapter-statistics.html#cb109-4" tabindex="-1"></a>    Welch Two Sample t<span class="sc">-</span>test</span>
<span id="cb109-5"><a href="chapter-statistics.html#cb109-5" tabindex="-1"></a>   </span>
<span id="cb109-6"><a href="chapter-statistics.html#cb109-6" tabindex="-1"></a>   data<span class="sc">:</span>  intl.calls by churn</span>
<span id="cb109-7"><a href="chapter-statistics.html#cb109-7" tabindex="-1"></a>   t <span class="ot">=</span> <span class="sc">-</span><span class="fl">3.2138</span>, df <span class="ot">=</span> <span class="fl">931.13</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">0.001355</span></span>
<span id="cb109-8"><a href="chapter-statistics.html#cb109-8" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true difference <span class="cf">in</span> means between group yes and group no is not equal to <span class="dv">0</span></span>
<span id="cb109-9"><a href="chapter-statistics.html#cb109-9" tabindex="-1"></a>   <span class="dv">95</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb109-10"><a href="chapter-statistics.html#cb109-10" tabindex="-1"></a>    <span class="sc">-</span><span class="fl">0.5324872</span> <span class="sc">-</span><span class="fl">0.1287201</span></span>
<span id="cb109-11"><a href="chapter-statistics.html#cb109-11" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb109-12"><a href="chapter-statistics.html#cb109-12" tabindex="-1"></a>   mean <span class="cf">in</span> group yes  mean <span class="cf">in</span> group no </span>
<span id="cb109-13"><a href="chapter-statistics.html#cb109-13" tabindex="-1"></a>            <span class="fl">4.151344</span>          <span class="fl">4.481947</span></span></code></pre></div>
<p>The function evaluates the difference in means between the two groups (<code>churn = "yes"</code> vs. <code>churn = "no"</code>) and provides a <em>p</em>-value, confidence interval, and descriptive statistics.</p>
<p>The <em>p</em>-value = 0.0014. Since this value is less than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), we reject the null hypothesis, concluding that the mean number of international calls differs significantly between churners and non-churners. The <em>95% confidence interval</em> = [-0.53, -0.13] provides a range of plausible values for the true difference in means. If the interval does not include zero, we have statistical evidence that the two groups differ significantly in their average number of international calls. The test output also provides the <em>sample means</em>:<br>
- Mean for churners = 4.15<br>
- Mean for non-churners = 4.48</p>
<p>These values allow direct comparison of international call usage between churners and non-churners. For instance, if churners made an average of 1.5 international calls while non-churners made 2.3 calls, this suggests that churners tend to make fewer international calls.</p>
<p>The two-sample t-test assumes that the two groups are independent and that the variable of interest is normally distributed within each group when sample sizes are small. For larger samples, the Central Limit Theorem ensures the validity of the test even if normality is not strictly met. While minor deviations from normality are generally acceptable, large departures may require alternative tests, such as the Mann-Whitney U test.</p>
<p>From a business perspective, the test results suggest that international call frequency is a relevant factor in churn. Customers who churn tend to make fewer international calls. Companies may explore whether international call costs contribute to customer churn. If higher costs deter international calls, targeted discounts for low-usage customers could encourage engagement and improve retention. However, statistical significance does not always imply practical significance. Even if churners make fewer international calls on average, the actual impact on churn should be evaluated in conjunction with other variables.</p>
<p>Although this example uses a two-tailed test to detect any difference in means, a one-tailed test could be used if the research question specifies a directional hypothesis. For instance, if a company hypothesizes that churners make fewer international calls than non-churners, a one-tailed test could increase the test’s sensitivity.</p>
<p>The two-sample t-test is a powerful and widely used method for comparing group means. It provides a statistical foundation for validating insights suggested by exploratory data analysis. By integrating graphical exploration with hypothesis testing, analysts can make well-informed inferences and derive actionable business insights.</p>
</div>
<div id="two-sample-z-test" class="section level2" number="5.7">
<h2>
<span class="header-section-number">5.7</span> Two-Sample Z-Test<a class="anchor" aria-label="anchor" href="#two-sample-z-test"><i class="fas fa-link"></i></a>
</h2>
<p>In the previous section, we applied the <em>two-sample t-test</em> to compare the mean number of international calls between churners and non-churners. While the t-test is useful for assessing differences in numerical variables, many business and scientific questions involve categorical variables, where proportions rather than means are of interest. The <em>two-sample Z-test</em> is designed to compare the proportions of two independent groups, determining whether the observed difference in proportions is statistically significant. This test is particularly valuable when analyzing binary categorical variables, such as customer churn or subscription status.</p>
<p>In Section <a href="chapter-EDA.html#chapter-EDA-categorical">4.4</a> of the previous chapter, we examined the relationship between the <em>Voice Mail Plan</em> (<code>voice.plan</code>) and churn status using bar plots. While visualizations suggest potential differences in churn rates between customers with and without a Voice Mail Plan, statistical testing quantifies whether these differences are statistically significant.</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-11-1.png" width="50%"><img src="statistics_files/figure-html/unnamed-chunk-11-2.png" width="50%"></p>
<p>The first bar plot (left) shows the raw counts of churners and non-churners across the two categories of <em>Voice Mail Plan</em> (Yes or No), while the second plot (right) displays proportions, allowing direct comparison of churn rates. These visualizations suggest that customers without a Voice Mail Plan may have a higher churn rate, but hypothesis testing is needed to confirm whether this difference is statistically meaningful.</p>
<p>To formally test whether the proportion of churners with a Voice Mail Plan differs from the proportion of non-churners with the plan, we establish the following hypotheses:</p>
<ul>
<li><p><em>Null Hypothesis (<span class="math inline">\(H_0\)</span>)</em>: <span class="math inline">\(\pi_1 = \pi_2\)</span><br>
(The proportions of customers with a Voice Mail Plan are the same for churners and non-churners.)</p></li>
<li><p><em>Alternative Hypothesis (<span class="math inline">\(H_a\)</span>)</em>: <span class="math inline">\(\pi_1 \neq \pi_2\)</span><br>
(The proportions of customers with a Voice Mail Plan differ between churners and non-churners.)</p></li>
</ul>
<p>These can also be expressed mathematically as:
<span class="math display">\[
\begin{cases}
    H_0: \pi_1 = \pi_2   \\
    H_a: \pi_1 \neq \pi_2
\end{cases}
\]</span></p>
<p>To perform the Z-test in R, we begin by creating a contingency table to summarize the counts of customers with and without a Voice Mail Plan in the churner and non-churner groups. This can be done using the <code><a href="https://rdrr.io/r/base/table.html">table()</a></code> function:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="chapter-statistics.html#cb110-1" tabindex="-1"></a>table_plan <span class="ot">=</span> <span class="fu">table</span>(churn<span class="sc">$</span>churn, churn<span class="sc">$</span>voice.plan, <span class="at">dnn =</span> <span class="fu">c</span>(<span class="st">"churn"</span>, <span class="st">"voice.plan"</span>))</span>
<span id="cb110-2"><a href="chapter-statistics.html#cb110-2" tabindex="-1"></a>table_plan</span>
<span id="cb110-3"><a href="chapter-statistics.html#cb110-3" tabindex="-1"></a>        voice.plan</span>
<span id="cb110-4"><a href="chapter-statistics.html#cb110-4" tabindex="-1"></a>   churn  yes   no</span>
<span id="cb110-5"><a href="chapter-statistics.html#cb110-5" tabindex="-1"></a>     yes  <span class="dv">102</span>  <span class="dv">605</span></span>
<span id="cb110-6"><a href="chapter-statistics.html#cb110-6" tabindex="-1"></a>     no  <span class="dv">1221</span> <span class="dv">3072</span></span></code></pre></div>
<p>This table displays the count of churners and non-churners with and without a Voice Mail Plan. To conduct the Z-test, we use the <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code> function:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="chapter-statistics.html#cb111-1" tabindex="-1"></a>z_test <span class="ot">=</span> <span class="fu">prop.test</span>(table_plan)</span>
<span id="cb111-2"><a href="chapter-statistics.html#cb111-2" tabindex="-1"></a>z_test</span>
<span id="cb111-3"><a href="chapter-statistics.html#cb111-3" tabindex="-1"></a>   </span>
<span id="cb111-4"><a href="chapter-statistics.html#cb111-4" tabindex="-1"></a>    <span class="dv">2</span><span class="sc">-</span>sample test <span class="cf">for</span> equality of proportions with continuity correction</span>
<span id="cb111-5"><a href="chapter-statistics.html#cb111-5" tabindex="-1"></a>   </span>
<span id="cb111-6"><a href="chapter-statistics.html#cb111-6" tabindex="-1"></a>   data<span class="sc">:</span>  table_plan</span>
<span id="cb111-7"><a href="chapter-statistics.html#cb111-7" tabindex="-1"></a>   X<span class="sc">-</span>squared <span class="ot">=</span> <span class="fl">60.552</span>, df <span class="ot">=</span> <span class="dv">1</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">7.165e-15</span></span>
<span id="cb111-8"><a href="chapter-statistics.html#cb111-8" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> two.sided</span>
<span id="cb111-9"><a href="chapter-statistics.html#cb111-9" tabindex="-1"></a>   <span class="dv">95</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb111-10"><a href="chapter-statistics.html#cb111-10" tabindex="-1"></a>    <span class="sc">-</span><span class="fl">0.1701734</span> <span class="sc">-</span><span class="fl">0.1101165</span></span>
<span id="cb111-11"><a href="chapter-statistics.html#cb111-11" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb111-12"><a href="chapter-statistics.html#cb111-12" tabindex="-1"></a>      prop <span class="dv">1</span>    prop <span class="dv">2</span> </span>
<span id="cb111-13"><a href="chapter-statistics.html#cb111-13" tabindex="-1"></a>   <span class="fl">0.1442716</span> <span class="fl">0.2844165</span></span></code></pre></div>
<p>The output provides the <em>p</em>-value, confidence interval, and sample proportions. Since the <em>p</em>-value (0) is smaller than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), we reject the null hypothesis. This result suggests that the proportion of customers with a Voice Mail Plan differs significantly between churners and non-churners.</p>
<p>The test also provides a <em>95% confidence interval</em> = [-0.1702, -0.1101] for the difference in proportions. Since this interval does not include zero, it reinforces the conclusion that the difference is statistically significant. Additionally, the sample proportions—0.1443 for churners and 0.2844 for non-churners—provide insight into the magnitude of this difference.</p>
<p>From a business perspective, this finding suggests that customers without a Voice Mail Plan may be more likely to churn. Companies could leverage this information by encouraging Voice Mail Plan subscriptions among at-risk customers or investigating whether the plan improves customer satisfaction and retention. Companies could leverage this information by encouraging Voice Mail Plan subscriptions among at-risk customers or investigating whether the plan improves customer satisfaction and retention. Although the Z-test shows a statistically significant difference, businesses should evaluate whether promoting the Voice Mail Plan meaningfully reduces churn rates and justifies marketing investment.</p>
<p>The two-sample Z-test provides a formal approach to comparing proportions between groups, complementing exploratory data analysis. By integrating statistical testing with business insights, companies can validate patterns and take targeted actions to reduce churn.</p>
</div>
<div id="chi-square-test" class="section level2" number="5.8">
<h2>
<span class="header-section-number">5.8</span> Chi-square Test<a class="anchor" aria-label="anchor" href="#chi-square-test"><i class="fas fa-link"></i></a>
</h2>
<p>While the <em>two-sample Z-test</em> is effective for comparing proportions between two groups, many real-world analyses involve categorical variables with more than two levels. The <em>Chi-square test</em> allows us to assess whether multiple categorical groups are associated, providing a broader framework for understanding categorical relationships. This makes it particularly useful for understanding customer behaviors and business outcomes across multiple categories.</p>
<p>Unlike the Z-test, which focuses on comparing proportions between two groups, the Chi-square test evaluates whether distributions across multiple categories differ significantly from what would be expected under independence. It provides a formal way to test relationships between categorical variables and is widely used in marketing analysis, customer segmentation, and business decision-making.</p>
<p>To illustrate, we examine whether marital status is associated with purchasing a deposit in the <em>bank</em> dataset (available in the <strong>liver</strong> package). This dataset will be revisited in Chapters <a href="chapter-knn.html#chapter-knn">7</a> and <a href="chapter-nn.html#chapter-nn">12</a> for classification modeling. The variable <code>marital</code> has three categories: “divorced,” “married,” and “single,” while the target variable <code>deposit</code> has two categories: “yes” (customers who purchased a deposit) and “no” (customers who did not). Our goal is to determine whether marital status influences deposit purchases.</p>
<p>We begin by visualizing the relationship between <code>marital</code> and <code>deposit</code> using bar plots:</p>
<p><img src="statistics_files/figure-html/unnamed-chunk-14-1.png" width="50%"><img src="statistics_files/figure-html/unnamed-chunk-14-2.png" width="50%"></p>
<p>The first bar plot (left) displays the raw counts of deposit purchases across marital categories, while the second plot (right) presents the relative proportions. Visual inspection suggests differences in deposit purchase rates by marital status, but a statistical test is needed to confirm whether these differences are significant.</p>
<p>We summarize the observed counts in a contingency table:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="chapter-statistics.html#cb112-1" tabindex="-1"></a>table_marital <span class="ot">&lt;-</span> <span class="fu">table</span>(bank<span class="sc">$</span>deposit, bank<span class="sc">$</span>marital, <span class="at">dnn =</span> <span class="fu">c</span>(<span class="st">"deposit"</span>, <span class="st">"marital"</span>))</span>
<span id="cb112-2"><a href="chapter-statistics.html#cb112-2" tabindex="-1"></a>table_marital</span>
<span id="cb112-3"><a href="chapter-statistics.html#cb112-3" tabindex="-1"></a>          marital</span>
<span id="cb112-4"><a href="chapter-statistics.html#cb112-4" tabindex="-1"></a>   deposit divorced married single</span>
<span id="cb112-5"><a href="chapter-statistics.html#cb112-5" tabindex="-1"></a>       no       <span class="dv">451</span>    <span class="dv">2520</span>   <span class="dv">1029</span></span>
<span id="cb112-6"><a href="chapter-statistics.html#cb112-6" tabindex="-1"></a>       yes       <span class="dv">77</span>     <span class="dv">277</span>    <span class="dv">167</span></span></code></pre></div>
<p>To formally test for independence, we define the hypotheses:
<span class="math display">\[
\begin{cases}
    H_0: \pi_{divorced, \ yes} = \pi_{married, \ yes} = \pi_{single, \ yes}  \\
    H_a: At \ least \ one \ of \ the \ claims \ in \ H_0 \ is \ wrong.
\end{cases}
\]</span>
The Chi-square test is applied using the <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code> function:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="chapter-statistics.html#cb113-1" tabindex="-1"></a>chisq_test <span class="ot">&lt;-</span> <span class="fu">chisq.test</span>(table_marital)</span>
<span id="cb113-2"><a href="chapter-statistics.html#cb113-2" tabindex="-1"></a>chisq_test</span>
<span id="cb113-3"><a href="chapter-statistics.html#cb113-3" tabindex="-1"></a>   </span>
<span id="cb113-4"><a href="chapter-statistics.html#cb113-4" tabindex="-1"></a>    Pearson<span class="st">'s Chi-squared test</span></span>
<span id="cb113-5"><a href="chapter-statistics.html#cb113-5" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb113-6"><a href="chapter-statistics.html#cb113-6" tabindex="-1"></a><span class="st">   data:  table_marital</span></span>
<span id="cb113-7"><a href="chapter-statistics.html#cb113-7" tabindex="-1"></a><span class="st">   X-squared = 19.03, df = 2, p-value = 7.374e-05</span></span></code></pre></div>
<p>The output includes the <em>p</em>-value, Chi-square test statistic, degrees of freedom, and expected frequencies under <span class="math inline">\(H_0\)</span>. If the <em>p</em>-value = 7.3735354^{-5} is smaller than <span class="math inline">\(\alpha = 0.05\)</span>, we reject the null hypothesis, concluding that marital status and deposit purchases are not independent. This means that at least one marital group differs significantly from the others in deposit purchase rates.</p>
<p>Examining the expected frequencies can reveal which marital groups contribute most to the observed association. If a particular group has a much higher or lower deposit purchase rate than expected, marketing efforts can be tailored accordingly.</p>
<p>From a business perspective, these findings suggest that banks may benefit from personalizing their marketing strategies based on marital status. For example, if married customers are significantly more likely to purchase deposits, targeted promotional campaigns could emphasize financial planning for families. Conversely, if single customers exhibit lower deposit adoption rates, banks might develop incentive programs tailored to their financial goals.</p>
<p>The Chi-square test is a powerful tool for identifying relationships between categorical variables. By integrating visual analysis, contingency tables, and statistical hypothesis testing, businesses can make data-driven decisions to optimize customer engagement and product offerings.</p>
</div>
<div id="analysis-of-variance-anova-test" class="section level2" number="5.9">
<h2>
<span class="header-section-number">5.9</span> Analysis of Variance (ANOVA) Test<a class="anchor" aria-label="anchor" href="#analysis-of-variance-anova-test"><i class="fas fa-link"></i></a>
</h2>
<p>In the previous sections, we explored hypothesis tests that compare two groups, such as the <em>two-sample t-test</em> and <em>Z-test</em>. However, in many real-world scenarios, categorical variables have more than two levels. In such cases, the <em>Analysis of Variance (ANOVA)</em> provides a systematic way to determine whether a numerical variable differs across multiple groups. It evaluates whether at least one group mean differs significantly from the others. ANOVA is especially useful when analyzing the relationship between a numerical variable and a categorical variable with multiple levels, providing a formal way to determine if the categorical variable impacts the numerical variable. The test relies on the F-distribution to assess whether the observed differences in means are statistically significant.</p>
<p>To illustrate, let’s analyze the relationship between the variable <code>cut</code> and the target variable <code>price</code> in the popular <em>diamonds</em> dataset (available in the <strong>ggplot2</strong> package). See <em>Section X.X</em> for an overview of this dataset. The variable <code>cut</code> has five categories (“Fair,” “Good,” “Very Good,” “Premium,” and “Ideal”), while <code>price</code> is numerical. Our objective is to test whether the mean price of diamonds differs across the five cut categories.</p>
<p>We begin with a box plot to visualize the distribution of diamond prices for each category of <code>cut</code>:</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">cut</span>, y <span class="op">=</span> <span class="va">price</span>, fill <span class="op">=</span> <span class="va">cut</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"palevioletred1"</span>, <span class="st">"darkseagreen1"</span>, <span class="st">"skyblue1"</span>, <span class="st">"gold1"</span>, <span class="st">"lightcoral"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="statistics_files/figure-html/unnamed-chunk-17-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The box plot displays the spread and median prices for diamonds in each cut category. While differences in medians and ranges suggest that cut quality might influence price, statistical testing is required to confirm whether these differences are significant. We apply an ANOVA test to formally assess this relationship.</p>
<p>To test whether the mean prices differ by cut type, we set up the following hypotheses:</p>
<p><span class="math display">\[
\begin{cases}
    H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5 \quad \text{(All group means are equal.)} \\
    H_a: \text{At least one group mean differs from the others.}  
\end{cases}
\]</span></p>
<p>To conduct the ANOVA test in R, we use the <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code> function:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="chapter-statistics.html#cb115-1" tabindex="-1"></a>anova_test <span class="ot">&lt;-</span> <span class="fu">aov</span>(price <span class="sc">~</span> cut, <span class="at">data =</span> diamonds)</span>
<span id="cb115-2"><a href="chapter-statistics.html#cb115-2" tabindex="-1"></a><span class="fu">summary</span>(anova_test)</span>
<span id="cb115-3"><a href="chapter-statistics.html#cb115-3" tabindex="-1"></a>                  Df    Sum Sq   Mean Sq F value <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)    </span>
<span id="cb115-4"><a href="chapter-statistics.html#cb115-4" tabindex="-1"></a>   cut             <span class="dv">4</span> <span class="fl">1.104e+10</span> <span class="fl">2.760e+09</span>   <span class="fl">175.7</span> <span class="sc">&lt;</span><span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb115-5"><a href="chapter-statistics.html#cb115-5" tabindex="-1"></a>   Residuals   <span class="dv">53935</span> <span class="fl">8.474e+11</span> <span class="fl">1.571e+07</span>                   </span>
<span id="cb115-6"><a href="chapter-statistics.html#cb115-6" tabindex="-1"></a>   <span class="sc">---</span></span>
<span id="cb115-7"><a href="chapter-statistics.html#cb115-7" tabindex="-1"></a>   Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span></code></pre></div>
<p>The output provides the test statistic (F-value), degrees of freedom, and the <em>p</em>-value. Since the <em>p</em>-value is smaller than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), we reject the null hypothesis. This indicates that the variable <code>cut</code> has a significant impact on the price of diamonds.</p>
<p>Rejecting <span class="math inline">\(H_0\)</span> in ANOVA does not specify which groups differ. To identify these differences, <em>post-hoc tests</em> such as Tukey’s Honestly Significant Difference (Tukey HSD) test are necessary. These tests control for multiple comparisons while pinpointing significant pairwise differences. In this example, we could apply Tukey’s test to determine which cut categories (e.g., “Ideal” vs. “Good”) drive the observed differences.</p>
<p>Understanding the impact of diamond cut on price is crucial for pricing strategies and consumer insights. If higher-quality cuts command significantly higher prices, retailers may adjust marketing efforts accordingly. Conversely, if certain mid-tier cuts do not show meaningful price differences, companies might reconsider their pricing models to enhance competitiveness.</p>
<p>The ANOVA test provides a structured approach to evaluating whether a categorical variable with multiple levels influences a numerical variable. In this case, the relationship between <code>cut</code> and <code>price</code> suggests that diamond cut type is an important predictor of price, offering valuable insights into how quality impacts cost. By integrating statistical testing with business insights, analysts can determine whether categorical variables have meaningful effects and use this knowledge to inform data-driven decisions.</p>
</div>
<div id="correlation-test" class="section level2" number="5.10">
<h2>
<span class="header-section-number">5.10</span> Correlation Test<a class="anchor" aria-label="anchor" href="#correlation-test"><i class="fas fa-link"></i></a>
</h2>
<p>In the previous sections, we explored hypothesis tests for comparing means and proportions across groups. When analyzing relationships between two numerical variables, correlation testing provides a formal method to assess whether a significant linear association exists. The <em>correlation test</em> evaluates both the strength and direction of the relationship by testing the null hypothesis that the population correlation coefficient (<span class="math inline">\(\rho\)</span>) is equal to zero. This test is particularly useful in understanding how two continuous variables co-vary, which can inform business strategies, pricing models, and predictive analytics.</p>
<p>To illustrate, we examine whether a significant relationship exists between <code>carat</code> (diamond weight) and <code>price</code> in the <em>diamonds</em> dataset (available in the <strong>ggplot2</strong> package). Since larger diamonds are generally more expensive, we expect a positive correlation between these variables. A scatter plot provides an initial visual assessment of the relationship:</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">diamonds</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carat</span>, y <span class="op">=</span> <span class="va">price</span><span class="op">)</span>, colour <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Carat"</span>, y <span class="op">=</span> <span class="st">"Price"</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="statistics_files/figure-html/unnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The scatter plot shows a clear upward trend, suggesting that as <em>carat</em> increases, so does <em>price</em>. However, visualizations alone do not confirm statistical significance. To formally test this relationship, we establish the following hypotheses:</p>
<p><span class="math display">\[
\begin{cases}
    H_0: \rho   =  0 \quad \text{(There is no linear correlation between `carat` and `price`.)} \\
    H_a: \rho \neq 0 \quad \text{(There is a significant linear correlation between `carat` and `price`.)}
\end{cases}
\]</span></p>
<p>To conduct the correlation test in R, we use the <code><a href="https://rdrr.io/r/stats/cor.test.html">cor.test()</a></code> function:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="chapter-statistics.html#cb117-1" tabindex="-1"></a>cor_test <span class="ot">&lt;-</span> <span class="fu">cor.test</span>(diamonds<span class="sc">$</span>carat, diamonds<span class="sc">$</span>price)</span>
<span id="cb117-2"><a href="chapter-statistics.html#cb117-2" tabindex="-1"></a>cor_test</span>
<span id="cb117-3"><a href="chapter-statistics.html#cb117-3" tabindex="-1"></a>   </span>
<span id="cb117-4"><a href="chapter-statistics.html#cb117-4" tabindex="-1"></a>    Pearson<span class="st">'s product-moment correlation</span></span>
<span id="cb117-5"><a href="chapter-statistics.html#cb117-5" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb117-6"><a href="chapter-statistics.html#cb117-6" tabindex="-1"></a><span class="st">   data:  diamonds$carat and diamonds$price</span></span>
<span id="cb117-7"><a href="chapter-statistics.html#cb117-7" tabindex="-1"></a><span class="st">   t = 551.41, df = 53938, p-value &lt; 2.2e-16</span></span>
<span id="cb117-8"><a href="chapter-statistics.html#cb117-8" tabindex="-1"></a><span class="st">   alternative hypothesis: true correlation is not equal to 0</span></span>
<span id="cb117-9"><a href="chapter-statistics.html#cb117-9" tabindex="-1"></a><span class="st">   95 percent confidence interval:</span></span>
<span id="cb117-10"><a href="chapter-statistics.html#cb117-10" tabindex="-1"></a><span class="st">    0.9203098 0.9228530</span></span>
<span id="cb117-11"><a href="chapter-statistics.html#cb117-11" tabindex="-1"></a><span class="st">   sample estimates:</span></span>
<span id="cb117-12"><a href="chapter-statistics.html#cb117-12" tabindex="-1"></a><span class="st">         cor </span></span>
<span id="cb117-13"><a href="chapter-statistics.html#cb117-13" tabindex="-1"></a><span class="st">   0.9215913</span></span></code></pre></div>
<p>The output provides key results, including the <em>p</em>-value, correlation coefficient, and confidence interval:</p>
<ul>
<li>
<strong>p-value</strong>: If the <em>p</em>-value = 0 is smaller than the significance level (<span class="math inline">\(\alpha = 0.05\)</span>), we reject <span class="math inline">\(H_0\)</span>, confirming that the correlation is statistically significant.</li>
<li>
<strong>Correlation Coefficient</strong>: The correlation coefficient (<span class="math inline">\(r = 0.92\)</span>) quantifies the strength and direction of the relationship. A value close to 1 indicates a strong positive correlation, while a value near 0 suggests no linear association.</li>
<li>
<strong>Confidence Interval</strong>: The 95% confidence interval [0.92, 0.92] provides a plausible range for the true population correlation (<span class="math inline">\(\rho\)</span>). If this interval does not include 0, it further supports rejecting <span class="math inline">\(H_0\)</span> and confirms a meaningful association.</li>
</ul>
<p>The correlation coefficient of 0.92 suggests a strong positive relationship between <em>carat</em> and <em>price</em>, meaning that larger diamonds tend to be more expensive. The small <em>p</em>-value confirms that this pattern is unlikely due to random variation, while the confidence interval provides an estimate of how precisely we can measure this correlation.</p>
<p>Beyond statistical significance, this relationship has practical implications for diamond pricing strategies. If the correlation is particularly strong, pricing models could rely more on <em>carat</em> as a key determinant of value. However, if variability remains high despite a significant correlation, additional factors—such as diamond clarity, cut, or market conditions—may play an influential role. Further analysis could involve multivariate regression to assess how <em>carat</em> interacts with other attributes in predicting price.</p>
<p>By integrating visualization, statistical inference, and business insights, the correlation test offers a robust framework for understanding numerical relationships. This approach ensures that observed trends are both statistically sound and practically meaningful, laying the foundation for more advanced modeling techniques.</p>
</div>
<div id="wrapping-up" class="section level2" number="5.11">
<h2>
<span class="header-section-number">5.11</span> Wrapping Up<a class="anchor" aria-label="anchor" href="#wrapping-up"><i class="fas fa-link"></i></a>
</h2>
<p>This chapter provided a foundation for statistical inference, beginning with <em>estimation</em>, where we explored how point estimates and confidence intervals help quantify population parameters while accounting for uncertainty. We then introduced <em>hypothesis testing</em>, learning how to formulate null and alternative hypotheses, compute test statistics, and interpret <em>p</em>-values to make informed decisions. Through practical examples, we applied various statistical tests, including <em>t</em>-tests for comparing means, proportion tests for categorical data, ANOVA for assessing differences across multiple groups, and the Chi-square test and correlation analysis for uncovering relationships between variables. Together, these tools form a robust framework for extracting insights and answering key research questions.</p>
<p>Statistical inference plays a critical role in data-driven decision-making, helping analysts distinguish meaningful patterns from random variation. These methods are widely used in business and research, from evaluating marketing strategies to predicting customer behavior. However, reliable conclusions require more than statistical significance. It is essential to check assumptions, contextualize results, and integrate domain knowledge to ensure findings are both accurate and actionable.<br>
While statistical inference and hypothesis testing are essential tools in data science, they fall outside the scope of machine learning. If you are interested in exploring these topics further, we recommend introductory statistics textbooks such as <em>Intuitive Introductory Statistics</em> by Wolfe and Schneider.<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Douglas A Wolfe and Grant Schneider, &lt;em&gt;Intuitive Introductory Statistics&lt;/em&gt; (Springer, 2017).&lt;/p&gt;"><sup>5</sup></a></span></p>
<p>In the next chapter, we transition from statistical inference to predictive modeling, focusing on how to partition datasets effectively. Just as hypothesis testing helps determine whether patterns in data are real, proper data partitioning ensures that machine learning models generalize well to unseen data. As we move forward, ensuring data validity and model robustness will be key to building reliable predictive systems.</p>
</div>
<div id="exercises-3" class="section level2" number="5.12">
<h2>
<span class="header-section-number">5.12</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises-3"><i class="fas fa-link"></i></a>
</h2>
<div id="conceptual-questions-1" class="section level3 unnumbered">
<h3>Conceptual Questions<a class="anchor" aria-label="anchor" href="#conceptual-questions-1"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Why is hypothesis testing important in data science? Explain its role in making data-driven decisions and how it complements exploratory data analysis.</p></li>
<li><p>What is the difference between a confidence interval and a hypothesis test? How do they provide different ways of drawing conclusions about population parameters?</p></li>
<li><p>The <em>p</em>-value represents the probability of observing the sample data, or something more extreme, assuming the null hypothesis is true. How should <em>p</em>-values be interpreted, and why is a <em>p</em>-value of 0.001 in a two-sample <em>t</em>-test not necessarily evidence of practical significance?**</p></li>
<li><p>Explain the concepts of <em>Type I</em> and <em>Type II</em> errors in hypothesis testing. Why is it important to balance the risks of these errors when designing statistical tests?</p></li>
<li><p>In a hypothesis test, failing to reject the null hypothesis does not imply that the null hypothesis is true. Explain why this is the case and discuss the implications of this result in practice.</p></li>
<li><p>When working with small sample sizes, why is the <em>t</em>-distribution used instead of the normal distribution? How does the shape of the <em>t</em>-distribution change as the sample size increases?</p></li>
<li><p>One-tailed and two-tailed hypothesis tests serve different purposes. When would a one-tailed test be more appropriate than a two-tailed test? Provide an example where each type of test would be applicable.</p></li>
<li><p>Both the two-sample <em>Z</em>-test and the Chi-square test analyze categorical data but serve different purposes. How do they differ, and when would one be preferred over the other?</p></li>
<li><p>The <em>Analysis of Variance</em> (ANOVA) test is designed to compare means across multiple groups. Why can’t multiple <em>t</em>-tests be used instead? What is the advantage of using ANOVA in this context?</p></li>
</ol>
</div>
<div id="hands-on-practice-hypothesis-testing-in-r" class="section level3 unnumbered">
<h3>Hands-On Practice: Hypothesis Testing in R<a class="anchor" aria-label="anchor" href="#hands-on-practice-hypothesis-testing-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>For the following exercises, use the <em>churn</em>, <em>bank</em>, <em>marketing</em>, and <em>diamonds</em> datasets available in the <strong>liver</strong> and <strong>ggplot2</strong> packages. We have previously used the <em>churn</em>, <em>bank</em>, and <em>diamonds</em> datasets in this and earlier chapters. In Chapter <a href="chapter-regression.html#chapter-regression">10</a>, we will introduce the <em>marketing</em> dataset for regression analysis.</p>
<p>To load the datasets, use the following commands:</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.uva.nl/profile/a.mohammadi">liver</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>   </span>
<span></span>
<span><span class="co"># To import the datasets</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">churn</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">bank</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">marketing</span>, package <span class="op">=</span> <span class="st">"liver"</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">)</span>  </span></code></pre></div>
<ol start="10" style="list-style-type: decimal">
<li>We are interested in knowing the 90% confidence interval for the population mean of the variable “<code>night.calls</code>” in the <em>churn</em> dataset. In <strong>R</strong>, we can obtain a confidence interval for the population mean using the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function as follows:</li>
</ol>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="chapter-statistics.html#cb119-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> churn<span class="sc">$</span>night.calls, <span class="at">conf.level =</span> <span class="fl">0.90</span>)<span class="sc">$</span><span class="st">"conf.int"</span></span>
<span id="cb119-2"><a href="chapter-statistics.html#cb119-2" tabindex="-1"></a>   [<span class="dv">1</span>]  <span class="fl">99.45484</span> <span class="fl">100.38356</span></span>
<span id="cb119-3"><a href="chapter-statistics.html#cb119-3" tabindex="-1"></a>   <span class="fu">attr</span>(,<span class="st">"conf.level"</span>)</span>
<span id="cb119-4"><a href="chapter-statistics.html#cb119-4" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.9</span></span></code></pre></div>
<p>Interpret the confidence interval in the context of customer service calls made at night. Report the 99% confidence interval for the population mean of “<code>night.calls</code>” and compare it with the 90% confidence interval. Which interval is wider, and what does this indicate about the precision of the estimates? Why does increasing the confidence level result in a wider interval, and how does this impact decision-making in a business context?</p>
<ol start="11" style="list-style-type: decimal">
<li>Subgroup analyses help identify behavioral patterns in specific customer segments. In the <em>churn</em> dataset, we focus on customers with both an <em>International Plan</em> and a <em>Voice Mail Plan</em> who make more than 220 daytime minutes of calls. To create this subset, we use:</li>
</ol>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sub_churn</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">churn</span>, <span class="op">(</span><span class="va">intl.plan</span> <span class="op">==</span> <span class="st">"yes"</span><span class="op">)</span> <span class="op">&amp;</span> <span class="op">(</span><span class="va">voice.plan</span> <span class="op">==</span> <span class="st">"yes"</span><span class="op">)</span> <span class="op">&amp;</span> <span class="op">(</span><span class="va">day.mins</span> <span class="op">&gt;</span> <span class="fl">220</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<p>Next, we compute the 95% confidence interval for the proportion of churners in this subset using <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code>:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="chapter-statistics.html#cb121-1" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="fu">table</span>(sub_churn<span class="sc">$</span>churn), <span class="at">conf.level =</span> <span class="fl">0.95</span>)<span class="sc">$</span><span class="st">"conf.int"</span></span>
<span id="cb121-2"><a href="chapter-statistics.html#cb121-2" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.2595701</span> <span class="fl">0.5911490</span></span>
<span id="cb121-3"><a href="chapter-statistics.html#cb121-3" tabindex="-1"></a>   <span class="fu">attr</span>(,<span class="st">"conf.level"</span>)</span>
<span id="cb121-4"><a href="chapter-statistics.html#cb121-4" tabindex="-1"></a>   [<span class="dv">1</span>] <span class="fl">0.95</span></span></code></pre></div>
<p>Compare this confidence interval with the overall churn rate in the dataset (see Section <a href="chapter-statistics.html#statistics-confidence-interval">5.2</a>). What insights can be drawn about this customer segment, and how might they inform retention strategies?</p>
<ol start="12" style="list-style-type: decimal">
<li>In the <em>churn</em> dataset, we test whether the mean number of customer service calls (<code>customer.calls</code>) is greater than 1.5 at a significance level of 0.01. The right-tailed test is formulated as:</li>
</ol>
<p><span class="math display">\[
\begin{cases}
  H_0:  \mu \leq 1.5 \\
  H_a:  \mu &gt; 1.5
\end{cases}
\]</span></p>
<p>Since the level of significance is <span class="math inline">\(\alpha = 0.01\)</span>, the confidence level is <span class="math inline">\(1-\alpha = 0.99\)</span>. We perform the test using:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="chapter-statistics.html#cb122-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> churn<span class="sc">$</span>customer.calls, </span>
<span id="cb122-2"><a href="chapter-statistics.html#cb122-2" tabindex="-1"></a>        <span class="at">mu =</span> <span class="fl">1.5</span>, </span>
<span id="cb122-3"><a href="chapter-statistics.html#cb122-3" tabindex="-1"></a>        <span class="at">alternative =</span> <span class="st">"greater"</span>, </span>
<span id="cb122-4"><a href="chapter-statistics.html#cb122-4" tabindex="-1"></a>        <span class="at">conf.level =</span> <span class="fl">0.99</span>)</span>
<span id="cb122-5"><a href="chapter-statistics.html#cb122-5" tabindex="-1"></a>   </span>
<span id="cb122-6"><a href="chapter-statistics.html#cb122-6" tabindex="-1"></a>    One Sample t<span class="sc">-</span>test</span>
<span id="cb122-7"><a href="chapter-statistics.html#cb122-7" tabindex="-1"></a>   </span>
<span id="cb122-8"><a href="chapter-statistics.html#cb122-8" tabindex="-1"></a>   data<span class="sc">:</span>  churn<span class="sc">$</span>customer.calls</span>
<span id="cb122-9"><a href="chapter-statistics.html#cb122-9" tabindex="-1"></a>   t <span class="ot">=</span> <span class="fl">3.8106</span>, df <span class="ot">=</span> <span class="dv">4999</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">7.015e-05</span></span>
<span id="cb122-10"><a href="chapter-statistics.html#cb122-10" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true mean is greater than <span class="fl">1.5</span></span>
<span id="cb122-11"><a href="chapter-statistics.html#cb122-11" tabindex="-1"></a>   <span class="dv">99</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb122-12"><a href="chapter-statistics.html#cb122-12" tabindex="-1"></a>    <span class="fl">1.527407</span>      <span class="cn">Inf</span></span>
<span id="cb122-13"><a href="chapter-statistics.html#cb122-13" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb122-14"><a href="chapter-statistics.html#cb122-14" tabindex="-1"></a>   mean of x </span>
<span id="cb122-15"><a href="chapter-statistics.html#cb122-15" tabindex="-1"></a>      <span class="fl">1.5704</span></span></code></pre></div>
<p>Report the <em>p</em>-value and determine whether to reject the null hypothesis at <span class="math inline">\(\alpha=0.01\)</span>. Explain your decision and discuss its implications in the context of customer service interactions.</p>
<ol start="13" style="list-style-type: decimal">
<li>In the <em>churn</em> dataset, we test whether the proportion of churners (<span class="math inline">\(\pi\)</span>) is less than 0.14 at a significance level of <span class="math inline">\(\alpha=0.01\)</span>. The confidence level is <span class="math inline">\(99\%\)</span>, corresponding to <span class="math inline">\(1-\alpha = 0.99\)</span>. The test is conducted in <strong>R</strong> using:</li>
</ol>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="chapter-statistics.html#cb123-1" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="fu">table</span>(churn<span class="sc">$</span>churn), </span>
<span id="cb123-2"><a href="chapter-statistics.html#cb123-2" tabindex="-1"></a>           <span class="at">p =</span> <span class="fl">0.14</span>, </span>
<span id="cb123-3"><a href="chapter-statistics.html#cb123-3" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="st">"less"</span>, </span>
<span id="cb123-4"><a href="chapter-statistics.html#cb123-4" tabindex="-1"></a>           <span class="at">conf.level =</span> <span class="fl">0.99</span>)</span>
<span id="cb123-5"><a href="chapter-statistics.html#cb123-5" tabindex="-1"></a>   </span>
<span id="cb123-6"><a href="chapter-statistics.html#cb123-6" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">-</span>sample proportions test with continuity correction</span>
<span id="cb123-7"><a href="chapter-statistics.html#cb123-7" tabindex="-1"></a>   </span>
<span id="cb123-8"><a href="chapter-statistics.html#cb123-8" tabindex="-1"></a>   data<span class="sc">:</span>  <span class="fu">table</span>(churn<span class="sc">$</span>churn), null probability <span class="fl">0.14</span></span>
<span id="cb123-9"><a href="chapter-statistics.html#cb123-9" tabindex="-1"></a>   X<span class="sc">-</span>squared <span class="ot">=</span> <span class="fl">0.070183</span>, df <span class="ot">=</span> <span class="dv">1</span>, p<span class="sc">-</span>value <span class="ot">=</span> <span class="fl">0.6045</span></span>
<span id="cb123-10"><a href="chapter-statistics.html#cb123-10" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true p is less than <span class="fl">0.14</span></span>
<span id="cb123-11"><a href="chapter-statistics.html#cb123-11" tabindex="-1"></a>   <span class="dv">99</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb123-12"><a href="chapter-statistics.html#cb123-12" tabindex="-1"></a>    <span class="fl">0.0000000</span> <span class="fl">0.1533547</span></span>
<span id="cb123-13"><a href="chapter-statistics.html#cb123-13" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb123-14"><a href="chapter-statistics.html#cb123-14" tabindex="-1"></a>        p </span>
<span id="cb123-15"><a href="chapter-statistics.html#cb123-15" tabindex="-1"></a>   <span class="fl">0.1414</span></span></code></pre></div>
<p>State the null and alternative hypotheses. Report the <em>p</em>-value and determine whether to reject the null hypothesis at <span class="math inline">\(\alpha=0.01\)</span>. Explain your conclusion and its potential impact on customer retention strategies.</p>
<ol start="14" style="list-style-type: decimal">
<li>In the <em>churn</em> dataset, we examine whether the number of customer service calls (<code>customer.calls</code>) differs between churners and non-churners. To test this, we perform a two-sample <em>t</em>-test:</li>
</ol>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="chapter-statistics.html#cb124-1" tabindex="-1"></a><span class="fu">t.test</span>(customer.calls <span class="sc">~</span> churn, <span class="at">data =</span> churn)</span>
<span id="cb124-2"><a href="chapter-statistics.html#cb124-2" tabindex="-1"></a>   </span>
<span id="cb124-3"><a href="chapter-statistics.html#cb124-3" tabindex="-1"></a>    Welch Two Sample t<span class="sc">-</span>test</span>
<span id="cb124-4"><a href="chapter-statistics.html#cb124-4" tabindex="-1"></a>   </span>
<span id="cb124-5"><a href="chapter-statistics.html#cb124-5" tabindex="-1"></a>   data<span class="sc">:</span>  customer.calls by churn</span>
<span id="cb124-6"><a href="chapter-statistics.html#cb124-6" tabindex="-1"></a>   t <span class="ot">=</span> <span class="fl">11.292</span>, df <span class="ot">=</span> <span class="fl">804.21</span>, p<span class="sc">-</span>value <span class="sc">&lt;</span> <span class="fl">2.2e-16</span></span>
<span id="cb124-7"><a href="chapter-statistics.html#cb124-7" tabindex="-1"></a>   alternative hypothesis<span class="sc">:</span> true difference <span class="cf">in</span> means between group yes and group no is not equal to <span class="dv">0</span></span>
<span id="cb124-8"><a href="chapter-statistics.html#cb124-8" tabindex="-1"></a>   <span class="dv">95</span> percent confidence interval<span class="sc">:</span></span>
<span id="cb124-9"><a href="chapter-statistics.html#cb124-9" tabindex="-1"></a>    <span class="fl">0.6583525</span> <span class="fl">0.9353976</span></span>
<span id="cb124-10"><a href="chapter-statistics.html#cb124-10" tabindex="-1"></a>   sample estimates<span class="sc">:</span></span>
<span id="cb124-11"><a href="chapter-statistics.html#cb124-11" tabindex="-1"></a>   mean <span class="cf">in</span> group yes  mean <span class="cf">in</span> group no </span>
<span id="cb124-12"><a href="chapter-statistics.html#cb124-12" tabindex="-1"></a>            <span class="fl">2.254597</span>          <span class="fl">1.457722</span></span></code></pre></div>
<p>State the null and alternative hypotheses. Determine whether to reject the null hypothesis at a significance level of <span class="math inline">\(\alpha=0.05\)</span>. Report the <em>p</em>-value and interpret the results, explaining whether there is evidence of a relationship between churn status and customer service call frequency.</p>
<ol start="15" style="list-style-type: decimal">
<li>In the <em>marketing</em> dataset, we test whether there is a <em>positive</em> relationship between <code>revenue</code> and <code>spend</code> at a significance level of <span class="math inline">\(\alpha = 0.025\)</span>. We perform a one-tailed correlation test using:</li>
</ol>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="chapter-statistics.html#cb125-1" tabindex="-1"></a><span class="fu">cor.test</span>(<span class="at">x =</span> marketing<span class="sc">$</span>spend, </span>
<span id="cb125-2"><a href="chapter-statistics.html#cb125-2" tabindex="-1"></a>         <span class="at">y =</span> marketing<span class="sc">$</span>revenue, </span>
<span id="cb125-3"><a href="chapter-statistics.html#cb125-3" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">"greater"</span>, </span>
<span id="cb125-4"><a href="chapter-statistics.html#cb125-4" tabindex="-1"></a>         <span class="at">conf.level =</span> <span class="fl">0.975</span>)</span>
<span id="cb125-5"><a href="chapter-statistics.html#cb125-5" tabindex="-1"></a>   </span>
<span id="cb125-6"><a href="chapter-statistics.html#cb125-6" tabindex="-1"></a>    Pearson<span class="st">'s product-moment correlation</span></span>
<span id="cb125-7"><a href="chapter-statistics.html#cb125-7" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb125-8"><a href="chapter-statistics.html#cb125-8" tabindex="-1"></a><span class="st">   data:  marketing$spend and marketing$revenue</span></span>
<span id="cb125-9"><a href="chapter-statistics.html#cb125-9" tabindex="-1"></a><span class="st">   t = 7.9284, df = 38, p-value = 7.075e-10</span></span>
<span id="cb125-10"><a href="chapter-statistics.html#cb125-10" tabindex="-1"></a><span class="st">   alternative hypothesis: true correlation is greater than 0</span></span>
<span id="cb125-11"><a href="chapter-statistics.html#cb125-11" tabindex="-1"></a><span class="st">   97.5 percent confidence interval:</span></span>
<span id="cb125-12"><a href="chapter-statistics.html#cb125-12" tabindex="-1"></a><span class="st">    0.6338152 1.0000000</span></span>
<span id="cb125-13"><a href="chapter-statistics.html#cb125-13" tabindex="-1"></a><span class="st">   sample estimates:</span></span>
<span id="cb125-14"><a href="chapter-statistics.html#cb125-14" tabindex="-1"></a><span class="st">        cor </span></span>
<span id="cb125-15"><a href="chapter-statistics.html#cb125-15" tabindex="-1"></a><span class="st">   0.789455</span></span></code></pre></div>
<p>State the null and alternative hypotheses. Report the <em>p</em>-value and determine whether to reject the null hypothesis. Explain your decision and discuss its implications for understanding the relationship between marketing spend and revenue.</p>
<ol start="16" style="list-style-type: decimal">
<li><p>In the <em>churn</em> dataset, for the variable “<code>day.mins</code>”, test whether the mean number of “Day Minutes” is greater than 180. Set the level of significance to be 0.05.</p></li>
<li><p>In the <em>churn</em> dataset, for the variable “<code>intl.plan</code>” test at <span class="math inline">\(\alpha=0.05\)</span> weather the proportion of customers who have international plan is less than 0.15.</p></li>
<li><p>In the <em>churn</em> dataset, test whether there is a relationship between the target variable “<code>churn</code>” and the variable “<code>intl.charge</code>” with <span class="math inline">\(\alpha=0.05\)</span>.</p></li>
<li><p>In the <em>bank</em> dataset, test whether there is a relationship between the target variable “<code>deposit</code>” and the variable “<code>education</code>” with <span class="math inline">\(\alpha=0.05\)</span>.</p></li>
<li><p>Compute the proportion of customers in the <em>churn</em> dataset who have an International Plan (<code>intl.plan</code>). Construct a 95% confidence interval for this proportion using R, and interpret the confidence interval in the context of customer subscriptions.</p></li>
<li><p>Using the <em>churn</em> dataset, test whether the average number of daytime minutes (<code>day.mins</code>) for churners differs significantly from 200 minutes. Conduct a one-sample <em>t</em>-test in R and interpret the results in relation to customer behavior.</p></li>
<li><p>Compare the average number of international calls (<code>intl.calls</code>) between churners and non-churners. Perform a two-sample <em>t</em>-test and evaluate whether the observed differences in means are statistically significant.</p></li>
<li><p>Test whether the proportion of customers with a Voice Mail Plan (<code>voice.plan</code>) differs between churners and non-churners. Use a two-sample <em>Z</em>-test in R and interpret the results, considering the implications for customer retention strategies.</p></li>
<li><p>Investigate whether marital status (<code>marital</code>) is associated with deposit subscription (<code>deposit</code>) in the <em>bank</em> dataset. Construct a contingency table and perform a Chi-square test to assess whether marital status has a significant impact on deposit purchasing behavior.</p></li>
<li><p>Using the <em>diamonds</em> dataset, test whether the mean price of diamonds differs across different diamond cuts (<code>cut</code>). Conduct an ANOVA test and interpret the results. If the test finds significant differences, discuss how post-hoc tests could be used to further explore the findings.</p></li>
<li><p>Assess the correlation between <code>carat</code> and <code>price</code> in the <em>diamonds</em> dataset. Perform a correlation test in R and visualize the relationship using a scatter plot. Interpret the results in the context of diamond pricing.</p></li>
<li><p>Construct a 95% confidence interval for the mean number of customer service calls (<code>customer.calls</code>) among churners. Explain how the confidence interval helps quantify uncertainty and how it might inform business decisions regarding customer support.</p></li>
<li><p>Take a random sample of 100 observations from the <em>churn</em> dataset and test whether the average <code>eve.mins</code> differs from 200. Repeat the test using a sample of 1000 observations. Compare the results and discuss how sample size affects hypothesis testing and statistical power.</p></li>
<li><p>Suppose a hypothesis test indicates that customers with a Voice Mail Plan are significantly less likely to churn (<em>p</em> &lt; 0.01). What are some potential business strategies a company could implement based on this finding? Beyond statistical significance, what additional factors should be considered before making marketing decisions?</p></li>
</ol>
</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="chapter-EDA.html"><span class="header-section-number">4</span> Exploratory Data Analysis</a></div>
<div class="next"><a href="chapter-modeling.html"><span class="header-section-number">6</span> Preparing Data for Modeling</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chapter-statistics"><span class="header-section-number">5</span> Statistical Inference and Hypothesis Testing</a></li>
<li><a class="nav-link" href="#estimation-using-data-to-make-predictions"><span class="header-section-number">5.1</span> Estimation: Using Data to Make Predictions</a></li>
<li><a class="nav-link" href="#statistics-confidence-interval"><span class="header-section-number">5.2</span> Quantifying Uncertainty: Confidence Intervals</a></li>
<li>
<a class="nav-link" href="#hypothesis-testing"><span class="header-section-number">5.3</span> Hypothesis Testing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#types-of-hypothesis-tests"><span class="header-section-number">5.3.1</span> Types of Hypothesis Tests</a></li>
<li><a class="nav-link" href="#common-hypothesis-tests">Common Hypothesis Tests</a></li>
</ul>
</li>
<li><a class="nav-link" href="#one-sample-t-test"><span class="header-section-number">5.4</span> One-sample t-test</a></li>
<li><a class="nav-link" href="#hypothesis-testing-for-proportion"><span class="header-section-number">5.5</span> Hypothesis Testing for Proportion</a></li>
<li><a class="nav-link" href="#two-sample-t-test"><span class="header-section-number">5.6</span> Two-sample T-test</a></li>
<li><a class="nav-link" href="#two-sample-z-test"><span class="header-section-number">5.7</span> Two-Sample Z-Test</a></li>
<li><a class="nav-link" href="#chi-square-test"><span class="header-section-number">5.8</span> Chi-square Test</a></li>
<li><a class="nav-link" href="#analysis-of-variance-anova-test"><span class="header-section-number">5.9</span> Analysis of Variance (ANOVA) Test</a></li>
<li><a class="nav-link" href="#correlation-test"><span class="header-section-number">5.10</span> Correlation Test</a></li>
<li><a class="nav-link" href="#wrapping-up"><span class="header-section-number">5.11</span> Wrapping Up</a></li>
<li>
<a class="nav-link" href="#exercises-3"><span class="header-section-number">5.12</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#conceptual-questions-1">Conceptual Questions</a></li>
<li><a class="nav-link" href="#hands-on-practice-hypothesis-testing-in-r">Hands-On Practice: Hypothesis Testing in R</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/RezaMoammadi/Book-Data-Science/blob/master/statistics.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/RezaMoammadi/Book-Data-Science/edit/master/statistics.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Uncovering Data Science with R</strong>" was written by Reza Mohammadi. It was last built on 2025-02-17.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
